{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Official Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/home/jdkent/.conda/envs/comfy_pants/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/conda/bin\n"
     ]
    }
   ],
   "source": [
    "%env PATH=/home/jdkent/.conda/envs/comfy_pants/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/conda/bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize, PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/BipolarDerivedDataTraining.csv'\n",
    "NTHREADS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_df = pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_df = bp_df.filter(regex=(\"age$|gender|handedness|31p.*[^r]$|t1r.*_m|alff.*_m|allvol|dti\"))\n",
    "selected_df = bp_df.filter(regex=(\"31p.*[^r]$|t1r.*_m|alff.*_m|allvol|dti\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mod_df = bp_df.filter(\n",
    "    regex=(\"t1r.*cbm.*_m|t1r.*cc.*_m|t1r.*wm_.*_m|dti.*lob.*|dti.*crus.*|dti.*vermis.*|dti.*vii.*|dti.*cc.*\")).replace({0.: np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3601f8e310>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(best_mod_df.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['t1r_l_cbmwm_m', 't1r_l_cbmctx_m', 't1r_laccumbarea_m', 't1r_r_cbmwm_m',\n",
       "       't1r_r_cbmctx_m', 't1r_raccumbarea_m', 't1r_opticchiasm_m',\n",
       "       't1r_cc_post_m', 't1r_cc_mid_post_m', 't1r_cc_mid_post_nv',\n",
       "       ...\n",
       "       'dti_r_viiia_krd', 'dti_l_lob_viiib_krd', 'dti_vermis_viiib_krd',\n",
       "       'dti_right_lob_viiib_krd', 'dti_l_lob_ix_krd', 'dti_vermis_ix_krd',\n",
       "       'dti_r_lob_ix_krd', 'dti_l_lob_x_krd', 'dti_vermis_x_krd',\n",
       "       'dti_r_lob_x_krd'],\n",
       "      dtype='object', length=268)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mod_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = label_binarize(bp_df['group'], classes=[\"Case\", \"Control\"]).squeeze()\n",
    "extra_info = bp_df[['madrs_score', 'ymrs_score', 'suicideideation_rating_mostsevere_life']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['Case', 'Case', 'Case', 'Case', 'Case', 'Case', 'Case', 'Case',\n",
       "       'Case', 'Case', 'Case', 'Case', 'Case', 'Case', 'Case', 'Case',\n",
       "       'Case', 'Case', 'Case', 'Case', 'Case', 'Case', 'Case', 'Case',\n",
       "       'Case', 'Case', 'Case', 'Case', 'Case', 'Case', 'Case', 'Case',\n",
       "       'Case', 'Case', 'Case', 'Case', 'Case', 'Case', 'Case', 'Case',\n",
       "       'Case', 'Case', 'Case', 'Case', 'Case', 'Case', 'Case', 'Case',\n",
       "       'Case', 'Case', 'Case', 'Case', 'Case', 'Case', 'Case', 'Case',\n",
       "       'Case', 'Control', 'Control', 'Control', 'Control', 'Control',\n",
       "       'Control', 'Control', 'Control', 'Control', 'Control', 'Control',\n",
       "       'Control', 'Control', 'Control', 'Control', 'Control', 'Control',\n",
       "       'Control', 'Control', 'Control', 'Control', 'Control', 'Control',\n",
       "       'Control', 'Control', 'Control', 'Control', 'Control', 'Control',\n",
       "       'Control', 'Control'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(group)\n",
    "display(bp_df['group'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratify makes sure the number of group\n",
    "X_train, X_test, y_train_all, y_test_all = train_test_split(\n",
    "    selected_df, group, test_size=10, stratify=group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train_all[:,0]\n",
    "extra_info_train = y_train_all[:,1:]\n",
    "y_test = y_test_all[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.decomposition import PCA, KernelPCA, DictionaryLearning, FactorAnalysis, FastICA, SparsePCA\n",
    "from sklearn.cross_decomposition import CCA, PLSSVD, PLSCanonical, PLSRegression\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, StackingClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import (\n",
    "    PowerTransformer, StandardScaler, PolynomialFeatures,\n",
    "    FunctionTransformer, OneHotEncoder, LabelBinarizer,\n",
    "    label_binarize, scale, QuantileTransformer)\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectKBest, SelectFromModel, RFE, RFECV, mutual_info_classif, f_classif\n",
    "from statsmodels.stats.diagnostic import kstest_normal, normal_ad\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import FeatureAgglomeration\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis  \n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from matplotlib.colors import Normalize\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Tune/Test your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=32)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done  12 out of  20 | elapsed:  1.7min remaining:  1.1min\n",
      "[Parallel(n_jobs=32)]: Done  20 out of  20 | elapsed:  1.8min finished\n",
      "/home/jdkent/.conda/envs/comfy_pants/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:2357: UserWarning: n_quantiles (1000) is greater than the total number of samples (78). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_kittens__C</th>\n",
       "      <th>param_kittens__dual</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73.019943</td>\n",
       "      <td>0.790654</td>\n",
       "      <td>8.87305</td>\n",
       "      <td>2.823183</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>{'kittens__C': 1, 'kittens__dual': True}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73.253695</td>\n",
       "      <td>0.798605</td>\n",
       "      <td>8.89946</td>\n",
       "      <td>2.798799</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>{'kittens__C': 10, 'kittens__dual': True}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      73.019943      0.790654          8.87305        2.823183   \n",
       "1      73.253695      0.798605          8.89946        2.798799   \n",
       "\n",
       "  param_kittens__C param_kittens__dual  \\\n",
       "0                1                True   \n",
       "1               10                True   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "0   {'kittens__C': 1, 'kittens__dual': True}           0.666667   \n",
       "1  {'kittens__C': 10, 'kittens__dual': True}           0.666667   \n",
       "\n",
       "   split1_test_score  split2_test_score  ...  split2_train_score  \\\n",
       "0           0.666667                0.6  ...                 1.0   \n",
       "1           0.666667                0.6  ...                 1.0   \n",
       "\n",
       "   split3_train_score  split4_train_score  split5_train_score  \\\n",
       "0                 1.0                 1.0                 1.0   \n",
       "1                 1.0                 1.0                 1.0   \n",
       "\n",
       "   split6_train_score  split7_train_score  split8_train_score  \\\n",
       "0                 1.0                 1.0                 1.0   \n",
       "1                 1.0                 1.0                 1.0   \n",
       "\n",
       "   split9_train_score  mean_train_score  std_train_score  \n",
       "0                 1.0               1.0              0.0  \n",
       "1                 1.0               1.0              0.0  \n",
       "\n",
       "[2 rows x 32 columns]"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_outliers = QuantileTransformer(output_distribution='normal')\n",
    "\n",
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50,\n",
    "                           random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "kbest = SelectKBest(k=1000)\n",
    "\n",
    "svc = LinearSVC(max_iter=100000, random_state=42, class_weight=\"balanced\")\n",
    "C_opts = [1, 10]\n",
    "\n",
    "grid_params = [\n",
    "    {\n",
    "        \"kittens__C\": C_opts,\n",
    "        \"kittens__dual\": [True]\n",
    "    }\n",
    "]\n",
    "\n",
    "pipelineM = Pipeline([(\"outliers\", fix_outliers),\n",
    "                      (\"imp\", imputer),\n",
    "                      (\"scaler\", scaler),\n",
    "                      (\"kbest\", kbest),\n",
    "                      (\"kittens\", svc)])\n",
    "\n",
    "search = GridSearchCV(\n",
    "    pipelineM, n_jobs=NTHREADS, param_grid=grid_params, \n",
    "    cv=10, scoring='roc_auc', error_score='raise', return_train_score=True, refit=True, verbose=2)\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "cv_df = pd.DataFrame(search.cv_results_)\n",
    "cv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666667"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(split0_test_score > 0.15)&(split1_test_score > 0.15)&(split2_test_score > 0.15)&(split3_test_score > 0.15)&(split4_test_score > 0.15)&(split5_test_score > 0.15)&(split6_test_score > 0.15)&(split7_test_score > 0.15)&(split8_test_score > 0.15)&(split9_test_score > 0.15)'"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_list = ['(split{}_test_score > 0.15)'.format(idx) for idx in range(10)]\n",
    "query = '&'.join(query_list)\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_kittens__C</th>\n",
       "      <th>param_kittens__dual</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>{'kittens__C': 1, 'kittens__dual': True}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.17127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>{'kittens__C': 10, 'kittens__dual': True}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.17127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_kittens__C param_kittens__dual  \\\n",
       "0                1                True   \n",
       "1               10                True   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "0   {'kittens__C': 1, 'kittens__dual': True}           0.666667   \n",
       "1  {'kittens__C': 10, 'kittens__dual': True}           0.666667   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.666667                0.6                0.6                0.6   \n",
       "1           0.666667                0.6                0.6                0.6   \n",
       "\n",
       "   split5_test_score  split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0           0.866667                0.6           0.833333                0.2   \n",
       "1           0.866667                0.6           0.833333                0.2   \n",
       "\n",
       "   split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0                0.7         0.633333         0.17127                1  \n",
       "1                0.7         0.633333         0.17127                1  "
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df.query(query).loc[:,\"param_kittens__C\":\"rank_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6912 candidates, totalling 69120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=32)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done  98 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=32)]: Done 301 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=32)]: Done 584 tasks      | elapsed: 17.3min\n",
      "[Parallel(n_jobs=32)]: Done 949 tasks      | elapsed: 27.5min\n",
      "[Parallel(n_jobs=32)]: Done 1394 tasks      | elapsed: 40.1min\n",
      "[Parallel(n_jobs=32)]: Done 1921 tasks      | elapsed: 55.3min\n",
      "[Parallel(n_jobs=32)]: Done 2528 tasks      | elapsed: 72.8min\n",
      "[Parallel(n_jobs=32)]: Done 3217 tasks      | elapsed: 92.4min\n",
      "[Parallel(n_jobs=32)]: Done 3986 tasks      | elapsed: 114.6min\n",
      "[Parallel(n_jobs=32)]: Done 4837 tasks      | elapsed: 138.7min\n",
      "[Parallel(n_jobs=32)]: Done 5768 tasks      | elapsed: 165.6min\n",
      "[Parallel(n_jobs=32)]: Done 6781 tasks      | elapsed: 194.5min\n",
      "[Parallel(n_jobs=32)]: Done 7874 tasks      | elapsed: 225.9min\n",
      "[Parallel(n_jobs=32)]: Done 9049 tasks      | elapsed: 258.9min\n",
      "[Parallel(n_jobs=32)]: Done 10304 tasks      | elapsed: 294.9min\n",
      "[Parallel(n_jobs=32)]: Done 11641 tasks      | elapsed: 333.7min\n",
      "[Parallel(n_jobs=32)]: Done 13058 tasks      | elapsed: 373.6min\n",
      "[Parallel(n_jobs=32)]: Done 14557 tasks      | elapsed: 415.7min\n",
      "[Parallel(n_jobs=32)]: Done 16136 tasks      | elapsed: 460.8min\n",
      "[Parallel(n_jobs=32)]: Done 17797 tasks      | elapsed: 507.7min\n",
      "[Parallel(n_jobs=32)]: Done 19538 tasks      | elapsed: 556.8min\n",
      "[Parallel(n_jobs=32)]: Done 21361 tasks      | elapsed: 608.1min\n",
      "[Parallel(n_jobs=32)]: Done 23264 tasks      | elapsed: 661.9min\n",
      "[Parallel(n_jobs=32)]: Done 25249 tasks      | elapsed: 717.9min\n",
      "[Parallel(n_jobs=32)]: Done 27314 tasks      | elapsed: 776.4min\n",
      "[Parallel(n_jobs=32)]: Done 29461 tasks      | elapsed: 837.5min\n",
      "[Parallel(n_jobs=32)]: Done 31688 tasks      | elapsed: 901.0min\n",
      "[Parallel(n_jobs=32)]: Done 33997 tasks      | elapsed: 967.0min\n",
      "[Parallel(n_jobs=32)]: Done 36386 tasks      | elapsed: 1034.7min\n",
      "[Parallel(n_jobs=32)]: Done 38857 tasks      | elapsed: 1106.0min\n",
      "[Parallel(n_jobs=32)]: Done 41408 tasks      | elapsed: 1178.4min\n",
      "[Parallel(n_jobs=32)]: Done 44041 tasks      | elapsed: 1253.1min\n",
      "[Parallel(n_jobs=32)]: Done 46754 tasks      | elapsed: 1330.0min\n",
      "[Parallel(n_jobs=32)]: Done 49549 tasks      | elapsed: 1410.1min\n",
      "[Parallel(n_jobs=32)]: Done 52424 tasks      | elapsed: 1491.8min\n",
      "[Parallel(n_jobs=32)]: Done 55381 tasks      | elapsed: 1574.9min\n",
      "[Parallel(n_jobs=32)]: Done 58418 tasks      | elapsed: 1660.6min\n",
      "[Parallel(n_jobs=32)]: Done 61537 tasks      | elapsed: 1749.6min\n",
      "[Parallel(n_jobs=32)]: Done 64736 tasks      | elapsed: 1840.3min\n",
      "[Parallel(n_jobs=32)]: Done 68017 tasks      | elapsed: 1933.5min\n",
      "[Parallel(n_jobs=32)]: Done 69120 out of 69120 | elapsed: 1964.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5416666666666667"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ignore residuals\n",
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "kbest = SelectKBest(k=500)\n",
    "pca = PCA(whiten=True)\n",
    "n_comp_opts = [2, 3, 5]\n",
    "poly = PolynomialFeatures(include_bias=False, interaction_only=True)\n",
    "dummy = FunctionTransformer()\n",
    "clf = xgboost.XGBClassifier(subsample=0.7, n_estimators=500)\n",
    "max_depth_opts = [3, 5, 10]\n",
    "learning_rate_opts = [0.01, 0.1, 0.5]\n",
    "scale_pos_weight_opts = [2, 4]\n",
    "gamma_opts = [0.5, 3]\n",
    "min_child_weight_opts = [3, 5]\n",
    "max_delta_step_opts = [3, 7]\n",
    "lambda_opts = [2, 5]\n",
    "alpha_opts = [1, 3]\n",
    "\n",
    "grid_params = [\n",
    "    {\n",
    "        'pca__n_components': n_comp_opts,\n",
    "        'pca__whiten': whiten_opts,\n",
    "        'poly': [dummy, poly],\n",
    "        'clf__max_depth': max_depth_opts,\n",
    "        'clf__learning_rate': learning_rate_opts,\n",
    "        'clf__scale_pos_weight': scale_pos_weight_opts,\n",
    "        'clf__gamma': gamma_opts,\n",
    "        'clf__min_child_weight': min_child_weight_opts,\n",
    "        'clf__max_delta_step': max_delta_step_opts,\n",
    "        'clf__lambda': lambda_opts,\n",
    "        'clf__alpha': alpha_opts,\n",
    "    }\n",
    "]\n",
    "pipelineM = Pipeline([(\"imp\", imputer),\n",
    "                      (\"scaler\", scaler),\n",
    "                      (\"kbest\", kbest),\n",
    "                      (\"poly\", poly),\n",
    "                      (\"pca\", pca),\n",
    "                      (\"clf\", clf)])\n",
    "# pipelineM.fit(X_train, y_train)\n",
    "# pipelineM.score(X_test, y_test)\n",
    "search = GridSearchCV(pipelineM, n_jobs=NTHREADS, param_grid=grid_params, cv=10, scoring='roc_auc', verbose=2)\n",
    "search.fit(X_train, y_train)\n",
    "search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__alpha</th>\n",
       "      <th>param_clf__gamma</th>\n",
       "      <th>param_clf__lambda</th>\n",
       "      <th>param_clf__learning_rate</th>\n",
       "      <th>param_clf__max_delta_step</th>\n",
       "      <th>param_clf__max_depth</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49.257251</td>\n",
       "      <td>2.611500</td>\n",
       "      <td>4.761478</td>\n",
       "      <td>1.412277</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.162788</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.636347</td>\n",
       "      <td>2.567339</td>\n",
       "      <td>4.803027</td>\n",
       "      <td>1.416206</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.263228</td>\n",
       "      <td>5991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.377423</td>\n",
       "      <td>2.756836</td>\n",
       "      <td>4.783385</td>\n",
       "      <td>1.424721</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.204423</td>\n",
       "      <td>2829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.086936</td>\n",
       "      <td>2.936776</td>\n",
       "      <td>4.810776</td>\n",
       "      <td>1.389861</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.157621</td>\n",
       "      <td>5979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48.556613</td>\n",
       "      <td>2.659269</td>\n",
       "      <td>4.785386</td>\n",
       "      <td>1.397731</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.157621</td>\n",
       "      <td>2275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      49.257251      2.611500         4.761478        1.412277   \n",
       "1      49.636347      2.567339         4.803027        1.416206   \n",
       "2      49.377423      2.756836         4.783385        1.424721   \n",
       "3      49.086936      2.936776         4.810776        1.389861   \n",
       "4      48.556613      2.659269         4.785386        1.397731   \n",
       "\n",
       "  param_clf__alpha param_clf__gamma param_clf__lambda  \\\n",
       "0                1              0.5                 2   \n",
       "1                1              0.5                 2   \n",
       "2                1              0.5                 2   \n",
       "3                1              0.5                 2   \n",
       "4                1              0.5                 2   \n",
       "\n",
       "  param_clf__learning_rate param_clf__max_delta_step param_clf__max_depth  \\\n",
       "0                     0.01                         3                    3   \n",
       "1                     0.01                         3                    3   \n",
       "2                     0.01                         3                    3   \n",
       "3                     0.01                         3                    3   \n",
       "4                     0.01                         3                    3   \n",
       "\n",
       "   ... split3_test_score split4_test_score split5_test_score  \\\n",
       "0  ...          0.400000          0.800000          0.466667   \n",
       "1  ...          0.066667          0.666667          0.833333   \n",
       "2  ...          0.600000          0.733333          0.400000   \n",
       "3  ...          0.266667          0.733333          0.566667   \n",
       "4  ...          0.466667          0.666667          0.266667   \n",
       "\n",
       "  split6_test_score split7_test_score split8_test_score  split9_test_score  \\\n",
       "0          0.600000          0.800000               0.7                0.6   \n",
       "1          0.200000          0.466667               0.8                0.6   \n",
       "2          0.600000          0.866667               0.6                0.3   \n",
       "3          0.333333          0.533333               0.6                0.4   \n",
       "4          0.600000          0.600000               0.7                0.6   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.683333        0.162788              410  \n",
       "1         0.440000        0.263228             5991  \n",
       "2         0.610000        0.204423             2829  \n",
       "3         0.440000        0.157621             5979  \n",
       "4         0.626667        0.157621             2275  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 1,\n",
       " 'clf__gamma': 3,\n",
       " 'clf__lambda': 2,\n",
       " 'clf__learning_rate': 0.5,\n",
       " 'clf__max_delta_step': 7,\n",
       " 'clf__max_depth': 3,\n",
       " 'clf__min_child_weight': 5,\n",
       " 'clf__scale_pos_weight': 4,\n",
       " 'pca__n_components': 2,\n",
       " 'pca__whiten': False,\n",
       " 'poly': FunctionTransformer(accept_sparse=False, check_inverse=True, func=None,\n",
       "                     inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "                     validate=False)}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(split0_test_score > 0.60)&(split1_test_score > 0.60)&(split2_test_score > 0.60)&(split3_test_score > 0.60)&(split4_test_score > 0.60)&(split5_test_score > 0.60)&(split6_test_score > 0.60)&(split7_test_score > 0.60)&(split8_test_score > 0.60)&(split9_test_score > 0.60)'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_list = ['(split{}_test_score > 0.60)'.format(idx) for idx in range(10)]\n",
    "query = '&'.join(query_list)\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_clf__alpha</th>\n",
       "      <th>param_clf__gamma</th>\n",
       "      <th>param_clf__lambda</th>\n",
       "      <th>param_clf__learning_rate</th>\n",
       "      <th>param_clf__max_delta_step</th>\n",
       "      <th>param_clf__max_depth</th>\n",
       "      <th>param_clf__min_child_weight</th>\n",
       "      <th>param_clf__scale_pos_weight</th>\n",
       "      <th>param_pca__n_components</th>\n",
       "      <th>param_pca__whiten</th>\n",
       "      <th>param_poly</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6158</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>FunctionTransformer(accept_sparse=False, check...</td>\n",
       "      <td>{'clf__alpha': 3, 'clf__gamma': 3, 'clf__lambd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     param_clf__alpha param_clf__gamma param_clf__lambda  \\\n",
       "6158                3                3                 5   \n",
       "\n",
       "     param_clf__learning_rate param_clf__max_delta_step param_clf__max_depth  \\\n",
       "6158                     0.01                         3                   10   \n",
       "\n",
       "     param_clf__min_child_weight param_clf__scale_pos_weight  \\\n",
       "6158                           3                           4   \n",
       "\n",
       "     param_pca__n_components param_pca__whiten  \\\n",
       "6158                       2             False   \n",
       "\n",
       "                                             param_poly  \\\n",
       "6158  FunctionTransformer(accept_sparse=False, check...   \n",
       "\n",
       "                                                 params  \n",
       "6158  {'clf__alpha': 3, 'clf__gamma': 3, 'clf__lambd...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.query(query).loc[:,'param_clf__alpha':'params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.validation import check_is_fitted, FLOAT_DTYPES\n",
    "from sklearn.utils import check_array\n",
    "class PLSRegressionPatch(PLSRegression):\n",
    "    def transform(self, X, Y=None, copy=True):\n",
    "        \"\"\"Apply the dimension reduction learned on the train data.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of predictors.\n",
    "        Y : array-like of shape (n_samples, n_targets)\n",
    "            Target vectors, where n_samples is the number of samples and\n",
    "            n_targets is the number of response variables.\n",
    "        copy : boolean, default True\n",
    "            Whether to copy X and Y, or perform in-place normalization.\n",
    "        Returns\n",
    "        -------\n",
    "        x_scores\n",
    "        \"\"\"\n",
    "        check_is_fitted(self)\n",
    "        X = check_array(X, copy=copy, dtype=FLOAT_DTYPES)\n",
    "        # Normalize\n",
    "        X -= self.x_mean_\n",
    "        X /= self.x_std_\n",
    "        # Apply rotation\n",
    "        x_scores = np.dot(X, self.x_rotations_)\n",
    "\n",
    "        return x_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=32)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 118 out of 120 | elapsed:  6.8min remaining:    6.9s\n",
      "[Parallel(n_jobs=32)]: Done 120 out of 120 | elapsed:  6.9min finished\n",
      "/home/jdkent/.conda/envs/comfy_pants/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:2357: UserWarning: n_quantiles (1000) is greater than the total number of samples (78). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_pca__n_components</th>\n",
       "      <th>param_rfe__n_features_to_select</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74.722818</td>\n",
       "      <td>1.181262</td>\n",
       "      <td>9.109651</td>\n",
       "      <td>2.796960</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>{'pca__n_components': 20, 'rfe__n_features_to_...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.913949</td>\n",
       "      <td>0.928442</td>\n",
       "      <td>0.874094</td>\n",
       "      <td>0.883152</td>\n",
       "      <td>0.835556</td>\n",
       "      <td>0.906087</td>\n",
       "      <td>0.900870</td>\n",
       "      <td>0.895954</td>\n",
       "      <td>0.027727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74.393301</td>\n",
       "      <td>0.582350</td>\n",
       "      <td>9.061412</td>\n",
       "      <td>2.749838</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>{'pca__n_components': 20, 'rfe__n_features_to_...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964674</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.935688</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.943111</td>\n",
       "      <td>0.903478</td>\n",
       "      <td>0.975652</td>\n",
       "      <td>0.950884</td>\n",
       "      <td>0.020650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74.945607</td>\n",
       "      <td>1.926212</td>\n",
       "      <td>9.150441</td>\n",
       "      <td>2.969922</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'pca__n_components': 20, 'rfe__n_features_to_...</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.982790</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.987319</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.998188</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.975652</td>\n",
       "      <td>0.993913</td>\n",
       "      <td>0.984567</td>\n",
       "      <td>0.008757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74.791852</td>\n",
       "      <td>0.979241</td>\n",
       "      <td>9.193043</td>\n",
       "      <td>2.779463</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>{'pca__n_components': 20, 'rfe__n_features_to_...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986413</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.997283</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.995471</td>\n",
       "      <td>0.993778</td>\n",
       "      <td>0.993913</td>\n",
       "      <td>0.997391</td>\n",
       "      <td>0.990175</td>\n",
       "      <td>0.008949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.182175</td>\n",
       "      <td>0.635318</td>\n",
       "      <td>9.160471</td>\n",
       "      <td>2.806414</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>{'pca__n_components': 30, 'rfe__n_features_to_...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.889493</td>\n",
       "      <td>0.870471</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.872283</td>\n",
       "      <td>0.897645</td>\n",
       "      <td>0.872889</td>\n",
       "      <td>0.813913</td>\n",
       "      <td>0.916522</td>\n",
       "      <td>0.880713</td>\n",
       "      <td>0.034133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>75.874876</td>\n",
       "      <td>1.125817</td>\n",
       "      <td>9.339184</td>\n",
       "      <td>2.930225</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>{'pca__n_components': 30, 'rfe__n_features_to_...</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.965580</td>\n",
       "      <td>0.889493</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.922667</td>\n",
       "      <td>0.949565</td>\n",
       "      <td>0.967826</td>\n",
       "      <td>0.944422</td>\n",
       "      <td>0.025360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>74.789283</td>\n",
       "      <td>1.151584</td>\n",
       "      <td>9.199325</td>\n",
       "      <td>2.814991</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>{'pca__n_components': 30, 'rfe__n_features_to_...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.980978</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993659</td>\n",
       "      <td>0.997283</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.989565</td>\n",
       "      <td>0.997391</td>\n",
       "      <td>0.994539</td>\n",
       "      <td>0.005406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>74.161405</td>\n",
       "      <td>0.942984</td>\n",
       "      <td>9.071088</td>\n",
       "      <td>2.786890</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>{'pca__n_components': 30, 'rfe__n_features_to_...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996377</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999111</td>\n",
       "      <td>0.997391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998563</td>\n",
       "      <td>0.001406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>75.145079</td>\n",
       "      <td>1.630866</td>\n",
       "      <td>9.195444</td>\n",
       "      <td>2.793428</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>{'pca__n_components': 50, 'rfe__n_features_to_...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918478</td>\n",
       "      <td>0.886775</td>\n",
       "      <td>0.889493</td>\n",
       "      <td>0.887681</td>\n",
       "      <td>0.888587</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.892174</td>\n",
       "      <td>0.912174</td>\n",
       "      <td>0.888528</td>\n",
       "      <td>0.022243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>73.958490</td>\n",
       "      <td>1.278466</td>\n",
       "      <td>9.102170</td>\n",
       "      <td>2.750459</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>{'pca__n_components': 50, 'rfe__n_features_to_...</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.953804</td>\n",
       "      <td>0.961957</td>\n",
       "      <td>0.943841</td>\n",
       "      <td>0.914855</td>\n",
       "      <td>0.901268</td>\n",
       "      <td>0.966222</td>\n",
       "      <td>0.939130</td>\n",
       "      <td>0.979130</td>\n",
       "      <td>0.941166</td>\n",
       "      <td>0.025256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>73.549148</td>\n",
       "      <td>0.799631</td>\n",
       "      <td>9.031596</td>\n",
       "      <td>2.797023</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>{'pca__n_components': 50, 'rfe__n_features_to_...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999094</td>\n",
       "      <td>0.995471</td>\n",
       "      <td>0.990036</td>\n",
       "      <td>0.998188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994783</td>\n",
       "      <td>0.996952</td>\n",
       "      <td>0.003067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>73.531201</td>\n",
       "      <td>0.650284</td>\n",
       "      <td>9.028420</td>\n",
       "      <td>2.723268</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>{'pca__n_components': 50, 'rfe__n_features_to_...</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999730</td>\n",
       "      <td>0.000578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       74.722818      1.181262         9.109651        2.796960   \n",
       "1       74.393301      0.582350         9.061412        2.749838   \n",
       "2       74.945607      1.926212         9.150441        2.969922   \n",
       "3       74.791852      0.979241         9.193043        2.779463   \n",
       "4       75.182175      0.635318         9.160471        2.806414   \n",
       "5       75.874876      1.125817         9.339184        2.930225   \n",
       "6       74.789283      1.151584         9.199325        2.814991   \n",
       "7       74.161405      0.942984         9.071088        2.786890   \n",
       "8       75.145079      1.630866         9.195444        2.793428   \n",
       "9       73.958490      1.278466         9.102170        2.750459   \n",
       "10      73.549148      0.799631         9.031596        2.797023   \n",
       "11      73.531201      0.650284         9.028420        2.723268   \n",
       "\n",
       "   param_pca__n_components param_rfe__n_features_to_select  \\\n",
       "0                       20                               3   \n",
       "1                       20                               5   \n",
       "2                       20                              10   \n",
       "3                       20                              20   \n",
       "4                       30                               3   \n",
       "5                       30                               5   \n",
       "6                       30                              10   \n",
       "7                       30                              20   \n",
       "8                       50                               3   \n",
       "9                       50                               5   \n",
       "10                      50                              10   \n",
       "11                      50                              20   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'pca__n_components': 20, 'rfe__n_features_to_...           0.600000   \n",
       "1   {'pca__n_components': 20, 'rfe__n_features_to_...           1.000000   \n",
       "2   {'pca__n_components': 20, 'rfe__n_features_to_...           0.466667   \n",
       "3   {'pca__n_components': 20, 'rfe__n_features_to_...           0.600000   \n",
       "4   {'pca__n_components': 30, 'rfe__n_features_to_...           0.400000   \n",
       "5   {'pca__n_components': 30, 'rfe__n_features_to_...           0.733333   \n",
       "6   {'pca__n_components': 30, 'rfe__n_features_to_...           0.800000   \n",
       "7   {'pca__n_components': 30, 'rfe__n_features_to_...           0.666667   \n",
       "8   {'pca__n_components': 50, 'rfe__n_features_to_...           0.266667   \n",
       "9   {'pca__n_components': 50, 'rfe__n_features_to_...           0.733333   \n",
       "10  {'pca__n_components': 50, 'rfe__n_features_to_...           0.600000   \n",
       "11  {'pca__n_components': 50, 'rfe__n_features_to_...           0.466667   \n",
       "\n",
       "    split1_test_score  split2_test_score  ...  split2_train_score  \\\n",
       "0            0.400000           0.666667  ...            0.891304   \n",
       "1            0.733333           0.800000  ...            0.964674   \n",
       "2            0.133333           0.666667  ...            0.982790   \n",
       "3            0.466667           0.733333  ...            0.986413   \n",
       "4            0.733333           0.800000  ...            0.889493   \n",
       "5            0.733333           0.666667  ...            0.956522   \n",
       "6            0.466667           0.733333  ...            0.980978   \n",
       "7            0.600000           0.866667  ...            0.998188   \n",
       "8            0.600000           0.800000  ...            0.918478   \n",
       "9            0.600000           0.800000  ...            0.953804   \n",
       "10           0.533333           0.666667  ...            0.999094   \n",
       "11           0.666667           0.733333  ...            1.000000   \n",
       "\n",
       "    split3_train_score  split4_train_score  split5_train_score  \\\n",
       "0             0.913949            0.928442            0.874094   \n",
       "1             0.971014            0.958333            0.935688   \n",
       "2             0.978261            0.987319            0.985507   \n",
       "3             0.978261            0.997283            0.994565   \n",
       "4             0.870471            0.940217            0.872283   \n",
       "5             0.979167            0.965580            0.889493   \n",
       "6             0.994565            1.000000            0.993659   \n",
       "7             1.000000            1.000000            0.996377   \n",
       "8             0.886775            0.889493            0.887681   \n",
       "9             0.961957            0.943841            0.914855   \n",
       "10            0.995471            0.990036            0.998188   \n",
       "11            0.998188            1.000000            1.000000   \n",
       "\n",
       "    split6_train_score  split7_train_score  split8_train_score  \\\n",
       "0             0.883152            0.835556            0.906087   \n",
       "1             0.940217            0.943111            0.903478   \n",
       "2             0.998188            0.989333            0.975652   \n",
       "3             0.995471            0.993778            0.993913   \n",
       "4             0.897645            0.872889            0.813913   \n",
       "5             0.934783            0.922667            0.949565   \n",
       "6             0.997283            0.994667            0.989565   \n",
       "7             1.000000            0.999111            0.997391   \n",
       "8             0.888587            0.888000            0.892174   \n",
       "9             0.901268            0.966222            0.939130   \n",
       "10            1.000000            0.994667            1.000000   \n",
       "11            1.000000            0.999111            1.000000   \n",
       "\n",
       "    split9_train_score  mean_train_score  std_train_score  \n",
       "0             0.900870          0.895954         0.027727  \n",
       "1             0.975652          0.950884         0.020650  \n",
       "2             0.993913          0.984567         0.008757  \n",
       "3             0.997391          0.990175         0.008949  \n",
       "4             0.916522          0.880713         0.034133  \n",
       "5             0.967826          0.944422         0.025360  \n",
       "6             0.997391          0.994539         0.005406  \n",
       "7             1.000000          0.998563         0.001406  \n",
       "8             0.912174          0.888528         0.022243  \n",
       "9             0.979130          0.941166         0.025256  \n",
       "10            0.994783          0.996952         0.003067  \n",
       "11            1.000000          0.999730         0.000578  \n",
       "\n",
       "[12 rows x 32 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ignore residuals\n",
    "\n",
    "fix_outliers = QuantileTransformer(output_distribution='normal')\n",
    "\n",
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "kbest = SelectKBest(k=1000)\n",
    "\n",
    "pca = PCA(whiten=True)\n",
    "n_component_opts = [20, 30, 50]\n",
    "\n",
    "selector = SVC(kernel='linear', class_weight=\"balanced\", cache_size=10000)\n",
    "\n",
    "rfe = RFE(selector)\n",
    "n_features_to_select_opts = [3, 5, 10, 20]\n",
    "\n",
    "clf = SVC(class_weight=\"balanced\", cache_size=10000)\n",
    "\n",
    "grid_params = [\n",
    "    {\n",
    "        \"pca__n_components\": n_component_opts,\n",
    "        \"rfe__n_features_to_select\": n_features_to_select_opts,\n",
    "    }\n",
    "]\n",
    "\n",
    "pipelineN = Pipeline([(\"outlier\", fix_outliers),\n",
    "                      (\"imp\", imputer),\n",
    "                      (\"scaler\", scaler),\n",
    "                      (\"kbest\", kbest),\n",
    "                      (\"pca\", pca),\n",
    "                      (\"rfe\", rfe),\n",
    "                      (\"clf\", clf)])\n",
    "\n",
    "searchN = GridSearchCV(pipelineN, n_jobs=NTHREADS, param_grid=grid_params, \n",
    "                      cv=10, scoring='roc_auc', return_train_score=True, refit=True, verbose=2)\n",
    "searchN.fit(X_train, y_train)\n",
    "cv_dfN = pd.DataFrame(searchN.cv_results_)\n",
    "cv_dfN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_pca__n_components</th>\n",
       "      <th>param_rfe__n_features_to_select</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>{'pca__n_components': 20, 'rfe__n_features_to_...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.140989</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>{'pca__n_components': 20, 'rfe__n_features_to_...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.671667</td>\n",
       "      <td>0.165336</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'pca__n_components': 20, 'rfe__n_features_to_...</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.503333</td>\n",
       "      <td>0.173494</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>{'pca__n_components': 20, 'rfe__n_features_to_...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.183303</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>{'pca__n_components': 30, 'rfe__n_features_to_...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.581667</td>\n",
       "      <td>0.139134</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>{'pca__n_components': 30, 'rfe__n_features_to_...</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.581667</td>\n",
       "      <td>0.179575</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>{'pca__n_components': 30, 'rfe__n_features_to_...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.161107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>{'pca__n_components': 30, 'rfe__n_features_to_...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.142205</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>{'pca__n_components': 50, 'rfe__n_features_to_...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.253996</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>{'pca__n_components': 50, 'rfe__n_features_to_...</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.160555</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>{'pca__n_components': 50, 'rfe__n_features_to_...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.157903</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>{'pca__n_components': 50, 'rfe__n_features_to_...</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.154785</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_pca__n_components param_rfe__n_features_to_select  \\\n",
       "0                       20                               3   \n",
       "1                       20                               5   \n",
       "2                       20                              10   \n",
       "3                       20                              20   \n",
       "4                       30                               3   \n",
       "5                       30                               5   \n",
       "6                       30                              10   \n",
       "7                       30                              20   \n",
       "8                       50                               3   \n",
       "9                       50                               5   \n",
       "10                      50                              10   \n",
       "11                      50                              20   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'pca__n_components': 20, 'rfe__n_features_to_...           0.600000   \n",
       "1   {'pca__n_components': 20, 'rfe__n_features_to_...           1.000000   \n",
       "2   {'pca__n_components': 20, 'rfe__n_features_to_...           0.466667   \n",
       "3   {'pca__n_components': 20, 'rfe__n_features_to_...           0.600000   \n",
       "4   {'pca__n_components': 30, 'rfe__n_features_to_...           0.400000   \n",
       "5   {'pca__n_components': 30, 'rfe__n_features_to_...           0.733333   \n",
       "6   {'pca__n_components': 30, 'rfe__n_features_to_...           0.800000   \n",
       "7   {'pca__n_components': 30, 'rfe__n_features_to_...           0.666667   \n",
       "8   {'pca__n_components': 50, 'rfe__n_features_to_...           0.266667   \n",
       "9   {'pca__n_components': 50, 'rfe__n_features_to_...           0.733333   \n",
       "10  {'pca__n_components': 50, 'rfe__n_features_to_...           0.600000   \n",
       "11  {'pca__n_components': 50, 'rfe__n_features_to_...           0.466667   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.400000           0.666667           0.533333   \n",
       "1            0.733333           0.800000           0.733333   \n",
       "2            0.133333           0.666667           0.666667   \n",
       "3            0.466667           0.733333           0.600000   \n",
       "4            0.733333           0.800000           0.400000   \n",
       "5            0.733333           0.666667           0.600000   \n",
       "6            0.466667           0.733333           0.733333   \n",
       "7            0.600000           0.866667           0.733333   \n",
       "8            0.600000           0.800000           0.666667   \n",
       "9            0.600000           0.800000           0.666667   \n",
       "10           0.533333           0.666667           0.533333   \n",
       "11           0.666667           0.733333           0.533333   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0            0.200000           0.666667           0.533333   \n",
       "1            0.533333           0.533333           0.800000   \n",
       "2            0.266667           0.666667           0.666667   \n",
       "3            0.200000           0.800000           0.466667   \n",
       "4            0.400000           0.666667           0.533333   \n",
       "5            0.133333           0.800000           0.466667   \n",
       "6            0.466667           0.866667           0.666667   \n",
       "7            0.533333           0.800000           0.533333   \n",
       "8            0.200000           0.533333           1.000000   \n",
       "9            0.733333           0.466667           0.400000   \n",
       "10           0.466667           0.666667           0.933333   \n",
       "11           0.400000           0.866667           0.733333   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0            0.500000                0.7                0.5         0.530000   \n",
       "1            0.583333                0.4                0.6         0.671667   \n",
       "2            0.500000                0.5                0.5         0.503333   \n",
       "3            0.666667                0.3                0.7         0.553333   \n",
       "4            0.583333                0.6                0.7         0.581667   \n",
       "5            0.583333                0.5                0.6         0.581667   \n",
       "6            1.000000                0.6                0.6         0.693333   \n",
       "7            0.833333                0.4                0.7         0.666667   \n",
       "8            0.750000                1.0                0.6         0.641667   \n",
       "9            0.666667                1.0                0.6         0.666667   \n",
       "10           0.833333                0.5                0.4         0.613333   \n",
       "11           0.750000                0.7                0.4         0.625000   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.140989               11  \n",
       "1         0.165336                2  \n",
       "2         0.173494               12  \n",
       "3         0.183303               10  \n",
       "4         0.139134                9  \n",
       "5         0.179575                8  \n",
       "6         0.161107                1  \n",
       "7         0.142205                3  \n",
       "8         0.253996                5  \n",
       "9         0.160555                4  \n",
       "10        0.157903                7  \n",
       "11        0.154785                6  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_dfN.loc[:,\"param_pca__n_components\":\"rank_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(split0_test_score > 0.0)&(split1_test_score > 0.0)&(split2_test_score > 0.0)&(split3_test_score > 0.0)&(split4_test_score > 0.0)&(split5_test_score > 0.0)&(split6_test_score > 0.0)&(split7_test_score > 0.0)&(split8_test_score > 0.0)&(split9_test_score > 0.0)'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_list = ['(split{}_test_score > 0.0)'.format(idx) for idx in range(10)]\n",
    "query = '&'.join(query_list)\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"8\" halign=\"left\">rank_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_rfe__n_features_to_select</th>\n",
       "      <th>param_pca__n_components</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">3</th>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.581667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.581667</td>\n",
       "      <td>0.581667</td>\n",
       "      <td>0.581667</td>\n",
       "      <td>0.581667</td>\n",
       "      <td>0.581667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">5</th>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.671667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671667</td>\n",
       "      <td>0.671667</td>\n",
       "      <td>0.671667</td>\n",
       "      <td>0.671667</td>\n",
       "      <td>0.671667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.581667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.581667</td>\n",
       "      <td>0.581667</td>\n",
       "      <td>0.581667</td>\n",
       "      <td>0.581667</td>\n",
       "      <td>0.581667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">10</th>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.503333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.503333</td>\n",
       "      <td>0.503333</td>\n",
       "      <td>0.503333</td>\n",
       "      <td>0.503333</td>\n",
       "      <td>0.503333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">20</th>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        mean_test_score  \\\n",
       "                                                                  count   \n",
       "param_rfe__n_features_to_select param_pca__n_components                   \n",
       "3                               20                                  1.0   \n",
       "                                30                                  1.0   \n",
       "                                50                                  1.0   \n",
       "5                               20                                  1.0   \n",
       "                                30                                  1.0   \n",
       "                                50                                  1.0   \n",
       "10                              20                                  1.0   \n",
       "                                30                                  1.0   \n",
       "                                50                                  1.0   \n",
       "20                              20                                  1.0   \n",
       "                                30                                  1.0   \n",
       "                                50                                  1.0   \n",
       "\n",
       "                                                                       \\\n",
       "                                                             mean std   \n",
       "param_rfe__n_features_to_select param_pca__n_components                 \n",
       "3                               20                       0.530000 NaN   \n",
       "                                30                       0.581667 NaN   \n",
       "                                50                       0.641667 NaN   \n",
       "5                               20                       0.671667 NaN   \n",
       "                                30                       0.581667 NaN   \n",
       "                                50                       0.666667 NaN   \n",
       "10                              20                       0.503333 NaN   \n",
       "                                30                       0.693333 NaN   \n",
       "                                50                       0.613333 NaN   \n",
       "20                              20                       0.553333 NaN   \n",
       "                                30                       0.666667 NaN   \n",
       "                                50                       0.625000 NaN   \n",
       "\n",
       "                                                                             \\\n",
       "                                                              min       25%   \n",
       "param_rfe__n_features_to_select param_pca__n_components                       \n",
       "3                               20                       0.530000  0.530000   \n",
       "                                30                       0.581667  0.581667   \n",
       "                                50                       0.641667  0.641667   \n",
       "5                               20                       0.671667  0.671667   \n",
       "                                30                       0.581667  0.581667   \n",
       "                                50                       0.666667  0.666667   \n",
       "10                              20                       0.503333  0.503333   \n",
       "                                30                       0.693333  0.693333   \n",
       "                                50                       0.613333  0.613333   \n",
       "20                              20                       0.553333  0.553333   \n",
       "                                30                       0.666667  0.666667   \n",
       "                                50                       0.625000  0.625000   \n",
       "\n",
       "                                                                             \\\n",
       "                                                              50%       75%   \n",
       "param_rfe__n_features_to_select param_pca__n_components                       \n",
       "3                               20                       0.530000  0.530000   \n",
       "                                30                       0.581667  0.581667   \n",
       "                                50                       0.641667  0.641667   \n",
       "5                               20                       0.671667  0.671667   \n",
       "                                30                       0.581667  0.581667   \n",
       "                                50                       0.666667  0.666667   \n",
       "10                              20                       0.503333  0.503333   \n",
       "                                30                       0.693333  0.693333   \n",
       "                                50                       0.613333  0.613333   \n",
       "20                              20                       0.553333  0.553333   \n",
       "                                30                       0.666667  0.666667   \n",
       "                                50                       0.625000  0.625000   \n",
       "\n",
       "                                                                   \\\n",
       "                                                              max   \n",
       "param_rfe__n_features_to_select param_pca__n_components             \n",
       "3                               20                       0.530000   \n",
       "                                30                       0.581667   \n",
       "                                50                       0.641667   \n",
       "5                               20                       0.671667   \n",
       "                                30                       0.581667   \n",
       "                                50                       0.666667   \n",
       "10                              20                       0.503333   \n",
       "                                30                       0.693333   \n",
       "                                50                       0.613333   \n",
       "20                              20                       0.553333   \n",
       "                                30                       0.666667   \n",
       "                                50                       0.625000   \n",
       "\n",
       "                                                        rank_test_score        \\\n",
       "                                                                  count  mean   \n",
       "param_rfe__n_features_to_select param_pca__n_components                         \n",
       "3                               20                                  1.0  11.0   \n",
       "                                30                                  1.0   9.0   \n",
       "                                50                                  1.0   5.0   \n",
       "5                               20                                  1.0   2.0   \n",
       "                                30                                  1.0   8.0   \n",
       "                                50                                  1.0   4.0   \n",
       "10                              20                                  1.0  12.0   \n",
       "                                30                                  1.0   1.0   \n",
       "                                50                                  1.0   7.0   \n",
       "20                              20                                  1.0  10.0   \n",
       "                                30                                  1.0   3.0   \n",
       "                                50                                  1.0   6.0   \n",
       "\n",
       "                                                                               \\\n",
       "                                                        std   min   25%   50%   \n",
       "param_rfe__n_features_to_select param_pca__n_components                         \n",
       "3                               20                      NaN  11.0  11.0  11.0   \n",
       "                                30                      NaN   9.0   9.0   9.0   \n",
       "                                50                      NaN   5.0   5.0   5.0   \n",
       "5                               20                      NaN   2.0   2.0   2.0   \n",
       "                                30                      NaN   8.0   8.0   8.0   \n",
       "                                50                      NaN   4.0   4.0   4.0   \n",
       "10                              20                      NaN  12.0  12.0  12.0   \n",
       "                                30                      NaN   1.0   1.0   1.0   \n",
       "                                50                      NaN   7.0   7.0   7.0   \n",
       "20                              20                      NaN  10.0  10.0  10.0   \n",
       "                                30                      NaN   3.0   3.0   3.0   \n",
       "                                50                      NaN   6.0   6.0   6.0   \n",
       "\n",
       "                                                                     \n",
       "                                                          75%   max  \n",
       "param_rfe__n_features_to_select param_pca__n_components              \n",
       "3                               20                       11.0  11.0  \n",
       "                                30                        9.0   9.0  \n",
       "                                50                        5.0   5.0  \n",
       "5                               20                        2.0   2.0  \n",
       "                                30                        8.0   8.0  \n",
       "                                50                        4.0   4.0  \n",
       "10                              20                       12.0  12.0  \n",
       "                                30                        1.0   1.0  \n",
       "                                50                        7.0   7.0  \n",
       "20                              20                       10.0  10.0  \n",
       "                                30                        3.0   3.0  \n",
       "                                50                        6.0   6.0  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k = 1000\n",
    "# n_components = 30 (pca)\n",
    "# features = 5\n",
    "cv_dfN.query(query).loc[:,[\"param_pca__n_components\", 'param_rfe__n_features_to_select', \"mean_test_score\", \"rank_test_score\"]].groupby(['param_rfe__n_features_to_select', \"param_pca__n_components\"]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 26 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=32)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done  98 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=32)]: Done 260 out of 260 | elapsed: 15.1min finished\n",
      "/home/jdkent/.conda/envs/comfy_pants/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:2357: UserWarning: n_quantiles (1000) is greater than the total number of samples (78). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "/home/jdkent/.conda/envs/comfy_pants/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/jdkent/.conda/envs/comfy_pants/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/jdkent/.conda/envs/comfy_pants/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/jdkent/.conda/envs/comfy_pants/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "fix_outliers = QuantileTransformer(output_distribution='normal')\n",
    "\n",
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "kbest = SelectKBest(k=1000)\n",
    "pca = PCA(n_components=30, whiten=True)\n",
    "selector = LinearSVC(class_weight=\"balanced\", max_iter=100000)\n",
    "\n",
    "rfe = RFE(selector, n_features_to_select=10)\n",
    "\n",
    "clf = LinearSVC(class_weight=\"balanced\", max_iter=100000)\n",
    "C_opts = np.logspace(-2, 10, 13)\n",
    "penalty_opts = ['l1', 'l2']\n",
    "dual_opts = [False, True]\n",
    "\n",
    "grid_params = [{\"clf__C\": [c], \"clf__penalty\": [p],\n",
    "                \"clf__dual\": [d],\n",
    "                \"rfe__estimator__C\": [c],\n",
    "                \"rfe__estimator__penalty\": [p],\n",
    "                \"rfe__estimator__dual\": [d],\n",
    "                 } for c, (p, d) in product(C_opts, zip(penalty_opts, dual_opts))]\n",
    "\n",
    "pipelineN = Pipeline([(\"outliers\", fix_outliers),\n",
    "                      (\"imp\", imputer),\n",
    "                      (\"scaler\", scaler),\n",
    "                      (\"kbest\", kbest),\n",
    "                      (\"pca\", pca),\n",
    "                      (\"rfe\", rfe),\n",
    "                      (\"clf\", clf)])\n",
    "\n",
    "searchN = GridSearchCV(pipelineN, n_jobs=NTHREADS, param_grid=grid_params, \n",
    "                      cv=10, scoring='roc_auc', return_train_score=True, refit=True, verbose=2)\n",
    "searchN.fit(X_train, y_train)\n",
    "cv_dfN = pd.DataFrame(searchN.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 100000.0,\n",
       " 'clf__dual': True,\n",
       " 'clf__penalty': 'l2',\n",
       " 'rfe__estimator__C': 100000.0,\n",
       " 'rfe__estimator__dual': True,\n",
       " 'rfe__estimator__penalty': 'l2'}"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchN.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7583333333333333"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchN.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchN.best_index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchN.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean_fit_time                                                              75.6797\n",
       "std_fit_time                                                              0.920301\n",
       "mean_score_time                                                            9.08987\n",
       "std_score_time                                                              2.7377\n",
       "param_clf__C                                                                100000\n",
       "param_clf__dual                                                               True\n",
       "param_clf__penalty                                                              l2\n",
       "param_rfe__estimator__C                                                     100000\n",
       "param_rfe__estimator__dual                                                    True\n",
       "param_rfe__estimator__penalty                                                   l2\n",
       "params                           {'clf__C': 100000.0, 'clf__dual': True, 'clf__...\n",
       "split0_test_score                                                              0.6\n",
       "split1_test_score                                                         0.933333\n",
       "split2_test_score                                                         0.866667\n",
       "split3_test_score                                                         0.866667\n",
       "split4_test_score                                                         0.733333\n",
       "split5_test_score                                                              0.6\n",
       "split6_test_score                                                         0.933333\n",
       "split7_test_score                                                             0.75\n",
       "split8_test_score                                                              0.8\n",
       "split9_test_score                                                              0.5\n",
       "mean_test_score                                                           0.758333\n",
       "std_test_score                                                            0.142838\n",
       "rank_test_score                                                                  1\n",
       "split0_train_score                                                         0.98913\n",
       "split1_train_score                                                        0.848732\n",
       "split2_train_score                                                        0.779891\n",
       "split3_train_score                                                        0.993659\n",
       "split4_train_score                                                        0.910326\n",
       "split5_train_score                                                        0.791667\n",
       "split6_train_score                                                        0.862319\n",
       "split7_train_score                                                           0.936\n",
       "split8_train_score                                                         0.84087\n",
       "split9_train_score                                                               1\n",
       "mean_train_score                                                          0.895259\n",
       "std_train_score                                                          0.0784864\n",
       "Name: 15, dtype: object"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_dfN.iloc[15,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(split0_test_score >= 0.35)&(split1_test_score >= 0.35)&(split2_test_score >= 0.35)&(split3_test_score >= 0.35)&(split4_test_score >= 0.35)&(split5_test_score >= 0.35)&(split6_test_score >= 0.35)&(split7_test_score >= 0.35)&(split8_test_score >= 0.35)&(split9_test_score >= 0.35)'"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_list = ['(split{}_test_score >= 0.35)'.format(idx) for idx in range(10)]\n",
    "query = '&'.join(query_list)\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_clf__C</th>\n",
       "      <th>param_clf__penalty</th>\n",
       "      <th>param_rfe__estimator__C</th>\n",
       "      <th>param_rfe__estimator__penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1e+09</td>\n",
       "      <td>l2</td>\n",
       "      <td>1e+09</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'clf__C': 1000000000.0, 'clf__penalty': 'l2',...</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.623333</td>\n",
       "      <td>0.117426</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_clf__C param_clf__penalty param_rfe__estimator__C  \\\n",
       "23        1e+09                 l2                   1e+09   \n",
       "\n",
       "   param_rfe__estimator__penalty  \\\n",
       "23                            l2   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "23  {'clf__C': 1000000000.0, 'clf__penalty': 'l2',...           0.533333   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "23           0.733333           0.733333           0.533333   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "23                0.6           0.666667                0.4   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "23           0.833333                0.6                0.6         0.623333   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "23        0.117426                6  "
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k = 10000\n",
    "# n_components = 30 (pca)\n",
    "# features = 10\n",
    "# gamma = 0.001\n",
    "# C = 10000\n",
    "cv_dfN.query(query).loc[:,\"param_clf__C\":\"rank_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jdkent/.conda/envs/comfy_pants/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:2357: UserWarning: n_quantiles (1000) is greater than the total number of samples (78). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 1, 1, 0, 1, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 1, 1, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fix_outliers = QuantileTransformer(output_distribution='normal')\n",
    "\n",
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "kbest = SelectKBest(k=1000)\n",
    "pca = PCA(n_components=30, whiten=True)\n",
    "selector = SVC(random_state=42, kernel='linear', C=10000, gamma=0.001,\n",
    "               class_weight=\"balanced\", cache_size=10000)\n",
    "\n",
    "rfe = RFE(selector, n_features_to_select=10)\n",
    "\n",
    "clf = SVC(random_state=42, C=10000, gamma=0.001,\n",
    "          class_weight=\"balanced\", cache_size=10000)\n",
    "\n",
    "pipelineA = Pipeline([(\"outliers\", fix_outliers),\n",
    "                      (\"imp\", imputer),\n",
    "                      (\"scaler\", scaler),\n",
    "                      (\"kbest\", kbest),\n",
    "                      (\"pca\", pca),\n",
    "                      (\"rfe\", rfe),\n",
    "                      (\"clf\", clf)])\n",
    "\n",
    "\n",
    "pipelineA.fit(X_train, y_train)\n",
    "display(pipelineA.score(X_test, y_test))\n",
    "display(pipelineA.predict(X_test))\n",
    "display(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 13 candidates, totalling 130 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=32)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 130 out of 130 | elapsed:  8.4min finished\n",
      "/home/jdkent/.conda/envs/comfy_pants/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:2357: UserWarning: n_quantiles (1000) is greater than the total number of samples (78). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_svc__C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.610638</td>\n",
       "      <td>1.495433</td>\n",
       "      <td>8.989835</td>\n",
       "      <td>2.856752</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'svc__C': 0.01}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74.871129</td>\n",
       "      <td>0.779774</td>\n",
       "      <td>8.956881</td>\n",
       "      <td>2.848534</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'svc__C': 0.1}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75.435579</td>\n",
       "      <td>1.135548</td>\n",
       "      <td>8.938449</td>\n",
       "      <td>2.794049</td>\n",
       "      <td>1</td>\n",
       "      <td>{'svc__C': 1.0}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75.443637</td>\n",
       "      <td>1.107607</td>\n",
       "      <td>8.948240</td>\n",
       "      <td>2.796937</td>\n",
       "      <td>10</td>\n",
       "      <td>{'svc__C': 10.0}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.735338</td>\n",
       "      <td>1.076179</td>\n",
       "      <td>9.028136</td>\n",
       "      <td>2.812481</td>\n",
       "      <td>100</td>\n",
       "      <td>{'svc__C': 100.0}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_svc__C  \\\n",
       "0      75.610638      1.495433         8.989835        2.856752         0.01   \n",
       "1      74.871129      0.779774         8.956881        2.848534          0.1   \n",
       "2      75.435579      1.135548         8.938449        2.794049            1   \n",
       "3      75.443637      1.107607         8.948240        2.796937           10   \n",
       "4      75.735338      1.076179         9.028136        2.812481          100   \n",
       "\n",
       "              params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0   {'svc__C': 0.01}           0.666667           0.733333                0.6   \n",
       "1    {'svc__C': 0.1}           0.666667           0.666667                0.6   \n",
       "2    {'svc__C': 1.0}           0.666667           0.666667                0.6   \n",
       "3   {'svc__C': 10.0}           0.666667           0.666667                0.6   \n",
       "4  {'svc__C': 100.0}           0.666667           0.666667                0.6   \n",
       "\n",
       "   split3_test_score  ...  split2_train_score  split3_train_score  \\\n",
       "0           0.666667  ...                 1.0                 1.0   \n",
       "1           0.600000  ...                 1.0                 1.0   \n",
       "2           0.600000  ...                 1.0                 1.0   \n",
       "3           0.600000  ...                 1.0                 1.0   \n",
       "4           0.600000  ...                 1.0                 1.0   \n",
       "\n",
       "   split4_train_score  split5_train_score  split6_train_score  \\\n",
       "0                 1.0                 1.0                 1.0   \n",
       "1                 1.0                 1.0                 1.0   \n",
       "2                 1.0                 1.0                 1.0   \n",
       "3                 1.0                 1.0                 1.0   \n",
       "4                 1.0                 1.0                 1.0   \n",
       "\n",
       "   split7_train_score  split8_train_score  split9_train_score  \\\n",
       "0                 1.0                 1.0                 1.0   \n",
       "1                 1.0                 1.0                 1.0   \n",
       "2                 1.0                 1.0                 1.0   \n",
       "3                 1.0                 1.0                 1.0   \n",
       "4                 1.0                 1.0                 1.0   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0               1.0              0.0  \n",
       "1               1.0              0.0  \n",
       "2               1.0              0.0  \n",
       "3               1.0              0.0  \n",
       "4               1.0              0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_outliers = QuantileTransformer(output_distribution='normal')\n",
    "\n",
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50,\n",
    "                           random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "kbest = SelectKBest(k=1000)\n",
    "svc = LinearSVC(max_iter=100000, random_state=42, class_weight=\"balanced\")\n",
    "C_opts = np.logspace(-2, 10, 13)\n",
    "\n",
    "grid_params = [\n",
    "    {\n",
    "        \"svc__C\": C_opts,\n",
    "    }\n",
    "]\n",
    "\n",
    "pipelineM = Pipeline([(\"outliers\", fix_outliers),\n",
    "                      (\"imp\", imputer),\n",
    "                      (\"scaler\", scaler),\n",
    "                      (\"kbest\", kbest),\n",
    "                      (\"svc\", svc)])\n",
    "\n",
    "search = GridSearchCV(pipelineM, n_jobs=NTHREADS, param_grid=grid_params, \n",
    "                      cv=10, scoring='roc_auc', error_score='raise', return_train_score=True, refit=True, verbose=2)\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "cv_df = pd.DataFrame(search.cv_results_)\n",
    "cv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666667"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-09, 1.e-08, 1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_opts = np.logspace(-9, -2, 8)\n",
    "C_opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc__C': 0.1}"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 1, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_svc__C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.610638</td>\n",
       "      <td>1.495433</td>\n",
       "      <td>8.989835</td>\n",
       "      <td>2.856752</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'svc__C': 0.01}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74.871129</td>\n",
       "      <td>0.779774</td>\n",
       "      <td>8.956881</td>\n",
       "      <td>2.848534</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'svc__C': 0.1}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75.435579</td>\n",
       "      <td>1.135548</td>\n",
       "      <td>8.938449</td>\n",
       "      <td>2.794049</td>\n",
       "      <td>1</td>\n",
       "      <td>{'svc__C': 1.0}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75.443637</td>\n",
       "      <td>1.107607</td>\n",
       "      <td>8.948240</td>\n",
       "      <td>2.796937</td>\n",
       "      <td>10</td>\n",
       "      <td>{'svc__C': 10.0}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.735338</td>\n",
       "      <td>1.076179</td>\n",
       "      <td>9.028136</td>\n",
       "      <td>2.812481</td>\n",
       "      <td>100</td>\n",
       "      <td>{'svc__C': 100.0}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>75.966204</td>\n",
       "      <td>1.187779</td>\n",
       "      <td>8.989891</td>\n",
       "      <td>2.863570</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'svc__C': 1000.0}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>75.094831</td>\n",
       "      <td>1.122726</td>\n",
       "      <td>8.928848</td>\n",
       "      <td>2.782269</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'svc__C': 10000.0}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>75.248582</td>\n",
       "      <td>1.255887</td>\n",
       "      <td>8.949266</td>\n",
       "      <td>2.838691</td>\n",
       "      <td>100000</td>\n",
       "      <td>{'svc__C': 100000.0}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>74.775562</td>\n",
       "      <td>0.954700</td>\n",
       "      <td>8.941110</td>\n",
       "      <td>2.839880</td>\n",
       "      <td>1e+06</td>\n",
       "      <td>{'svc__C': 1000000.0}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>74.819971</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>9.010478</td>\n",
       "      <td>2.871802</td>\n",
       "      <td>1e+07</td>\n",
       "      <td>{'svc__C': 10000000.0}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>74.911218</td>\n",
       "      <td>1.879201</td>\n",
       "      <td>9.032036</td>\n",
       "      <td>2.872232</td>\n",
       "      <td>1e+08</td>\n",
       "      <td>{'svc__C': 100000000.0}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>74.669030</td>\n",
       "      <td>1.004048</td>\n",
       "      <td>9.053399</td>\n",
       "      <td>2.925428</td>\n",
       "      <td>1e+09</td>\n",
       "      <td>{'svc__C': 1000000000.0}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>74.547795</td>\n",
       "      <td>1.601321</td>\n",
       "      <td>9.063745</td>\n",
       "      <td>2.800837</td>\n",
       "      <td>1e+10</td>\n",
       "      <td>{'svc__C': 10000000000.0}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_svc__C  \\\n",
       "0       75.610638      1.495433         8.989835        2.856752         0.01   \n",
       "1       74.871129      0.779774         8.956881        2.848534          0.1   \n",
       "2       75.435579      1.135548         8.938449        2.794049            1   \n",
       "3       75.443637      1.107607         8.948240        2.796937           10   \n",
       "4       75.735338      1.076179         9.028136        2.812481          100   \n",
       "5       75.966204      1.187779         8.989891        2.863570         1000   \n",
       "6       75.094831      1.122726         8.928848        2.782269        10000   \n",
       "7       75.248582      1.255887         8.949266        2.838691       100000   \n",
       "8       74.775562      0.954700         8.941110        2.839880        1e+06   \n",
       "9       74.819971      1.085796         9.010478        2.871802        1e+07   \n",
       "10      74.911218      1.879201         9.032036        2.872232        1e+08   \n",
       "11      74.669030      1.004048         9.053399        2.925428        1e+09   \n",
       "12      74.547795      1.601321         9.063745        2.800837        1e+10   \n",
       "\n",
       "                       params  split0_test_score  split1_test_score  \\\n",
       "0            {'svc__C': 0.01}           0.666667           0.733333   \n",
       "1             {'svc__C': 0.1}           0.666667           0.666667   \n",
       "2             {'svc__C': 1.0}           0.666667           0.666667   \n",
       "3            {'svc__C': 10.0}           0.666667           0.666667   \n",
       "4           {'svc__C': 100.0}           0.666667           0.666667   \n",
       "5          {'svc__C': 1000.0}           0.666667           0.666667   \n",
       "6         {'svc__C': 10000.0}           0.666667           0.666667   \n",
       "7        {'svc__C': 100000.0}           0.666667           0.666667   \n",
       "8       {'svc__C': 1000000.0}           0.666667           0.666667   \n",
       "9      {'svc__C': 10000000.0}           0.666667           0.666667   \n",
       "10    {'svc__C': 100000000.0}           0.666667           0.666667   \n",
       "11   {'svc__C': 1000000000.0}           0.666667           0.666667   \n",
       "12  {'svc__C': 10000000000.0}           0.666667           0.666667   \n",
       "\n",
       "    split2_test_score  split3_test_score  ...  split2_train_score  \\\n",
       "0                 0.6           0.666667  ...                 1.0   \n",
       "1                 0.6           0.600000  ...                 1.0   \n",
       "2                 0.6           0.600000  ...                 1.0   \n",
       "3                 0.6           0.600000  ...                 1.0   \n",
       "4                 0.6           0.600000  ...                 1.0   \n",
       "5                 0.6           0.600000  ...                 1.0   \n",
       "6                 0.6           0.600000  ...                 1.0   \n",
       "7                 0.6           0.600000  ...                 1.0   \n",
       "8                 0.6           0.600000  ...                 1.0   \n",
       "9                 0.6           0.600000  ...                 1.0   \n",
       "10                0.6           0.600000  ...                 1.0   \n",
       "11                0.6           0.600000  ...                 1.0   \n",
       "12                0.6           0.600000  ...                 1.0   \n",
       "\n",
       "    split3_train_score  split4_train_score  split5_train_score  \\\n",
       "0                  1.0                 1.0                 1.0   \n",
       "1                  1.0                 1.0                 1.0   \n",
       "2                  1.0                 1.0                 1.0   \n",
       "3                  1.0                 1.0                 1.0   \n",
       "4                  1.0                 1.0                 1.0   \n",
       "5                  1.0                 1.0                 1.0   \n",
       "6                  1.0                 1.0                 1.0   \n",
       "7                  1.0                 1.0                 1.0   \n",
       "8                  1.0                 1.0                 1.0   \n",
       "9                  1.0                 1.0                 1.0   \n",
       "10                 1.0                 1.0                 1.0   \n",
       "11                 1.0                 1.0                 1.0   \n",
       "12                 1.0                 1.0                 1.0   \n",
       "\n",
       "    split6_train_score  split7_train_score  split8_train_score  \\\n",
       "0                  1.0                 1.0                 1.0   \n",
       "1                  1.0                 1.0                 1.0   \n",
       "2                  1.0                 1.0                 1.0   \n",
       "3                  1.0                 1.0                 1.0   \n",
       "4                  1.0                 1.0                 1.0   \n",
       "5                  1.0                 1.0                 1.0   \n",
       "6                  1.0                 1.0                 1.0   \n",
       "7                  1.0                 1.0                 1.0   \n",
       "8                  1.0                 1.0                 1.0   \n",
       "9                  1.0                 1.0                 1.0   \n",
       "10                 1.0                 1.0                 1.0   \n",
       "11                 1.0                 1.0                 1.0   \n",
       "12                 1.0                 1.0                 1.0   \n",
       "\n",
       "    split9_train_score  mean_train_score  std_train_score  \n",
       "0                  1.0               1.0              0.0  \n",
       "1                  1.0               1.0              0.0  \n",
       "2                  1.0               1.0              0.0  \n",
       "3                  1.0               1.0              0.0  \n",
       "4                  1.0               1.0              0.0  \n",
       "5                  1.0               1.0              0.0  \n",
       "6                  1.0               1.0              0.0  \n",
       "7                  1.0               1.0              0.0  \n",
       "8                  1.0               1.0              0.0  \n",
       "9                  1.0               1.0              0.0  \n",
       "10                 1.0               1.0              0.0  \n",
       "11                 1.0               1.0              0.0  \n",
       "12                 1.0               1.0              0.0  \n",
       "\n",
       "[13 rows x 31 columns]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_svc__C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>{'svc__C': 0.01}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.199025</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>{'svc__C': 0.1}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.171270</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>{'svc__C': 1.0}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.171270</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>{'svc__C': 10.0}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.171270</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>{'svc__C': 100.0}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.171270</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000</td>\n",
       "      <td>{'svc__C': 1000.0}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.171270</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10000</td>\n",
       "      <td>{'svc__C': 10000.0}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.171270</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100000</td>\n",
       "      <td>{'svc__C': 100000.0}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.171270</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1e+06</td>\n",
       "      <td>{'svc__C': 1000000.0}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.171270</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1e+07</td>\n",
       "      <td>{'svc__C': 10000000.0}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.171270</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1e+08</td>\n",
       "      <td>{'svc__C': 100000000.0}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.171270</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1e+09</td>\n",
       "      <td>{'svc__C': 1000000000.0}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.171270</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1e+10</td>\n",
       "      <td>{'svc__C': 10000000000.0}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.171270</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_svc__C                     params  split0_test_score  \\\n",
       "0          0.01           {'svc__C': 0.01}           0.666667   \n",
       "1           0.1            {'svc__C': 0.1}           0.666667   \n",
       "2             1            {'svc__C': 1.0}           0.666667   \n",
       "3            10           {'svc__C': 10.0}           0.666667   \n",
       "4           100          {'svc__C': 100.0}           0.666667   \n",
       "5          1000         {'svc__C': 1000.0}           0.666667   \n",
       "6         10000        {'svc__C': 10000.0}           0.666667   \n",
       "7        100000       {'svc__C': 100000.0}           0.666667   \n",
       "8         1e+06      {'svc__C': 1000000.0}           0.666667   \n",
       "9         1e+07     {'svc__C': 10000000.0}           0.666667   \n",
       "10        1e+08    {'svc__C': 100000000.0}           0.666667   \n",
       "11        1e+09   {'svc__C': 1000000000.0}           0.666667   \n",
       "12        1e+10  {'svc__C': 10000000000.0}           0.666667   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.733333                0.6           0.666667   \n",
       "1            0.666667                0.6           0.600000   \n",
       "2            0.666667                0.6           0.600000   \n",
       "3            0.666667                0.6           0.600000   \n",
       "4            0.666667                0.6           0.600000   \n",
       "5            0.666667                0.6           0.600000   \n",
       "6            0.666667                0.6           0.600000   \n",
       "7            0.666667                0.6           0.600000   \n",
       "8            0.666667                0.6           0.600000   \n",
       "9            0.666667                0.6           0.600000   \n",
       "10           0.666667                0.6           0.600000   \n",
       "11           0.666667                0.6           0.600000   \n",
       "12           0.666667                0.6           0.600000   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0            0.466667           0.800000                0.6   \n",
       "1            0.600000           0.866667                0.6   \n",
       "2            0.600000           0.866667                0.6   \n",
       "3            0.600000           0.866667                0.6   \n",
       "4            0.600000           0.866667                0.6   \n",
       "5            0.600000           0.866667                0.6   \n",
       "6            0.600000           0.866667                0.6   \n",
       "7            0.600000           0.866667                0.6   \n",
       "8            0.600000           0.866667                0.6   \n",
       "9            0.600000           0.866667                0.6   \n",
       "10           0.600000           0.866667                0.6   \n",
       "11           0.600000           0.866667                0.6   \n",
       "12           0.600000           0.866667                0.6   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0            0.833333                0.1                0.7         0.616667   \n",
       "1            0.833333                0.2                0.7         0.633333   \n",
       "2            0.833333                0.2                0.7         0.633333   \n",
       "3            0.833333                0.2                0.7         0.633333   \n",
       "4            0.833333                0.2                0.7         0.633333   \n",
       "5            0.833333                0.2                0.7         0.633333   \n",
       "6            0.833333                0.2                0.7         0.633333   \n",
       "7            0.833333                0.2                0.7         0.633333   \n",
       "8            0.833333                0.2                0.7         0.633333   \n",
       "9            0.833333                0.2                0.7         0.633333   \n",
       "10           0.833333                0.2                0.7         0.633333   \n",
       "11           0.833333                0.2                0.7         0.633333   \n",
       "12           0.833333                0.2                0.7         0.633333   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.199025               13  \n",
       "1         0.171270                1  \n",
       "2         0.171270                1  \n",
       "3         0.171270                1  \n",
       "4         0.171270                1  \n",
       "5         0.171270                1  \n",
       "6         0.171270                1  \n",
       "7         0.171270                1  \n",
       "8         0.171270                1  \n",
       "9         0.171270                1  \n",
       "10        0.171270                1  \n",
       "11        0.171270                1  \n",
       "12        0.171270                1  "
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df.loc[:,\"param_svc__C\":\"rank_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean_fit_time                  75.6106\n",
       "std_fit_time                   1.49543\n",
       "mean_score_time                8.98984\n",
       "std_score_time                 2.85675\n",
       "param_svc__C                      0.01\n",
       "params                {'svc__C': 0.01}\n",
       "split0_test_score             0.666667\n",
       "split1_test_score             0.733333\n",
       "split2_test_score                  0.6\n",
       "split3_test_score             0.666667\n",
       "split4_test_score             0.466667\n",
       "split5_test_score                  0.8\n",
       "split6_test_score                  0.6\n",
       "split7_test_score             0.833333\n",
       "split8_test_score                  0.1\n",
       "split9_test_score                  0.7\n",
       "mean_test_score               0.616667\n",
       "std_test_score                0.199025\n",
       "rank_test_score                     13\n",
       "split0_train_score                   1\n",
       "split1_train_score                   1\n",
       "split2_train_score                   1\n",
       "split3_train_score                   1\n",
       "split4_train_score                   1\n",
       "split5_train_score                   1\n",
       "split6_train_score                   1\n",
       "split7_train_score                   1\n",
       "split8_train_score                   1\n",
       "split9_train_score                   1\n",
       "mean_train_score                     1\n",
       "std_train_score                      0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=32)]: Using backend LokyBackend with 32 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-338-657dceeb55f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m search = GridSearchCV(pipeline, n_jobs=NTHREADS, param_grid=grid_params, \n\u001b[1;32m     35\u001b[0m                       cv=10, scoring='roc_auc', error_score='raise', return_train_score=True, refit=True, verbose=2)\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mcv_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/comfy_pants/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/comfy_pants/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/comfy_pants/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/comfy_pants/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/comfy_pants/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/comfy_pants/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/comfy_pants/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/comfy_pants/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fix_outliers = QuantileTransformer(output_distribution='normal')\n",
    "\n",
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50,\n",
    "                           random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "kbest = SelectKBest(k=1000)\n",
    "pca = SparsePCA(n_components=40, random_state=42, max_iter=10000)\n",
    "selector = LogisticRegression(C=1000, class_weight=\"balanced\", random_state=42, max_iter=10000)\n",
    "\n",
    "rfe = RFE(selector, n_features_to_select=10)\n",
    "\n",
    "clf = LogisticRegression(C=1000, class_weight=\"balanced\", random_state=42, max_iter=10000)\n",
    "\n",
    "grid_params = [\n",
    "    {\n",
    "        \"pca__alpha\": [0.001, 0.01, 0.1, 1, 10],\n",
    "        \"pca__ridge_alpha\": [0.001, 0.01, 0.1, 1, 10]\n",
    "    }\n",
    "]\n",
    "pipeline = Pipeline([(\"outliers\", fix_outliers),\n",
    "                      (\"imp\", imputer),\n",
    "                      (\"scaler\", scaler),\n",
    "                      (\"kbest\", kbest),\n",
    "                      (\"pca\", pca),\n",
    "                      (\"rfe\", rfe),\n",
    "                      (\"clf\", clf)])\n",
    "\n",
    "search = GridSearchCV(pipeline, n_jobs=NTHREADS, param_grid=grid_params, \n",
    "                      cv=10, scoring='roc_auc', error_score='raise', return_train_score=True, refit=True, verbose=2)\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "cv_df = pd.DataFrame(search.cv_results_)\n",
    "cv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.30865269,  2.53987089, -1.01127483, -1.53676004, -0.91052725,\n",
       "         1.66863372,  1.30350713,  0.79840086, -0.84838311, -1.01060886]])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.named_steps['clf'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_clf__C</th>\n",
       "      <th>param_rfe__estimator__C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'clf__C': 0.1, 'rfe__estimator__C': 0.1}</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.548333</td>\n",
       "      <td>0.162694</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'clf__C': 1, 'rfe__estimator__C': 1}</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.149676</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'clf__C': 10, 'rfe__estimator__C': 10}</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.635000</td>\n",
       "      <td>0.192995</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>{'clf__C': 50, 'rfe__estimator__C': 50}</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.204294</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'clf__C': 100, 'rfe__estimator__C': 100}</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.204185</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'clf__C': 1000, 'rfe__estimator__C': 1000}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.661667</td>\n",
       "      <td>0.162626</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_clf__C param_rfe__estimator__C  \\\n",
       "0          0.1                     0.1   \n",
       "1            1                       1   \n",
       "2           10                      10   \n",
       "3           50                      50   \n",
       "4          100                     100   \n",
       "5         1000                    1000   \n",
       "\n",
       "                                        params  split0_test_score  \\\n",
       "0    {'clf__C': 0.1, 'rfe__estimator__C': 0.1}           0.600000   \n",
       "1        {'clf__C': 1, 'rfe__estimator__C': 1}           0.466667   \n",
       "2      {'clf__C': 10, 'rfe__estimator__C': 10}           0.466667   \n",
       "3      {'clf__C': 50, 'rfe__estimator__C': 50}           0.466667   \n",
       "4    {'clf__C': 100, 'rfe__estimator__C': 100}           0.466667   \n",
       "5  {'clf__C': 1000, 'rfe__estimator__C': 1000}           0.666667   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.800000           0.533333           0.533333           0.266667   \n",
       "1           0.800000           0.666667           0.666667           0.266667   \n",
       "2           0.800000           0.600000           0.733333           0.333333   \n",
       "3           0.866667           0.600000           0.733333           0.333333   \n",
       "4           0.933333           0.600000           1.000000           0.266667   \n",
       "5           1.000000           0.733333           0.733333           0.333333   \n",
       "\n",
       "   split5_test_score  split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0           0.666667           0.533333           0.750000                0.3   \n",
       "1           0.666667           0.600000           0.750000                0.7   \n",
       "2           0.733333           0.733333           0.750000                0.9   \n",
       "3           0.733333           0.800000           0.750000                0.6   \n",
       "4           0.666667           0.533333           0.583333                0.6   \n",
       "5           0.666667           0.533333           0.750000                0.6   \n",
       "\n",
       "   split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0                0.5         0.548333        0.162694                6  \n",
       "1                0.5         0.608333        0.149676                4  \n",
       "2                0.3         0.635000        0.192995                2  \n",
       "3                0.2         0.608333        0.204294                4  \n",
       "4                0.5         0.615000        0.204185                3  \n",
       "5                0.6         0.661667        0.162626                1  "
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df.loc[:,\"param_clf__C\":\"rank_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 108 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=32)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done  98 tasks      | elapsed:   42.8s\n",
      "[Parallel(n_jobs=32)]: Done 301 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=32)]: Done 584 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=32)]: Done 949 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=32)]: Done 1080 out of 1080 | elapsed:  6.0min finished\n"
     ]
    }
   ],
   "source": [
    "# ignore residuals\n",
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "kbest = SelectKBest(score_func=mutual_info_classif, k=500)\n",
    "pca = PCA(n_components=5, whiten=True)\n",
    "clf = xgboost.XGBRFClassifier(\n",
    "    subsample=0.7, n_estimators=2000, eval_metric='auc',\n",
    "    scale_pos_weight=2, min_child_weight=1)\n",
    "\n",
    "reg_alpha_opts = [0.00005, 0.5, 5]\n",
    "reg_lambda_opts = [0, 0.1]\n",
    "gamma_opts = [0, 1, 5]\n",
    "max_delta_step_opts = [5, 10]\n",
    "max_depth_opts = [5, 10, 20]\n",
    "\n",
    "grid_params = [\n",
    "    {\n",
    "        \"clf__reg_alpha\": reg_alpha_opts,\n",
    "        \"clf__reg_lambda\": reg_lambda_opts,\n",
    "        \"clf__gamma\": gamma_opts,\n",
    "        \"clf__max_delta_steps\": max_delta_step_opts,\n",
    "        \"clf__max_depth\": max_depth_opts,\n",
    "    }\n",
    "]\n",
    "pipelineM = Pipeline([(\"imp\", imputer),\n",
    "                      (\"scaler\", scaler),\n",
    "                      (\"kbest\", kbest),\n",
    "                      (\"pca\", pca),\n",
    "                      (\"clf\", clf)])\n",
    "\n",
    "search = GridSearchCV(pipelineM, n_jobs=NTHREADS, param_grid=grid_params, \n",
    "                      cv=10, scoring='roc_auc', return_train_score=True, verbose=2)\n",
    "search.fit(X_train, y_train)\n",
    "cv_df = pd.DataFrame(search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_clf__gamma</th>\n",
       "      <th>param_clf__max_delta_steps</th>\n",
       "      <th>param_clf__max_depth</th>\n",
       "      <th>param_clf__reg_alpha</th>\n",
       "      <th>param_clf__reg_lambda</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__gamma': 0, 'clf__max_delta_steps': 5, '...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.478333</td>\n",
       "      <td>0.316408</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'clf__gamma': 0, 'clf__max_delta_steps': 5, '...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.252653</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__gamma': 0, 'clf__max_delta_steps': 5, '...</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.486667</td>\n",
       "      <td>0.278568</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'clf__gamma': 0, 'clf__max_delta_steps': 5, '...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.551667</td>\n",
       "      <td>0.216596</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__gamma': 0, 'clf__max_delta_steps': 5, '...</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.285365</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_clf__gamma param_clf__max_delta_steps param_clf__max_depth  \\\n",
       "0                0                          5                    5   \n",
       "1                0                          5                    5   \n",
       "2                0                          5                    5   \n",
       "3                0                          5                    5   \n",
       "4                0                          5                    5   \n",
       "\n",
       "  param_clf__reg_alpha param_clf__reg_lambda  \\\n",
       "0                5e-05                     0   \n",
       "1                5e-05                   0.1   \n",
       "2                  0.5                     0   \n",
       "3                  0.5                   0.1   \n",
       "4                    5                     0   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'clf__gamma': 0, 'clf__max_delta_steps': 5, '...           0.133333   \n",
       "1  {'clf__gamma': 0, 'clf__max_delta_steps': 5, '...           0.800000   \n",
       "2  {'clf__gamma': 0, 'clf__max_delta_steps': 5, '...           0.466667   \n",
       "3  {'clf__gamma': 0, 'clf__max_delta_steps': 5, '...           0.266667   \n",
       "4  {'clf__gamma': 0, 'clf__max_delta_steps': 5, '...           0.466667   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.400000           0.400000           0.666667           0.000000   \n",
       "1           0.666667           0.666667           0.200000           0.066667   \n",
       "2           1.000000           0.133333           0.600000           0.133333   \n",
       "3           0.800000           0.600000           0.200000           0.400000   \n",
       "4           0.733333           0.266667           0.600000           0.333333   \n",
       "\n",
       "   split5_test_score  split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0           0.400000           0.533333           0.250000                1.0   \n",
       "1           0.666667           0.800000           0.500000                0.6   \n",
       "2           0.400000           0.933333           0.500000                0.3   \n",
       "3           0.733333           0.800000           0.416667                0.5   \n",
       "4           0.733333           0.000000           0.166667                1.0   \n",
       "\n",
       "   split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0                1.0         0.478333        0.316408               82  \n",
       "1                0.2         0.516667        0.252653               62  \n",
       "2                0.4         0.486667        0.278568               79  \n",
       "3                0.8         0.551667        0.216596               38  \n",
       "4                0.4         0.470000        0.285365               88  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df.head().loc[:,\"param_clf__gamma\":\"rank_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([51.33206892, 49.29445577, 52.2130971 , 50.38465095, 51.08050036,\n",
       "        51.88531351, 48.74357605, 53.78708291, 47.62354255, 48.18069315]),\n",
       " 'score_time': array([7.8138535 , 4.23292089, 4.00179577, 3.91022038, 3.80355072,\n",
       "        4.21170688, 7.87850285, 3.98289299, 9.00674105, 4.15452933]),\n",
       " 'estimator': (Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                                 interaction_constraints=None, learning_rate=0.01,\n",
       "                                 max_delta_step=3, max_depth=15,\n",
       "                                 min_child_weight=1, missing=nan,\n",
       "                                 monotone_constraints=None, n_estimators=100,\n",
       "                                 n_jobs=0, num_parallel_tree=2500,\n",
       "                                 objective='binary:logistic', random_state=0,\n",
       "                                 reg_alpha=0.5, reg_lambda=6,\n",
       "                                 scale_pos_weight=2.8, subsample=0.6,\n",
       "                                 tree_method=None, validate_parameters=False,\n",
       "                                 verbosity=None))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                                 interaction_constraints=None, learning_rate=0.01,\n",
       "                                 max_delta_step=3, max_depth=15,\n",
       "                                 min_child_weight=1, missing=nan,\n",
       "                                 monotone_constraints=None, n_estimators=100,\n",
       "                                 n_jobs=0, num_parallel_tree=2500,\n",
       "                                 objective='binary:logistic', random_state=0,\n",
       "                                 reg_alpha=0.5, reg_lambda=6,\n",
       "                                 scale_pos_weight=2.8, subsample=0.6,\n",
       "                                 tree_method=None, validate_parameters=False,\n",
       "                                 verbosity=None))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                                 interaction_constraints=None, learning_rate=0.01,\n",
       "                                 max_delta_step=3, max_depth=15,\n",
       "                                 min_child_weight=1, missing=nan,\n",
       "                                 monotone_constraints=None, n_estimators=100,\n",
       "                                 n_jobs=0, num_parallel_tree=2500,\n",
       "                                 objective='binary:logistic', random_state=0,\n",
       "                                 reg_alpha=0.5, reg_lambda=6,\n",
       "                                 scale_pos_weight=2.8, subsample=0.6,\n",
       "                                 tree_method=None, validate_parameters=False,\n",
       "                                 verbosity=None))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                                 interaction_constraints=None, learning_rate=0.01,\n",
       "                                 max_delta_step=3, max_depth=15,\n",
       "                                 min_child_weight=1, missing=nan,\n",
       "                                 monotone_constraints=None, n_estimators=100,\n",
       "                                 n_jobs=0, num_parallel_tree=2500,\n",
       "                                 objective='binary:logistic', random_state=0,\n",
       "                                 reg_alpha=0.5, reg_lambda=6,\n",
       "                                 scale_pos_weight=2.8, subsample=0.6,\n",
       "                                 tree_method=None, validate_parameters=False,\n",
       "                                 verbosity=None))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                                 interaction_constraints=None, learning_rate=0.01,\n",
       "                                 max_delta_step=3, max_depth=15,\n",
       "                                 min_child_weight=1, missing=nan,\n",
       "                                 monotone_constraints=None, n_estimators=100,\n",
       "                                 n_jobs=0, num_parallel_tree=2500,\n",
       "                                 objective='binary:logistic', random_state=0,\n",
       "                                 reg_alpha=0.5, reg_lambda=6,\n",
       "                                 scale_pos_weight=2.8, subsample=0.6,\n",
       "                                 tree_method=None, validate_parameters=False,\n",
       "                                 verbosity=None))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                                 interaction_constraints=None, learning_rate=0.01,\n",
       "                                 max_delta_step=3, max_depth=15,\n",
       "                                 min_child_weight=1, missing=nan,\n",
       "                                 monotone_constraints=None, n_estimators=100,\n",
       "                                 n_jobs=0, num_parallel_tree=2500,\n",
       "                                 objective='binary:logistic', random_state=0,\n",
       "                                 reg_alpha=0.5, reg_lambda=6,\n",
       "                                 scale_pos_weight=2.8, subsample=0.6,\n",
       "                                 tree_method=None, validate_parameters=False,\n",
       "                                 verbosity=None))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                                 interaction_constraints=None, learning_rate=0.01,\n",
       "                                 max_delta_step=3, max_depth=15,\n",
       "                                 min_child_weight=1, missing=nan,\n",
       "                                 monotone_constraints=None, n_estimators=100,\n",
       "                                 n_jobs=0, num_parallel_tree=2500,\n",
       "                                 objective='binary:logistic', random_state=0,\n",
       "                                 reg_alpha=0.5, reg_lambda=6,\n",
       "                                 scale_pos_weight=2.8, subsample=0.6,\n",
       "                                 tree_method=None, validate_parameters=False,\n",
       "                                 verbosity=None))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                                 interaction_constraints=None, learning_rate=0.01,\n",
       "                                 max_delta_step=3, max_depth=15,\n",
       "                                 min_child_weight=1, missing=nan,\n",
       "                                 monotone_constraints=None, n_estimators=100,\n",
       "                                 n_jobs=0, num_parallel_tree=2500,\n",
       "                                 objective='binary:logistic', random_state=0,\n",
       "                                 reg_alpha=0.5, reg_lambda=6,\n",
       "                                 scale_pos_weight=2.8, subsample=0.6,\n",
       "                                 tree_method=None, validate_parameters=False,\n",
       "                                 verbosity=None))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                                 interaction_constraints=None, learning_rate=0.01,\n",
       "                                 max_delta_step=3, max_depth=15,\n",
       "                                 min_child_weight=1, missing=nan,\n",
       "                                 monotone_constraints=None, n_estimators=100,\n",
       "                                 n_jobs=0, num_parallel_tree=2500,\n",
       "                                 objective='binary:logistic', random_state=0,\n",
       "                                 reg_alpha=0.5, reg_lambda=6,\n",
       "                                 scale_pos_weight=2.8, subsample=0.6,\n",
       "                                 tree_method=None, validate_parameters=False,\n",
       "                                 verbosity=None))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                                 interaction_constraints=None, learning_rate=0.01,\n",
       "                                 max_delta_step=3, max_depth=15,\n",
       "                                 min_child_weight=1, missing=nan,\n",
       "                                 monotone_constraints=None, n_estimators=100,\n",
       "                                 n_jobs=0, num_parallel_tree=2500,\n",
       "                                 objective='binary:logistic', random_state=0,\n",
       "                                 reg_alpha=0.5, reg_lambda=6,\n",
       "                                 scale_pos_weight=2.8, subsample=0.6,\n",
       "                                 tree_method=None, validate_parameters=False,\n",
       "                                 verbosity=None))],\n",
       "           verbose=False)),\n",
       " 'test_score': array([0.58333333, 0.93333333, 0.6       , 0.86666667, 0.6       ,\n",
       "        0.4       , 0.66666667, 0.93333333, 1.        , 0.4       ]),\n",
       " 'train_score': array([0.99555556, 0.98641304, 0.97554348, 0.98097826, 0.9990942 ,\n",
       "        0.99184783, 0.97916667, 0.98188406, 0.99217391, 0.98347826])}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MultiDecomp(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_components=None, whiten=False):\n",
    "        self.lda = LinearDiscriminantAnalysis(solver='eigen', shrinkage='auto')\n",
    "        self.pls = PLSSVD(n_components=1)\n",
    "        self.pca = PCA(n_components=n_components, whiten=whiten)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.lda.fit(X, y)\n",
    "        self.pls.fit(X, y)\n",
    "        self.pca.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Since X is a tuple\n",
    "        lda_trans = self.lda.transform(X)\n",
    "        pls_trans = self.pls.transform(X)\n",
    "        pca_trans = self.pca.transform(X)\n",
    "        return np.hstack([lda_trans, pls_trans, pca_trans])\n",
    "\n",
    "class MakeNumpy(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # Since X is a tuple       \n",
    "        if isinstance(X, tuple):\n",
    "            return np.array(X[0])\n",
    "        return X\n",
    "\n",
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "kbest = SelectKBest(k=500)\n",
    "#cca = CCA(n_components=3, max_iter=1000)\n",
    "pls = MultiDecomp()\n",
    "npy = MakeNumpy()\n",
    "poly = PolynomialFeatures(interaction_only=True)\n",
    "#clf = LogisticRegression(penalty='elasticnet',\n",
    "#                         solver='saga', max_iter=1000,\n",
    "#                         class_weight='balanced', l1_ratio=0.25, C=0.1)\n",
    "# clf = KNeighborsClassifier()\n",
    "clf = xgboost.XGBClassifier(\n",
    "    subsample=0.6, num_parallel_tree=2500,\n",
    "    reg_alpha=0.5, reg_lambda=6, gamma=5, learning_rate=0.01,\n",
    "    max_delta_step=3, max_depth=15, min_child_weight=1,\n",
    "    eval_metric='auc',\n",
    "    colsample_bytree=0.5, scale_pos_weight=2.8)\n",
    "\n",
    "pipelineM = Pipeline([(\"imp\", imputer),\n",
    "                      (\"scaler\", scaler),\n",
    "                      (\"kbest\", kbest),\n",
    "                      (\"pls\", pls),\n",
    "#                      (\"npy\", npy),\n",
    "#                      (\"poly\", poly),\n",
    "                      (\"clf\", clf)])\n",
    "cv_results = cross_validate(pipelineM, X_train, y_train, scoring='roc_auc', cv=10, return_train_score=True, return_estimator=True, n_jobs=NTHREADS)\n",
    "cv_results\n",
    "# pipelineM.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['estimator'][9].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiDecomp(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_components=None, whiten=False, lda=True,\n",
    "                 pls=True, pca=True, cca=True,\n",
    "                 pls_can=True, extra_info=None):\n",
    "        self.use_lda = lda\n",
    "        self.use_pls = pls\n",
    "        self.use_pca = pca\n",
    "        self.use_cca = cca\n",
    "        self.use_pls_can = pls_can\n",
    "        self.whiten = whiten\n",
    "        self.n_components = n_components\n",
    "        self.extra_info = extra_info\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if self.extra_info is not None:\n",
    "            y_all = scale(np.hstack([np.atleast_2d(y).T, self.extra_info]))\n",
    "        else:\n",
    "            y_all = np.atleast_2d(y).T\n",
    "        n_components = y_all.shape[1]\n",
    "        if self.use_lda:\n",
    "            self.lda = LinearDiscriminantAnalysis(solver='eigen', shrinkage='auto')\n",
    "            self.lda.fit(X, y)\n",
    "        if self.use_pls:\n",
    "            self.pls = PLSSVD(n_components=n_components)\n",
    "            self.pls.fit(X, y_all)\n",
    "        if self.use_pca:\n",
    "            self.pca = PCA(n_components=self.n_components, whiten=self.whiten)\n",
    "            self.pca.fit(X)\n",
    "        if self.use_cca:\n",
    "            self.cca = CCA(n_components=n_components)\n",
    "            self.cca.fit(X, y_all)\n",
    "        if self.use_pls_can:\n",
    "            self.pls_can = PLSCanonical(n_components=n_components)\n",
    "            self.pls_can.fit(X, y_all)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        features = []\n",
    "        if self.use_lda:\n",
    "            features.append(self.lda.transform(X))\n",
    "        if self.use_pls:\n",
    "            features.append(self.pls.transform(X))\n",
    "        if self.use_pca:\n",
    "            features.append(self.pca.transform(X))\n",
    "        if self.use_cca:\n",
    "            features.append(self.cca.transform(X)[:,1:])\n",
    "        if self.use_pls_can:\n",
    "            features.append(self.pls_can.transform(X)[:,1:])\n",
    "        return np.hstack(features)\n",
    "\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\"lda\": self.use_lda, \n",
    "                \"pls\": self.use_pls,\n",
    "                \"pca\": self.use_pca,\n",
    "                \"whiten\": self.whiten,\n",
    "                \"n_components\": self.n_components,\n",
    "                \"extra_info\": self.extra_info,\n",
    "                \"cca\": self.use_cca,\n",
    "                \"pls_can\": self.pls_can}\n",
    "\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "kbest = SelectKBest(score_func=f_classif, k=500)\n",
    "\n",
    "multi_decomp = MultiDecomp(n_components=2, whiten=True, extra_info=extra_info_train)\n",
    "\n",
    "\n",
    "clf = xgboost.XGBClassifier(\n",
    "    subsample=0.6, num_parallel_tree=2500,\n",
    "    reg_alpha=0.5, reg_lambda=6, gamma=5, learning_rate=0.01,\n",
    "    max_delta_step=3, max_depth=15, min_child_weight=1,\n",
    "    eval_metric='auc',\n",
    "    colsample_bytree=0.5, scale_pos_weight=2.8)\n",
    "# clf = LogisticRegression(class_weight=\"balanced\", C=0.1)\n",
    "# grid_params = [\n",
    "#    {\n",
    "#        'multi_decomp__pca': [True],\n",
    "#        'multi_decomp__lda': [True, False],\n",
    "#        'multi_decomp__pls': [True, False],\n",
    "#        'multi_decomp__cca': [True, False],\n",
    "#        'multi_decomp__n_components': n_components_opts,\n",
    "#        'kbest__score_func': score_func_opts,\n",
    "#    },\n",
    "#    {\n",
    "#        'multi_decomp__pca': [False],\n",
    "#        'multi_decomp__lda': [True],\n",
    "#        'multi_decomp__pls': [True, False],\n",
    "#        'multi_decomp__cca': [True, False],\n",
    "#        'kbest__score_func': score_func_opts,\n",
    "#    },\n",
    "#     {\n",
    "#        'multi_decomp__pca': [False],\n",
    "#        'multi_decomp__lda': [False],\n",
    "#        'multi_decomp__pls': [True],\n",
    "#        'multi_decomp__cca': [True, False],\n",
    "#        'kbest__score_func': score_func_opts,\n",
    "#    },\n",
    "#    {\n",
    "#        'multi_decomp__pca': [False],\n",
    "#        'multi_decomp__lda': [False],\n",
    "#        'multi_decomp__pls': [False],\n",
    "#        'multi_decomp__cca': [True],\n",
    "#        'kbest__score_func': score_func_opts,\n",
    "#    },\n",
    "#]\n",
    "pipelineM = Pipeline([(\"imp\", imputer),\n",
    "                      (\"scaler\", scaler),\n",
    "                      (\"kbest\", kbest),\n",
    "                      ('multi_decomp', multi_decomp),\n",
    "                      (\"clf\", clf)])\n",
    "\n",
    "pipelineM.fit(X_train, y_train)\n",
    "pipelineM.score(X_test, y_test)\n",
    "pipelineM.predict(X_test)\n",
    "#search = GridSearchCV(pipelineM, n_jobs=NTHREADS, param_grid=grid_params, \n",
    "#                      cv=10, scoring='roc_auc', return_train_score=True, verbose=2, refit=False,\n",
    "#                      error_score='raise')\n",
    "#search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipelineM.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelineM.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-205-f9b0b51c425d>(17)fit()\n",
      "-> if self.extra_info is not None:\n",
      "(Pdb) c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.66187188,  3.73715857,  0.10229256,  3.46358889,  0.20880571,\n",
       "        -0.28489108,  0.01906677,  1.48412169,  0.72146724, -0.08242269,\n",
       "         2.25641638,  0.34308615, -0.80252759],\n",
       "       [-2.58030827,  3.89120009,  2.24061014,  2.58966315,  2.91613616,\n",
       "        -0.37873338, -0.14138463,  0.54669105,  0.46772988, -0.22855028,\n",
       "         1.77341496,  1.45960815,  2.17821114],\n",
       "       [-0.57502754,  0.85817117,  0.29798803,  0.0336658 ,  0.43329555,\n",
       "        -0.0801614 , -0.14827825, -0.11660109,  0.21937963,  1.09624337,\n",
       "         0.03298221, -0.09785873,  0.46445983],\n",
       "       [-2.21148556, -1.36297219, -2.15913964,  1.4612184 ,  2.76319254,\n",
       "         0.02763   ,  0.10636872,  0.01712782, -0.79619807, -1.38283462,\n",
       "         3.14297083, -1.60155509,  2.69938532],\n",
       "       [ 0.13087617,  9.97816335,  1.67665553,  3.66966447,  0.28550357,\n",
       "        -0.71203139, -0.11100479,  1.33668004,  0.27730742,  0.13304308,\n",
       "         0.74992275,  0.15169163, -0.9743495 ],\n",
       "       [-2.95096394,  1.20435769,  2.34545011,  0.70845561,  1.30712102,\n",
       "        -0.1603606 , -0.28221295, -0.4822708 ,  2.19739229,  0.15239832,\n",
       "         0.28196835,  1.78613004,  1.09504065],\n",
       "       [ 2.91380157, 10.08910025, -3.36563229,  2.05013032, -0.9692242 ,\n",
       "        -0.55324711, -0.50060357,  1.0301382 , -1.06649936, -0.7406851 ,\n",
       "        -0.03752779, -4.00438806, -1.6835778 ],\n",
       "       [-3.12459674,  0.71276686, -2.41908555,  5.54773682,  2.30319304,\n",
       "        -0.12979458,  0.41825885,  0.86373628, -0.69362696, -0.97802358,\n",
       "         6.02610158, -0.6682993 ,  1.07459052],\n",
       "       [-1.95876434,  2.67073228, -2.02536209,  3.80667693,  0.48961631,\n",
       "        -0.17802815, -0.05774955,  0.14382596, -1.83993733, -0.84290225,\n",
       "         3.29845728, -0.85065613, -0.51011144],\n",
       "       [-3.26698032, -0.72855377, -1.60013706,  4.0745106 ,  2.41852252,\n",
       "        -0.02813718,  0.18892926, -0.10041469, -0.61931712, -1.58313611,\n",
       "         4.82546232,  0.02554285,  1.5661799 ]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "kbest = SelectKBest(k=500)\n",
    "\n",
    "multi_decomp = MultiDecomp(n_components=2, whiten=True, extra_info=extra_info_train)\n",
    "\n",
    "pipeline_test = Pipeline([(\"imp\", imputer),\n",
    "                      (\"scaler\", scaler),\n",
    "                      (\"kbest\", kbest),\n",
    "                      ('multi_decomp', multi_decomp)])\n",
    "pipeline_test.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.87049972,  3.68197138, -1.50138742,  3.80747992,  1.71107789,\n",
       "        -0.274266  , -0.01009178,  1.68752684,  1.06449431, -1.02765228,\n",
       "         3.28018632, -1.0077021 ,  0.70166952],\n",
       "       [-2.93128533,  3.87075431,  2.22594748,  2.62474016,  3.03309475,\n",
       "        -0.37894521, -0.14125886,  0.53671801,  0.50405286, -0.32016155,\n",
       "         1.83773613,  1.46520764,  2.2887131 ],\n",
       "       [ 2.19224159,  5.10923842,  1.79113115,  0.62640391,  1.45707393,\n",
       "        -0.38537681, -0.20491359,  0.3746396 ,  0.29935582, -0.13809477,\n",
       "        -0.61179719,  0.23533211,  1.14945838],\n",
       "       [-1.61891187, -1.51528051, -1.63454223,  2.29807114, -0.90130232,\n",
       "         0.09557766,  0.13412915,  0.9732654 , -1.29929757, -0.27532639,\n",
       "         2.64024603, -0.0454266 , -1.36488329],\n",
       "       [ 0.25908978,  9.94194276,  1.69717607,  3.85116435,  0.36205692,\n",
       "        -0.71039098, -0.09953275,  1.78257302,  0.26521057,  0.44308184,\n",
       "         0.89538989,  0.25940067, -0.95814594],\n",
       "       [-2.84220307,  1.21069343,  2.34999378,  0.69758594,  1.27087786,\n",
       "        -0.16029496, -0.28225193, -0.47918036,  2.18613652,  0.18078685,\n",
       "         0.26203649,  1.78439487,  1.06079827],\n",
       "       [ 2.64185619, 10.07325837, -3.37699327,  2.07730882, -0.87860191,\n",
       "        -0.55341124, -0.50050611,  1.02241086, -1.03835545, -0.81166769,\n",
       "         0.01230979, -4.00004943, -1.59795825],\n",
       "       [-4.37545777,  0.17631643, -1.61575686,  6.32533868,  0.97302179,\n",
       "        -0.12486684,  0.4785255 ,  0.98267462, -1.13206108, -0.72221358,\n",
       "         6.53486295,  0.32355923, -0.44330249],\n",
       "       [-1.57410703,  2.69314007, -2.00929238,  3.76823389,  0.36143422,\n",
       "        -0.17779599, -0.0578874 ,  0.15475602, -1.87974592, -0.74249983,\n",
       "         3.22796376, -0.85679296, -0.63121732],\n",
       "       [-1.64071609, -0.6431282 , -3.20917645,  3.34031815, -1.23101665,\n",
       "         0.05709578,  0.17585589,  0.30700903, -1.5634109 , -0.48419321,\n",
       "         3.69968757, -1.26522261, -1.90844782]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_kbest__score_func</th>\n",
       "      <th>param_multi_decomp__lda</th>\n",
       "      <th>param_multi_decomp__n_components</th>\n",
       "      <th>param_multi_decomp__pca</th>\n",
       "      <th>param_multi_decomp__pls</th>\n",
       "      <th>params</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.719009</td>\n",
       "      <td>2.321320</td>\n",
       "      <td>5.868998</td>\n",
       "      <td>2.141243</td>\n",
       "      <td>&lt;function f_classif at 0x7f34e3969560&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>{'kbest__score_func': &lt;function f_classif at 0...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972826</td>\n",
       "      <td>0.993659</td>\n",
       "      <td>0.973732</td>\n",
       "      <td>0.990036</td>\n",
       "      <td>0.962862</td>\n",
       "      <td>0.971920</td>\n",
       "      <td>0.979130</td>\n",
       "      <td>0.979130</td>\n",
       "      <td>0.978417</td>\n",
       "      <td>0.011875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.683807</td>\n",
       "      <td>2.174572</td>\n",
       "      <td>5.895672</td>\n",
       "      <td>2.163476</td>\n",
       "      <td>&lt;function f_classif at 0x7f34e3969560&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>{'kbest__score_func': &lt;function f_classif at 0...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981884</td>\n",
       "      <td>0.975543</td>\n",
       "      <td>0.980978</td>\n",
       "      <td>0.992754</td>\n",
       "      <td>0.959239</td>\n",
       "      <td>0.974638</td>\n",
       "      <td>0.994783</td>\n",
       "      <td>0.983478</td>\n",
       "      <td>0.981183</td>\n",
       "      <td>0.009599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61.139453</td>\n",
       "      <td>1.874440</td>\n",
       "      <td>5.969408</td>\n",
       "      <td>2.197799</td>\n",
       "      <td>&lt;function f_classif at 0x7f34e3969560&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>{'kbest__score_func': &lt;function f_classif at 0...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983696</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.999094</td>\n",
       "      <td>0.974638</td>\n",
       "      <td>0.998188</td>\n",
       "      <td>0.966957</td>\n",
       "      <td>0.988696</td>\n",
       "      <td>0.987066</td>\n",
       "      <td>0.010472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61.267946</td>\n",
       "      <td>2.346904</td>\n",
       "      <td>6.235975</td>\n",
       "      <td>2.425915</td>\n",
       "      <td>&lt;function f_classif at 0x7f34e3969560&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>{'kbest__score_func': &lt;function f_classif at 0...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959239</td>\n",
       "      <td>0.983696</td>\n",
       "      <td>0.977355</td>\n",
       "      <td>0.974638</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998188</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.968696</td>\n",
       "      <td>0.979309</td>\n",
       "      <td>0.014409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64.694834</td>\n",
       "      <td>2.113907</td>\n",
       "      <td>5.867517</td>\n",
       "      <td>2.179866</td>\n",
       "      <td>&lt;function f_classif at 0x7f34e3969560&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>{'kbest__score_func': &lt;function f_classif at 0...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974638</td>\n",
       "      <td>0.980072</td>\n",
       "      <td>0.972826</td>\n",
       "      <td>0.969203</td>\n",
       "      <td>0.975543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965217</td>\n",
       "      <td>0.993913</td>\n",
       "      <td>0.979923</td>\n",
       "      <td>0.010651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      59.719009      2.321320         5.868998        2.141243   \n",
       "1      59.683807      2.174572         5.895672        2.163476   \n",
       "2      61.139453      1.874440         5.969408        2.197799   \n",
       "3      61.267946      2.346904         6.235975        2.425915   \n",
       "4      64.694834      2.113907         5.867517        2.179866   \n",
       "\n",
       "                  param_kbest__score_func param_multi_decomp__lda  \\\n",
       "0  <function f_classif at 0x7f34e3969560>                    True   \n",
       "1  <function f_classif at 0x7f34e3969560>                    True   \n",
       "2  <function f_classif at 0x7f34e3969560>                    True   \n",
       "3  <function f_classif at 0x7f34e3969560>                    True   \n",
       "4  <function f_classif at 0x7f34e3969560>                    True   \n",
       "\n",
       "  param_multi_decomp__n_components param_multi_decomp__pca  \\\n",
       "0                                2                    True   \n",
       "1                                2                    True   \n",
       "2                                5                    True   \n",
       "3                                5                    True   \n",
       "4                               10                    True   \n",
       "\n",
       "  param_multi_decomp__pls                                             params  \\\n",
       "0                    True  {'kbest__score_func': <function f_classif at 0...   \n",
       "1                   False  {'kbest__score_func': <function f_classif at 0...   \n",
       "2                    True  {'kbest__score_func': <function f_classif at 0...   \n",
       "3                   False  {'kbest__score_func': <function f_classif at 0...   \n",
       "4                    True  {'kbest__score_func': <function f_classif at 0...   \n",
       "\n",
       "   ...  split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0  ...            0.972826            0.993659            0.973732   \n",
       "1  ...            0.981884            0.975543            0.980978   \n",
       "2  ...            1.000000            0.983696            0.979167   \n",
       "3  ...            0.959239            0.983696            0.977355   \n",
       "4  ...            0.974638            0.980072            0.972826   \n",
       "\n",
       "   split5_train_score  split6_train_score  split7_train_score  \\\n",
       "0            0.990036            0.962862            0.971920   \n",
       "1            0.992754            0.959239            0.974638   \n",
       "2            0.999094            0.974638            0.998188   \n",
       "3            0.974638            1.000000            0.998188   \n",
       "4            0.969203            0.975543            1.000000   \n",
       "\n",
       "   split8_train_score  split9_train_score  mean_train_score  std_train_score  \n",
       "0            0.979130            0.979130          0.978417         0.011875  \n",
       "1            0.994783            0.983478          0.981183         0.009599  \n",
       "2            0.966957            0.988696          0.987066         0.010472  \n",
       "3            0.956522            0.968696          0.979309         0.014409  \n",
       "4            0.965217            0.993913          0.979923         0.010651  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df = pd.DataFrame(search.cv_results_)\n",
    "cv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.701667</td>\n",
       "      <td>0.194429</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.196532</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.309570</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.723333</td>\n",
       "      <td>0.183818</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.242579</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.643333</td>\n",
       "      <td>0.208726</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.673333</td>\n",
       "      <td>0.259401</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.623333</td>\n",
       "      <td>0.276506</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.661667</td>\n",
       "      <td>0.246987</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.231805</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.245040</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.197772</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.310125</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.671667</td>\n",
       "      <td>0.273054</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.656667</td>\n",
       "      <td>0.278109</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.543333</td>\n",
       "      <td>0.273272</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.618333</td>\n",
       "      <td>0.242722</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.603333</td>\n",
       "      <td>0.225315</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.296578</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.210924</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.244404</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.252631</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.596667</td>\n",
       "      <td>0.248752</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.311716</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.224598</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.646667</td>\n",
       "      <td>0.240924</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.676667</td>\n",
       "      <td>0.195533</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.237674</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.234189</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.643333</td>\n",
       "      <td>0.235726</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0            0.583333           0.933333           0.866667   \n",
       "1            0.416667           1.000000           0.666667   \n",
       "2            0.833333           1.000000           1.000000   \n",
       "3            0.500000           1.000000           0.666667   \n",
       "4            0.666667           1.000000           0.600000   \n",
       "5            0.500000           0.666667           0.666667   \n",
       "6            0.833333           0.866667           0.800000   \n",
       "7            0.500000           0.933333           0.666667   \n",
       "8            0.916667           1.000000           0.666667   \n",
       "9            0.666667           0.866667           0.666667   \n",
       "10           0.833333           1.000000           0.333333   \n",
       "11           0.750000           0.733333           0.600000   \n",
       "12           1.000000           0.866667           0.000000   \n",
       "13           0.750000           1.000000           0.066667   \n",
       "14           0.833333           0.866667           0.400000   \n",
       "15           0.500000           0.933333           0.400000   \n",
       "16           0.750000           0.800000           0.333333   \n",
       "17           0.500000           1.000000           0.400000   \n",
       "18           0.750000           0.800000           0.000000   \n",
       "19           0.833333           0.933333           0.333333   \n",
       "20           1.000000           1.000000           0.466667   \n",
       "21           0.666667           1.000000           0.333333   \n",
       "22           0.500000           1.000000           0.266667   \n",
       "23           0.833333           1.000000           0.400000   \n",
       "24           0.833333           0.866667           0.866667   \n",
       "25           0.833333           0.866667           0.466667   \n",
       "26           0.500000           1.000000           0.533333   \n",
       "27           0.833333           1.000000           0.533333   \n",
       "28           0.833333           1.000000           0.666667   \n",
       "29           0.833333           0.933333           0.400000   \n",
       "\n",
       "    split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0            0.666667           0.600000           0.600000   \n",
       "1            0.666667           0.600000           0.533333   \n",
       "2            0.333333           0.600000           0.733333   \n",
       "3            0.800000           0.600000           0.800000   \n",
       "4            0.666667           0.533333           0.666667   \n",
       "5            0.533333           0.600000           0.266667   \n",
       "6            0.466667           0.600000           0.466667   \n",
       "7            0.533333           0.600000           0.400000   \n",
       "8            0.600000           0.400000           0.333333   \n",
       "9            0.533333           0.600000           0.400000   \n",
       "10           0.466667           0.600000           0.466667   \n",
       "11           0.533333           0.400000           0.333333   \n",
       "12           0.466667           0.666667           0.600000   \n",
       "13           0.400000           0.800000           0.600000   \n",
       "14           0.533333           0.666667           0.600000   \n",
       "15           0.333333           0.600000           0.466667   \n",
       "16           0.600000           0.666667           0.533333   \n",
       "17           0.466667           0.533333           0.600000   \n",
       "18           0.466667           0.666667           0.600000   \n",
       "19           0.533333           0.666667           0.466667   \n",
       "20           0.600000           0.600000           0.733333   \n",
       "21           0.466667           0.666667           0.600000   \n",
       "22           0.533333           0.600000           0.533333   \n",
       "23           0.333333           0.600000           0.600000   \n",
       "24           0.466667           0.733333           0.466667   \n",
       "25           0.733333           0.533333           0.666667   \n",
       "26           0.733333           0.533333           0.600000   \n",
       "27           0.400000           0.600000           0.400000   \n",
       "28           0.733333           0.400000           0.466667   \n",
       "29           0.533333           0.600000           0.533333   \n",
       "\n",
       "    split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0            0.666667           0.800000                1.0   \n",
       "1            0.733333           0.733333                1.0   \n",
       "2            0.800000           0.866667                1.0   \n",
       "3            0.733333           0.733333                1.0   \n",
       "4            0.733333           0.600000                0.8   \n",
       "5            0.600000           1.000000                1.0   \n",
       "6            0.666667           0.933333                1.0   \n",
       "7            0.800000           0.800000                1.0   \n",
       "8            0.666667           0.733333                1.0   \n",
       "9            0.933333           0.733333                1.0   \n",
       "10           0.800000           0.733333                1.0   \n",
       "11           0.466667           0.733333                1.0   \n",
       "12           0.666667           0.666667                0.9   \n",
       "13           0.800000           0.800000                1.0   \n",
       "14           0.866667           0.800000                1.0   \n",
       "15           0.533333           0.666667                1.0   \n",
       "16           0.800000           0.600000                1.0   \n",
       "17           0.866667           0.666667                0.8   \n",
       "18           0.933333           0.666667                1.0   \n",
       "19           0.866667           0.666667                1.0   \n",
       "20           0.666667           0.666667                1.0   \n",
       "21           0.866667           0.733333                1.0   \n",
       "22           0.666667           0.666667                1.0   \n",
       "23           0.933333           0.800000                1.0   \n",
       "24           0.866667           0.933333                1.0   \n",
       "25           0.533333           0.733333                1.0   \n",
       "26           0.800000           0.666667                1.0   \n",
       "27           0.666667           0.800000                1.0   \n",
       "28           0.800000           0.600000                0.9   \n",
       "29           0.600000           0.800000                1.0   \n",
       "\n",
       "    split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0                 0.3         0.701667        0.194429                4  \n",
       "1                 0.4         0.675000        0.196532                8  \n",
       "2                 0.0         0.716667        0.309570                3  \n",
       "3                 0.4         0.723333        0.183818                2  \n",
       "4                 0.0         0.626667        0.242579               22  \n",
       "5                 0.6         0.643333        0.208726               20  \n",
       "6                 0.1         0.673333        0.259401                9  \n",
       "7                 0.0         0.623333        0.276506               23  \n",
       "8                 0.3         0.661667        0.246987               11  \n",
       "9                 0.2         0.660000        0.231805               12  \n",
       "10                0.3         0.653333        0.245040               17  \n",
       "11                0.4         0.595000        0.197772               28  \n",
       "12                0.1         0.593333        0.310125               29  \n",
       "13                0.5         0.671667        0.273054               10  \n",
       "14                0.0         0.656667        0.278109               14  \n",
       "15                0.0         0.543333        0.273272               30  \n",
       "16                0.1         0.618333        0.242722               24  \n",
       "17                0.2         0.603333        0.225315               26  \n",
       "18                0.2         0.608333        0.296578               25  \n",
       "19                0.5         0.680000        0.210924                6  \n",
       "20                0.2         0.693333        0.244404                5  \n",
       "21                0.2         0.653333        0.252631               15  \n",
       "22                0.2         0.596667        0.248752               27  \n",
       "23                0.0         0.650000        0.311716               18  \n",
       "24                0.3         0.733333        0.224598                1  \n",
       "25                0.1         0.646667        0.240924               19  \n",
       "26                0.4         0.676667        0.195533                7  \n",
       "27                0.3         0.653333        0.237674               16  \n",
       "28                0.2         0.660000        0.234189               12  \n",
       "29                0.2         0.643333        0.235726               20  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df.loc[:,\"split0_test_score\":\"rank_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_decomp = MultiDecomp(whiten=True, n_components=2)\n",
    "pipeline_test = Pipeline([(\"imp\", imputer),\n",
    "                      (\"scaler\", scaler),\n",
    "                      (\"kbest\", kbest),\n",
    "                      ('multi_decomp', multi_decomp)])\n",
    "res = pipeline_test.fit_transform(X_train, y_train)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.77226854e+00,  2.34410157e+00, -1.30564326e-01,\n",
       "        -1.99049527e-01],\n",
       "       [ 5.37215041e+00, -6.43145179e+00, -1.07527088e-01,\n",
       "         1.26698541e+00],\n",
       "       [-1.70227311e+00,  4.51088788e+00, -3.25522879e-01,\n",
       "        -2.77525109e-01],\n",
       "       [ 5.20576702e+00, -1.62487405e+01,  8.56401120e-01,\n",
       "         1.70372071e+00],\n",
       "       [-1.90995134e+00, -1.43835767e+00,  2.88508885e-01,\n",
       "        -8.00984033e-01],\n",
       "       [-1.61550809e+00, -1.02501808e+00,  2.06362828e-01,\n",
       "        -5.30854177e-01],\n",
       "       [-2.50162186e+00,  3.47238647e+00, -3.56027254e-01,\n",
       "         3.65518731e-01],\n",
       "       [ 3.79520435e+00, -8.05805671e+00,  5.25848349e-01,\n",
       "         2.83138753e-01],\n",
       "       [ 3.90626059e+00, -1.90896025e+00,  2.55484605e-02,\n",
       "        -8.86599682e-02],\n",
       "       [ 4.15738901e+00, -7.57764505e+00,  1.32795631e-01,\n",
       "         2.10339356e+00],\n",
       "       [ 4.20376552e+00,  5.21839565e+00, -3.93105865e-01,\n",
       "        -2.93032943e-01],\n",
       "       [-2.34175050e+00,  6.27824668e+00, -2.80920944e-01,\n",
       "        -3.37368868e-01],\n",
       "       [ 4.04772232e+00,  6.39110283e+00, -5.56551226e-01,\n",
       "        -1.83561226e-01],\n",
       "       [ 4.65129327e+00,  5.48857079e+00, -9.13977905e-01,\n",
       "         2.25798070e+00],\n",
       "       [-2.31177833e+00,  7.02500247e+00, -4.16634622e-01,\n",
       "        -2.10015195e-01],\n",
       "       [ 4.72882557e+00,  1.07178036e+00, -7.17546390e-01,\n",
       "         2.52357775e+00],\n",
       "       [-2.31846188e+00,  3.83421270e+00, -1.16945084e-01,\n",
       "        -4.49438001e-01],\n",
       "       [ 3.71353172e+00,  8.57446726e+00, -6.68791623e-01,\n",
       "        -1.75175292e-01],\n",
       "       [ 4.95001861e+00, -2.42683677e-01, -9.61594119e-02,\n",
       "         6.73596053e-03],\n",
       "       [-2.10300523e+00,  8.71209767e+00, -5.14678414e-01,\n",
       "        -6.84919342e-01],\n",
       "       [-2.43332756e+00,  6.23135832e+00, -3.27396892e-01,\n",
       "        -5.30590519e-01],\n",
       "       [-2.36695146e+00,  4.27106042e+00, -2.56457499e-01,\n",
       "        -3.31031612e-01],\n",
       "       [-2.62123606e+00, -8.50330875e+00,  9.21855373e-01,\n",
       "        -8.10524598e-01],\n",
       "       [-2.81584131e+00,  4.40196837e+00, -9.63391549e-02,\n",
       "        -6.37433584e-01],\n",
       "       [ 4.51846380e+00, -9.85897834e+00,  6.14287403e-01,\n",
       "         6.72927895e-02],\n",
       "       [ 4.64485108e+00, -1.05434567e+00, -9.77659622e-02,\n",
       "         2.19304395e-01],\n",
       "       [-3.20463464e+00,  8.02487947e+00, -1.70437439e-01,\n",
       "        -1.34597981e+00],\n",
       "       [-2.58741583e+00,  6.69505376e+00, -2.14350749e-01,\n",
       "        -1.12184810e+00],\n",
       "       [-1.91047439e+00,  6.90673514e+00, -2.93174945e-01,\n",
       "        -8.89853222e-01],\n",
       "       [-2.27553233e+00,  1.13713590e+00, -2.75550632e-02,\n",
       "        -1.31053490e-01],\n",
       "       [-2.84796640e+00,  3.38769651e+00,  3.29435416e-03,\n",
       "        -7.43825993e-01],\n",
       "       [ 3.24370331e+00, -7.43535952e+00,  6.32476417e-01,\n",
       "        -2.43079390e-01],\n",
       "       [-1.85447322e+00,  7.63156650e+00, -6.04385299e-01,\n",
       "        -7.29471074e-02],\n",
       "       [-3.00815284e+00,  6.53437907e+00, -3.36899891e-01,\n",
       "        -3.74373715e-01],\n",
       "       [-2.10529373e+00, -8.19262142e+00,  7.18732981e-01,\n",
       "        -1.46707872e-01],\n",
       "       [-1.89652665e+00,  6.18752097e-01,  3.37467875e-02,\n",
       "        -3.33362635e-01],\n",
       "       [ 3.64483894e+00,  9.39009509e-01, -5.97141613e-02,\n",
       "        -8.48982204e-02],\n",
       "       [-2.10657321e+00,  7.28352948e+00, -5.42016464e-01,\n",
       "        -4.57217472e-02],\n",
       "       [-2.81679339e+00, -2.29580428e+00,  4.66662646e-01,\n",
       "        -9.94605111e-01],\n",
       "       [-1.59496584e+00,  2.48446345e+00, -1.46128927e-01,\n",
       "        -4.30396950e-01],\n",
       "       [ 4.36255458e+00, -6.99120173e+00,  4.05223001e-01,\n",
       "         6.66745850e-02],\n",
       "       [-2.62675268e+00,  1.02097937e+01, -6.31796560e-01,\n",
       "        -7.65303479e-01],\n",
       "       [-2.28362865e+00, -1.01377454e+01,  9.88467704e-01,\n",
       "        -4.94131536e-01],\n",
       "       [ 4.59523626e+00, -7.04814979e+00,  3.83191686e-01,\n",
       "         2.81167401e-01],\n",
       "       [-1.94103126e+00, -9.08943409e+00,  1.73937344e-01,\n",
       "         2.90048637e+00],\n",
       "       [ 4.16036448e+00,  4.28335226e+00, -4.58958167e-01,\n",
       "        -9.33733990e-02],\n",
       "       [-1.98578066e+00,  8.86166829e+00, -7.42984776e-01,\n",
       "         1.63155638e-01],\n",
       "       [-2.59182082e+00, -3.72200837e+00,  6.00210808e-01,\n",
       "        -1.24125935e+00],\n",
       "       [ 4.86882097e+00,  9.45239889e-01, -6.75189504e-01,\n",
       "         2.67046725e+00],\n",
       "       [-2.25797765e+00,  6.22506157e-01,  9.54642034e-02,\n",
       "        -4.70916551e-01],\n",
       "       [ 5.12581484e+00, -2.62462798e+00, -1.97232359e-01,\n",
       "         8.42698775e-01],\n",
       "       [-2.17108195e+00,  4.78036357e+00, -2.20724051e-01,\n",
       "        -5.23231601e-01],\n",
       "       [ 5.91914561e+00, -3.39916728e+01,  2.33132578e+00,\n",
       "         7.80716381e-01],\n",
       "       [-2.91499356e+00, -2.91214374e+00,  3.91159980e-01,\n",
       "        -5.97914497e-01],\n",
       "       [-3.12981537e+00,  1.47627366e+01, -1.00299519e+00,\n",
       "        -4.22132160e-01],\n",
       "       [-2.59941844e+00,  7.15584044e+00, -1.78662151e-01,\n",
       "        -1.56336332e+00],\n",
       "       [-2.46094236e+00,  1.19063894e+01, -8.26717912e-01,\n",
       "        -3.13621924e-01],\n",
       "       [ 3.90492830e+00,  4.10877377e+00, -7.47971116e-01,\n",
       "         2.01901767e+00],\n",
       "       [-2.31268915e+00,  6.67491983e+00, -6.64561045e-01,\n",
       "         1.14862469e+00],\n",
       "       [-2.73934135e+00,  6.07856058e+00, -2.08006430e-01,\n",
       "        -6.03536299e-01],\n",
       "       [-2.16656169e+00,  1.79589756e+01, -1.65123151e+00,\n",
       "         1.63616132e+00],\n",
       "       [-2.20714924e+00, -5.62775307e+00,  5.12063186e-01,\n",
       "        -5.18320912e-01],\n",
       "       [-2.26993775e+00,  1.38585580e+01, -8.18737964e-01,\n",
       "        -1.04069551e+00],\n",
       "       [ 3.76890412e+00, -1.23557694e+01,  9.03516626e-01,\n",
       "         1.49717912e-02],\n",
       "       [-2.03394616e+00,  1.50493097e+00, -1.88431013e-01,\n",
       "         4.46904315e-01],\n",
       "       [-2.94835438e+00,  4.21549355e+00, -2.42542736e-01,\n",
       "         1.89872281e-01],\n",
       "       [-2.70413630e+00,  5.95298152e+00, -2.32300188e-01,\n",
       "        -8.13327609e-01],\n",
       "       [ 4.82771665e+00, -2.51100750e+01,  1.78988259e+00,\n",
       "         3.83312898e-01],\n",
       "       [-2.66941246e+00,  1.14652508e+01, -3.13962338e-01,\n",
       "        -2.53313544e+00],\n",
       "       [ 5.57595751e+00, -8.89026819e+01,  6.92106537e+00,\n",
       "         7.71386625e-01],\n",
       "       [-2.50129983e+00,  4.21713832e+00, -3.25160498e-01,\n",
       "         1.43922739e-01],\n",
       "       [-1.81451744e+00,  4.61836496e+00, -8.20454897e-01,\n",
       "         2.22484237e+00],\n",
       "       [-1.79033610e+00, -5.98843476e+00,  4.97783443e-01,\n",
       "        -2.78055706e-01],\n",
       "       [ 4.56513517e+00,  1.41477797e+00, -2.02186970e-01,\n",
       "        -3.28266458e-01],\n",
       "       [-2.50576566e+00,  5.07648966e+00, -2.37365331e-01,\n",
       "        -7.06087816e-01],\n",
       "       [-2.52542321e+00,  9.99044333e+00, -7.13077411e-01,\n",
       "        -4.84731126e-01],\n",
       "       [-2.44967460e+00,  1.78776614e+00, -1.55242861e-01,\n",
       "         2.35608375e-01],\n",
       "       [ 3.16620245e+00,  2.85287423e+00, -1.95744491e-01,\n",
       "        -4.27418190e-01]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=True),\n",
       "       FeatureUnion(n_jobs=None,\n",
       "             transformer_list=[('pca',\n",
       "                                PCA(copy=True, iterated_power='auto',\n",
       "                                    n_components=None, random_state=None,\n",
       "                                    svd_solver='auto', tol=0.0, whiten=True)),\n",
       "                               ('lda',\n",
       "                                LinearDiscriminantAnalysis(n_components=None,\n",
       "                                                           priors=None,\n",
       "                                                           shrinkage='auto',\n",
       "                                                           solver='eigen',\n",
       "                                                           store_covariance=False,\n",
       "                                                           tol=0.0001))],\n",
       "             transformer_weights=None, verbose=False),\n",
       "       FeatureUnion(n_jobs=None,\n",
       "             transformer_list=[('pca',\n",
       "                                PCA(copy=True, iterated_power='auto',\n",
       "                                    n_components=None, random_state=None,\n",
       "                                    svd_solver='auto', tol=0.0, whiten=True)),\n",
       "                               ('lda',\n",
       "                                LinearDiscriminantAnalysis(n_components=None,\n",
       "                                                           priors=None,\n",
       "                                                           shrinkage='auto',\n",
       "                                                           solver='eigen',\n",
       "                                                           store_covariance=False,\n",
       "                                                           tol=0.0001)),\n",
       "                               ('pls',\n",
       "                                PLSSVD(copy=True, n_components=1, scale=True))],\n",
       "             transformer_weights=None, verbose=False),\n",
       "       FeatureUnion(n_jobs=None,\n",
       "             transformer_list=[('lda',\n",
       "                                LinearDiscriminantAnalysis(n_components=None,\n",
       "                                                           priors=None,\n",
       "                                                           shrinkage='auto',\n",
       "                                                           solver='eigen',\n",
       "                                                           store_covariance=False,\n",
       "                                                           tol=0.0001)),\n",
       "                               ('pls',\n",
       "                                PLSSVD(copy=True, n_components=1, scale=True))],\n",
       "             transformer_weights=None, verbose=False)], dtype=object)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df['param_dimred'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureUnion(n_jobs=None,\n",
       "             transformer_list=[('pca',\n",
       "                                PCA(copy=True, iterated_power='auto',\n",
       "                                    n_components=None, random_state=None,\n",
       "                                    svd_solver='auto', tol=0.0, whiten=True)),\n",
       "                               ('lda',\n",
       "                                LinearDiscriminantAnalysis(n_components=None,\n",
       "                                                           priors=None,\n",
       "                                                           shrinkage='auto',\n",
       "                                                           solver='eigen',\n",
       "                                                           store_covariance=False,\n",
       "                                                           tol=0.0001)),\n",
       "                               ('pls',\n",
       "                                PLSSVD(copy=True, n_components=1, scale=True))],\n",
       "             transformer_weights=None, verbose=False)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df.loc[12,'param_dimred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df.loc[:,\"param_dimred\":\"rank_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=32)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done  98 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=32)]: Done 360 out of 360 | elapsed: 46.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('imp',\n",
       "                                        IterativeImputer(add_indicator=False,\n",
       "                                                         estimator=None,\n",
       "                                                         imputation_order='random',\n",
       "                                                         initial_strategy='median',\n",
       "                                                         max_iter=10,\n",
       "                                                         max_value=None,\n",
       "                                                         min_value=None,\n",
       "                                                         missing_values=nan,\n",
       "                                                         n_nearest_features=50,\n",
       "                                                         random_state=None,\n",
       "                                                         sample_posterior=True,\n",
       "                                                         skip_complete=False,\n",
       "                                                         tol=0.001,\n",
       "                                                         verbose=0)),\n",
       "                                       (...\n",
       "                                                                    ('lda',\n",
       "                                                                     LinearDiscriminantAnalysis(n_components=None,\n",
       "                                                                                                priors=None,\n",
       "                                                                                                shrinkage='auto',\n",
       "                                                                                                solver='eigen',\n",
       "                                                                                                store_covariance=False,\n",
       "                                                                                                tol=0.0001)),\n",
       "                                                                    ('pls',\n",
       "                                                                     PLSSVD(copy=True,\n",
       "                                                                            n_components=1,\n",
       "                                                                            scale=True))],\n",
       "                                                  transformer_weights=None,\n",
       "                                                  verbose=False)],\n",
       "                          'dimred__pca__n_components': [2, 3, 5, 8]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lda and pls do not appear to help with logistic regression\n",
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "lgr = LogisticRegression(penalty='l2', max_iter=10000, class_weight='balanced')\n",
    "rfe = RFECV(lgr, min_features_to_select=300, cv=10, scoring='roc_auc')\n",
    "pca = PCA(whiten=True)\n",
    "lda = LinearDiscriminantAnalysis(solver='eigen', shrinkage='auto')\n",
    "pls = PLSSVD(n_components=1)\n",
    "pca_lda = FeatureUnion([(\"pca\", pca), (\"lda\", lda)])\n",
    "pca_lda_pls = FeatureUnion([(\"pca\", pca), (\"lda\", lda), (\"pls\", pls)])\n",
    "n_components_opts = [2, 3, 5, 8]\n",
    "clf = LogisticRegression(penalty='l2', max_iter=10000, class_weight='balanced')\n",
    "c_opts = [0.01, 0.1, 1.0]\n",
    "\n",
    "grid_params = [\n",
    "    {\n",
    "        'dimred': [pca],\n",
    "        'dimred__n_components': n_components_opts,\n",
    "        'clf__C': c_opts,\n",
    "    },\n",
    "    {\n",
    "        'dimred': [pca_lda, pca_lda_pls],\n",
    "        'dimred__pca__n_components': n_components_opts,\n",
    "        'clf__C': c_opts,\n",
    "    },\n",
    "]\n",
    "pipelineM = Pipeline([(\"imp\", imputer),\n",
    "                      (\"scaler\", scaler),\n",
    "                      (\"rfe\", rfe),\n",
    "                      (\"dimred\", pca),\n",
    "                      (\"clf\", clf)])\n",
    "\n",
    "search = GridSearchCV(pipelineM, n_jobs=NTHREADS, param_grid=grid_params, \n",
    "                      cv=10, scoring='roc_auc', return_train_score=True, verbose=2)\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>0.540411</td>\n",
       "      <td>0.508333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.716612</td>\n",
       "      <td>0.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.767634</td>\n",
       "      <td>0.611667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0.837037</td>\n",
       "      <td>0.585000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>0.557102</td>\n",
       "      <td>0.506667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17</td>\n",
       "      <td>0.695933</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.791993</td>\n",
       "      <td>0.591667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.808031</td>\n",
       "      <td>0.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "      <td>0.546507</td>\n",
       "      <td>0.508333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21</td>\n",
       "      <td>0.692625</td>\n",
       "      <td>0.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>0.803350</td>\n",
       "      <td>0.606667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>0.820820</td>\n",
       "      <td>0.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>0.991615</td>\n",
       "      <td>0.605000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>0.986091</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>0.988790</td>\n",
       "      <td>0.581667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12</td>\n",
       "      <td>0.995493</td>\n",
       "      <td>0.576667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19</td>\n",
       "      <td>0.992686</td>\n",
       "      <td>0.536667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10</td>\n",
       "      <td>0.992670</td>\n",
       "      <td>0.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>0.994317</td>\n",
       "      <td>0.603333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>18</td>\n",
       "      <td>0.989870</td>\n",
       "      <td>0.553333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>0.989460</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>13</td>\n",
       "      <td>0.992232</td>\n",
       "      <td>0.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>14</td>\n",
       "      <td>0.982866</td>\n",
       "      <td>0.573333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>15</td>\n",
       "      <td>0.996046</td>\n",
       "      <td>0.573333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_score  mean_train_score  mean_test_score\n",
       "0                22          0.540411         0.508333\n",
       "1                10          0.716612         0.580000\n",
       "2                 3          0.767634         0.611667\n",
       "3                 8          0.837037         0.585000\n",
       "4                24          0.557102         0.506667\n",
       "5                17          0.695933         0.566667\n",
       "6                 7          0.791993         0.591667\n",
       "7                 1          0.808031         0.660000\n",
       "8                23          0.546507         0.508333\n",
       "9                21          0.692625         0.510000\n",
       "10                4          0.803350         0.606667\n",
       "11               16          0.820820         0.570000\n",
       "12                5          0.991615         0.605000\n",
       "13               20          0.986091         0.520000\n",
       "14                9          0.988790         0.581667\n",
       "15               12          0.995493         0.576667\n",
       "16               34               NaN              NaN\n",
       "17               28               NaN              NaN\n",
       "18               32               NaN              NaN\n",
       "19               31               NaN              NaN\n",
       "20               19          0.992686         0.536667\n",
       "21               10          0.992670         0.580000\n",
       "22                6          0.994317         0.603333\n",
       "23               18          0.989870         0.553333\n",
       "24               30               NaN              NaN\n",
       "25               29               NaN              NaN\n",
       "26               35               NaN              NaN\n",
       "27               27               NaN              NaN\n",
       "28                2          0.989460         0.650000\n",
       "29               13          0.992232         0.575000\n",
       "30               14          0.982866         0.573333\n",
       "31               15          0.996046         0.573333\n",
       "32               26               NaN              NaN\n",
       "33               25               NaN              NaN\n",
       "34               33               NaN              NaN\n",
       "35               36               NaN              NaN"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df = pd.DataFrame(search.cv_results_)\n",
    "cv_df[[\"rank_test_score\", \"mean_train_score\", \"mean_test_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(split0_test_score > 0.35)&(split1_test_score > 0.35)&(split2_test_score > 0.35)&(split3_test_score > 0.35)&(split4_test_score > 0.35)&(split5_test_score > 0.35)&(split6_test_score > 0.35)&(split7_test_score > 0.35)&(split8_test_score > 0.35)&(split9_test_score > 0.35)'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_list = ['(split{}_test_score > 0.35)'.format(idx) for idx in range(10)]\n",
    "query = '&'.join(query_list)\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean_fit_time                                                                231.244\n",
       "std_fit_time                                                                 5.61076\n",
       "mean_score_time                                                               6.0824\n",
       "std_score_time                                                               1.99265\n",
       "param_clf__C                                                                     0.1\n",
       "param_dimred                       PCA(copy=True, iterated_power='auto', n_compon...\n",
       "param_dimred__n_components                                                         8\n",
       "param_dimred__pca__n_components                                                  NaN\n",
       "params                             {'clf__C': 0.1, 'dimred': PCA(copy=True, itera...\n",
       "split0_test_score                                                                  1\n",
       "split1_test_score                                                                0.8\n",
       "split2_test_score                                                                0.4\n",
       "split3_test_score                                                                0.4\n",
       "split4_test_score                                                           0.933333\n",
       "split5_test_score                                                                0.6\n",
       "split6_test_score                                                           0.533333\n",
       "split7_test_score                                                           0.833333\n",
       "split8_test_score                                                                0.4\n",
       "split9_test_score                                                                0.7\n",
       "mean_test_score                                                                 0.66\n",
       "std_test_score                                                              0.215407\n",
       "rank_test_score                                                                    1\n",
       "split0_train_score                                                          0.699275\n",
       "split1_train_score                                                          0.748188\n",
       "split2_train_score                                                          0.792572\n",
       "split3_train_score                                                          0.834239\n",
       "split4_train_score                                                          0.788949\n",
       "split5_train_score                                                          0.771739\n",
       "split6_train_score                                                          0.951087\n",
       "split7_train_score                                                             0.856\n",
       "split8_train_score                                                          0.921739\n",
       "split9_train_score                                                          0.716522\n",
       "mean_train_score                                                            0.808031\n",
       "std_train_score                                                            0.0787943\n",
       "Name: 7, dtype: object"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df.iloc[7,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01627416,  0.27812222,  0.62391284, -0.35240666, -0.10489054,\n",
       "        -0.40259465, -0.05671495,  0.08546177]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_estimator_.named_steps['clf'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 0.1,\n",
       " 'dimred': PCA(copy=True, iterated_power='auto', n_components=8, random_state=None,\n",
       "     svd_solver='auto', tol=0.0, whiten=True),\n",
       " 'dimred__n_components': 8}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfm_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = pipelineM.predict(X_test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True,  True, False, False,  True,  True,  True,\n",
       "       False])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test == prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([44.64633679, 45.91966748, 44.72462916, 44.9925971 , 45.57197213,\n",
       "        51.22543502, 44.11260056, 42.12161946, 43.53103566, 43.78809285]),\n",
       " 'score_time': array([4.08448863, 3.71930289, 4.12880611, 8.72043419, 4.04098153,\n",
       "        7.72677922, 7.75545382, 3.91159439, 4.01412225, 3.92895198]),\n",
       " 'estimator': (Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=True, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=Tr...\n",
       "                   FastICA(algorithm='parallel', fun='logcosh', fun_args=None,\n",
       "                           max_iter=200, n_components=5, random_state=None,\n",
       "                           tol=0.0001, w_init=None, whiten=True)),\n",
       "                  ('clf',\n",
       "                   SVC(C=0.005, break_ties=False, cache_size=200,\n",
       "                       class_weight='balanced', coef0=0.0,\n",
       "                       decision_function_shape='ovr', degree=3, gamma=0.05,\n",
       "                       kernel='rbf', max_iter=-1, probability=False,\n",
       "                       random_state=None, shrinking=True, tol=0.001,\n",
       "                       verbose=False))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=True, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=Tr...\n",
       "                   FastICA(algorithm='parallel', fun='logcosh', fun_args=None,\n",
       "                           max_iter=200, n_components=5, random_state=None,\n",
       "                           tol=0.0001, w_init=None, whiten=True)),\n",
       "                  ('clf',\n",
       "                   SVC(C=0.005, break_ties=False, cache_size=200,\n",
       "                       class_weight='balanced', coef0=0.0,\n",
       "                       decision_function_shape='ovr', degree=3, gamma=0.05,\n",
       "                       kernel='rbf', max_iter=-1, probability=False,\n",
       "                       random_state=None, shrinking=True, tol=0.001,\n",
       "                       verbose=False))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=True, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=Tr...\n",
       "                   FastICA(algorithm='parallel', fun='logcosh', fun_args=None,\n",
       "                           max_iter=200, n_components=5, random_state=None,\n",
       "                           tol=0.0001, w_init=None, whiten=True)),\n",
       "                  ('clf',\n",
       "                   SVC(C=0.005, break_ties=False, cache_size=200,\n",
       "                       class_weight='balanced', coef0=0.0,\n",
       "                       decision_function_shape='ovr', degree=3, gamma=0.05,\n",
       "                       kernel='rbf', max_iter=-1, probability=False,\n",
       "                       random_state=None, shrinking=True, tol=0.001,\n",
       "                       verbose=False))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=True, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=Tr...\n",
       "                   FastICA(algorithm='parallel', fun='logcosh', fun_args=None,\n",
       "                           max_iter=200, n_components=5, random_state=None,\n",
       "                           tol=0.0001, w_init=None, whiten=True)),\n",
       "                  ('clf',\n",
       "                   SVC(C=0.005, break_ties=False, cache_size=200,\n",
       "                       class_weight='balanced', coef0=0.0,\n",
       "                       decision_function_shape='ovr', degree=3, gamma=0.05,\n",
       "                       kernel='rbf', max_iter=-1, probability=False,\n",
       "                       random_state=None, shrinking=True, tol=0.001,\n",
       "                       verbose=False))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=True, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=Tr...\n",
       "                   FastICA(algorithm='parallel', fun='logcosh', fun_args=None,\n",
       "                           max_iter=200, n_components=5, random_state=None,\n",
       "                           tol=0.0001, w_init=None, whiten=True)),\n",
       "                  ('clf',\n",
       "                   SVC(C=0.005, break_ties=False, cache_size=200,\n",
       "                       class_weight='balanced', coef0=0.0,\n",
       "                       decision_function_shape='ovr', degree=3, gamma=0.05,\n",
       "                       kernel='rbf', max_iter=-1, probability=False,\n",
       "                       random_state=None, shrinking=True, tol=0.001,\n",
       "                       verbose=False))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=True, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=Tr...\n",
       "                   FastICA(algorithm='parallel', fun='logcosh', fun_args=None,\n",
       "                           max_iter=200, n_components=5, random_state=None,\n",
       "                           tol=0.0001, w_init=None, whiten=True)),\n",
       "                  ('clf',\n",
       "                   SVC(C=0.005, break_ties=False, cache_size=200,\n",
       "                       class_weight='balanced', coef0=0.0,\n",
       "                       decision_function_shape='ovr', degree=3, gamma=0.05,\n",
       "                       kernel='rbf', max_iter=-1, probability=False,\n",
       "                       random_state=None, shrinking=True, tol=0.001,\n",
       "                       verbose=False))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=True, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=Tr...\n",
       "                   FastICA(algorithm='parallel', fun='logcosh', fun_args=None,\n",
       "                           max_iter=200, n_components=5, random_state=None,\n",
       "                           tol=0.0001, w_init=None, whiten=True)),\n",
       "                  ('clf',\n",
       "                   SVC(C=0.005, break_ties=False, cache_size=200,\n",
       "                       class_weight='balanced', coef0=0.0,\n",
       "                       decision_function_shape='ovr', degree=3, gamma=0.05,\n",
       "                       kernel='rbf', max_iter=-1, probability=False,\n",
       "                       random_state=None, shrinking=True, tol=0.001,\n",
       "                       verbose=False))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=True, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=Tr...\n",
       "                   FastICA(algorithm='parallel', fun='logcosh', fun_args=None,\n",
       "                           max_iter=200, n_components=5, random_state=None,\n",
       "                           tol=0.0001, w_init=None, whiten=True)),\n",
       "                  ('clf',\n",
       "                   SVC(C=0.005, break_ties=False, cache_size=200,\n",
       "                       class_weight='balanced', coef0=0.0,\n",
       "                       decision_function_shape='ovr', degree=3, gamma=0.05,\n",
       "                       kernel='rbf', max_iter=-1, probability=False,\n",
       "                       random_state=None, shrinking=True, tol=0.001,\n",
       "                       verbose=False))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=True, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=Tr...\n",
       "                   FastICA(algorithm='parallel', fun='logcosh', fun_args=None,\n",
       "                           max_iter=200, n_components=5, random_state=None,\n",
       "                           tol=0.0001, w_init=None, whiten=True)),\n",
       "                  ('clf',\n",
       "                   SVC(C=0.005, break_ties=False, cache_size=200,\n",
       "                       class_weight='balanced', coef0=0.0,\n",
       "                       decision_function_shape='ovr', degree=3, gamma=0.05,\n",
       "                       kernel='rbf', max_iter=-1, probability=False,\n",
       "                       random_state=None, shrinking=True, tol=0.001,\n",
       "                       verbose=False))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=True, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=Tr...\n",
       "                   FastICA(algorithm='parallel', fun='logcosh', fun_args=None,\n",
       "                           max_iter=200, n_components=5, random_state=None,\n",
       "                           tol=0.0001, w_init=None, whiten=True)),\n",
       "                  ('clf',\n",
       "                   SVC(C=0.005, break_ties=False, cache_size=200,\n",
       "                       class_weight='balanced', coef0=0.0,\n",
       "                       decision_function_shape='ovr', degree=3, gamma=0.05,\n",
       "                       kernel='rbf', max_iter=-1, probability=False,\n",
       "                       random_state=None, shrinking=True, tol=0.001,\n",
       "                       verbose=False))],\n",
       "           verbose=False)),\n",
       " 'test_score': array([0.6       , 0.4       , 0.8       , 0.6       , 0.2       ,\n",
       "        0.66666667, 0.66666667, 0.58333333, 0.        , 0.8       ]),\n",
       " 'train_score': array([0.5923913 , 0.65036232, 0.59148551, 0.71648551, 0.69021739,\n",
       "        0.60960145, 0.66123188, 0.624     , 0.6426087 , 0.59391304])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lda and pls do not appear to help with logistic regression\n",
    "imputer = IterativeImputer(add_indicator=True,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "kbest = SelectKBest(k=500)\n",
    "lgr = LogisticRegression(penalty='l2', max_iter=10000, class_weight='balanced')\n",
    "rfe = RFECV(lgr, min_features_to_select=300, cv=10, scoring='roc_auc')\n",
    "pca = PCA(n_components=10, whiten=True)\n",
    "ica = FastICA(n_components=5, whiten=True)\n",
    "# poly = PolynomialFeatures(interaction_only=False)\n",
    "clf = SVC(C=0.005, gamma=0.05, class_weight='balanced')\n",
    "\n",
    "pipelineM = Pipeline([(\"imp\", imputer),\n",
    "                      (\"scaler\", scaler),\n",
    "#                      (\"kbest\", kbest),\n",
    "#                      (\"rfe\", rfe),\n",
    "                      (\"dimred\", ica),\n",
    "#                      (\"poly\", poly),\n",
    "                      (\"clf\", clf)])\n",
    "\n",
    "cv_results = cross_validate(pipelineM, X_train, y_train, scoring='roc_auc', cv=10, return_train_score=True, return_estimator=True, n_jobs=NTHREADS)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('imp',\n",
       "                 IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                  imputation_order='random',\n",
       "                                  initial_strategy='median', max_iter=10,\n",
       "                                  max_value=None, min_value=None,\n",
       "                                  missing_values=nan, n_nearest_features=50,\n",
       "                                  random_state=None, sample_posterior=True,\n",
       "                                  skip_complete=False, tol=0.001, verbose=0)),\n",
       "                ('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=T...\n",
       "                                                                                          min_impurity_decrease=0.0,\n",
       "                                                                                          min_impurity_split=None,\n",
       "                                                                                          min_samples_leaf=1,\n",
       "                                                                                          min_samples_split=2,\n",
       "                                                                                          min_weight_fraction_leaf=0.0,\n",
       "                                                                                          n_estimators=200,\n",
       "                                                                                          n_iter_no_change=None,\n",
       "                                                                                          presort='deprecated',\n",
       "                                                                                          random_state=None,\n",
       "                                                                                          subsample=0.8,\n",
       "                                                                                          tol=0.0001,\n",
       "                                                                                          validation_fraction=0.1,\n",
       "                                                                                          verbose=0,\n",
       "                                                                                          warm_start=False),\n",
       "                                                     n_features_to_select=100,\n",
       "                                                     step=1, verbose=0))],\n",
       "                              transformer_weights=None, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "kbest = SelectKBest(score_func=mutual_info_classif, k=500)\n",
    "selector1 = RandomForestClassifier(\n",
    "    n_estimators=200, max_depth=5,\n",
    "    class_weight=\"balanced_subsample\",\n",
    "    max_samples=0.8)\n",
    "\n",
    "selector2 = LogisticRegression(\n",
    "    penalty='l2', max_iter=10000, class_weight='balanced')\n",
    "\n",
    "selector3 = AdaBoostClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(max_depth=5, class_weight=\"balanced\"),\n",
    "    n_estimators=200, learning_rate=0.1)\n",
    "\n",
    "selector4 = GradientBoostingClassifier(n_estimators=200, subsample=0.8)\n",
    "\n",
    "rfe1 = RFE(selector1, n_features_to_select=100)\n",
    "rfe2 = RFE(selector2, n_features_to_select=100)\n",
    "rfe3 = RFE(selector3, n_features_to_select=100)\n",
    "rfe4 = RFE(selector4, n_features_to_select=100)\n",
    "\n",
    "fu = FeatureUnion([(\"rfe1\", rfe1),\n",
    "                   (\"rfe2\", rfe2),\n",
    "                   (\"rfe3\", rfe3),\n",
    "                   (\"rfe4\", rfe4)], n_jobs=NTHREADS)\n",
    "\n",
    "feat_pipe = Pipeline([(\"imp\", imputer),\n",
    "                      (\"scaler\", scaler),\n",
    "                      (\"kbest\", kbest),\n",
    "                      (\"fu\", fu)])\n",
    "feat_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "da_best = feat_pipe.named_steps['kbest'].get_support()\n",
    "rf_best = feat_pipe.named_steps['fu'].transformer_list[0][1].get_support()\n",
    "lr_best = feat_pipe.named_steps['fu'].transformer_list[1][1].get_support()\n",
    "ad_best = feat_pipe.named_steps['fu'].transformer_list[2][1].get_support()\n",
    "gb_best = feat_pipe.named_steps['fu'].transformer_list[3][1].get_support()\n",
    "\n",
    "all_best = rf_best * lr_best * ad_best * gb_best\n",
    "# feat_pipe.named_steps['fu'].transformer_list[0][1].get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['allvol_right_choroid_plexus', 'allvol_wm_lh_paracentral',\n",
       "       't1r_ctxrins_m', 'dti_r_infcrblped_krd', 'dti_vermis_x_km',\n",
       "       'dti_l_lob_viib_kfa'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns[da_best][all_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvp_features1 = [\n",
    "    'allvol_wm_rh_posteriorcingulate',\n",
    "    't1r_ctxrins_m',\n",
    "    't1r_venousblood_m',\n",
    "    'dti_r_infcrblped_krd',\n",
    "    'dti_vermis_x_km',\n",
    "    'dti_l_lob_viib_kfa',\n",
    "    'dti_l_lob_viiia_kfa',\n",
    "    'dti_vermis_x_krd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mvp_features2 = [\n",
    "    'allvol_wm_rh_fusiform',\n",
    "    'allvol_venousblood',\n",
    "    'allvol_cc_central',\n",
    "    't1r_ctxrins_m',\n",
    "    't1r_venousblood_m',\n",
    "    'dti_vermis_x_km'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvp_features3 = [\n",
    "    'allvol_right_choroid_plexus',\n",
    "    'allvol_wm_lh_paracentral',\n",
    "    't1r_ctxrins_m',\n",
    "    'dti_r_infcrblped_krd',\n",
    "    'dti_vermis_x_km',\n",
    "    'dti_l_lob_viib_kfa'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = [\n",
    "    't1r_ctxrins_m',\n",
    "    'dti_vermis_x_km',\n",
    "    'dti_l_lob_viib_kfa',\n",
    "    't1r_venousblood_m',\n",
    "    'dti_r_infcrblped_krd',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features_idx = [X_train.columns.get_loc(c) for c in best_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">t1r_ctxrins_m</th>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>122.117925</td>\n",
       "      <td>93.362824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>36.409664</td>\n",
       "      <td>43.215375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.495673</td>\n",
       "      <td>-0.482289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>116.468500</td>\n",
       "      <td>96.787850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>128.264000</td>\n",
       "      <td>109.642000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>136.038250</td>\n",
       "      <td>118.494500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>175.773000</td>\n",
       "      <td>138.969000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">dti_vermis_x_km</th>\n",
       "      <th>count</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.650724</td>\n",
       "      <td>0.570717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.086570</td>\n",
       "      <td>0.088041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.426555</td>\n",
       "      <td>0.451905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.584505</td>\n",
       "      <td>0.506820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.643785</td>\n",
       "      <td>0.550995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.713415</td>\n",
       "      <td>0.628335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.843315</td>\n",
       "      <td>0.792165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">dti_l_lob_viib_kfa</th>\n",
       "      <th>count</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.534576</td>\n",
       "      <td>0.582490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.129081</td>\n",
       "      <td>0.101654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.182925</td>\n",
       "      <td>0.351262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.455283</td>\n",
       "      <td>0.510663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.561868</td>\n",
       "      <td>0.626139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.640876</td>\n",
       "      <td>0.642589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.732250</td>\n",
       "      <td>0.715338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">t1r_venousblood_m</th>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>70.234676</td>\n",
       "      <td>78.072178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.259633</td>\n",
       "      <td>18.720095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>39.767400</td>\n",
       "      <td>45.382200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>58.369550</td>\n",
       "      <td>64.801750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>69.134200</td>\n",
       "      <td>80.632300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>80.118675</td>\n",
       "      <td>87.673850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>136.271000</td>\n",
       "      <td>119.932000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">dti_r_infcrblped_krd</th>\n",
       "      <th>count</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.103415</td>\n",
       "      <td>1.142742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.224916</td>\n",
       "      <td>0.154211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.682455</td>\n",
       "      <td>0.906255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.928665</td>\n",
       "      <td>1.017115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.117660</td>\n",
       "      <td>1.162390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.266280</td>\n",
       "      <td>1.246473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.588960</td>\n",
       "      <td>1.484650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "group                                0           1\n",
       "t1r_ctxrins_m        count   50.000000   27.000000\n",
       "                     mean   122.117925   93.362824\n",
       "                     std     36.409664   43.215375\n",
       "                     min      0.495673   -0.482289\n",
       "                     25%    116.468500   96.787850\n",
       "                     50%    128.264000  109.642000\n",
       "                     75%    136.038250  118.494500\n",
       "                     max    175.773000  138.969000\n",
       "dti_vermis_x_km      count   49.000000   26.000000\n",
       "                     mean     0.650724    0.570717\n",
       "                     std      0.086570    0.088041\n",
       "                     min      0.426555    0.451905\n",
       "                     25%      0.584505    0.506820\n",
       "                     50%      0.643785    0.550995\n",
       "                     75%      0.713415    0.628335\n",
       "                     max      0.843315    0.792165\n",
       "dti_l_lob_viib_kfa   count   49.000000   26.000000\n",
       "                     mean     0.534576    0.582490\n",
       "                     std      0.129081    0.101654\n",
       "                     min      0.182925    0.351262\n",
       "                     25%      0.455283    0.510663\n",
       "                     50%      0.561868    0.626139\n",
       "                     75%      0.640876    0.642589\n",
       "                     max      0.732250    0.715338\n",
       "t1r_venousblood_m    count   50.000000   27.000000\n",
       "                     mean    70.234676   78.072178\n",
       "                     std     17.259633   18.720095\n",
       "                     min     39.767400   45.382200\n",
       "                     25%     58.369550   64.801750\n",
       "                     50%     69.134200   80.632300\n",
       "                     75%     80.118675   87.673850\n",
       "                     max    136.271000  119.932000\n",
       "dti_r_infcrblped_krd count   49.000000   26.000000\n",
       "                     mean     1.103415    1.142742\n",
       "                     std      0.224916    0.154211\n",
       "                     min      0.682455    0.906255\n",
       "                     25%      0.928665    1.017115\n",
       "                     50%      1.117660    1.162390\n",
       "                     75%      1.266280    1.246473\n",
       "                     max      1.588960    1.484650"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 999\n",
    "new_df = X_train[best_features].copy()\n",
    "new_df['group'] = y_train\n",
    "new_df.groupby('group').describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allvol_unknown</th>\n",
       "      <th>allvol_ctx_rh_posterior_insula</th>\n",
       "      <th>allvol_ctx_lh_posterior_insula</th>\n",
       "      <th>allvol_ctx_rh_parietal_operculum</th>\n",
       "      <th>allvol_ctx_lh_parietal_operculum</th>\n",
       "      <th>allvol_left_lateral_ventricle</th>\n",
       "      <th>allvol_left_inf_lat_vent</th>\n",
       "      <th>allvol_ctx_rh_post_orbital_gyrus</th>\n",
       "      <th>allvol_left_cerebellum_wm</th>\n",
       "      <th>allvol_ctx_lh_post_orbital_gyrus</th>\n",
       "      <th>...</th>\n",
       "      <th>31p_r_paroperc_aatp</th>\n",
       "      <th>31p_l_wm_parcing_ph</th>\n",
       "      <th>31p_l_wm_parcing_gatp</th>\n",
       "      <th>31p_l_wm_parcing_aatp</th>\n",
       "      <th>31p_cc_ant_ph</th>\n",
       "      <th>31p_cc_ant_gatp</th>\n",
       "      <th>31p_cc_ant_aatp</th>\n",
       "      <th>31p_l_pat_ph</th>\n",
       "      <th>31p_l_pat_gatp</th>\n",
       "      <th>31p_l_pat_aatp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>6059622</td>\n",
       "      <td>2528</td>\n",
       "      <td>2588</td>\n",
       "      <td>2837</td>\n",
       "      <td>3282</td>\n",
       "      <td>288</td>\n",
       "      <td>25</td>\n",
       "      <td>3783</td>\n",
       "      <td>15058</td>\n",
       "      <td>3284</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6333243</td>\n",
       "      <td>2154</td>\n",
       "      <td>2312</td>\n",
       "      <td>2588</td>\n",
       "      <td>2536</td>\n",
       "      <td>203</td>\n",
       "      <td>27</td>\n",
       "      <td>3150</td>\n",
       "      <td>12130</td>\n",
       "      <td>2822</td>\n",
       "      <td>...</td>\n",
       "      <td>2669620.0</td>\n",
       "      <td>7.16438</td>\n",
       "      <td>6611740.0</td>\n",
       "      <td>3234290.0</td>\n",
       "      <td>7.13503</td>\n",
       "      <td>7858490.0</td>\n",
       "      <td>3510950.0</td>\n",
       "      <td>7.16700</td>\n",
       "      <td>11857700.0</td>\n",
       "      <td>4044550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6271620</td>\n",
       "      <td>2338</td>\n",
       "      <td>2243</td>\n",
       "      <td>2670</td>\n",
       "      <td>1728</td>\n",
       "      <td>199</td>\n",
       "      <td>11</td>\n",
       "      <td>2714</td>\n",
       "      <td>11760</td>\n",
       "      <td>3051</td>\n",
       "      <td>...</td>\n",
       "      <td>6376530.0</td>\n",
       "      <td>7.23973</td>\n",
       "      <td>11951100.0</td>\n",
       "      <td>5826170.0</td>\n",
       "      <td>7.30665</td>\n",
       "      <td>29879000.0</td>\n",
       "      <td>8074850.0</td>\n",
       "      <td>7.31797</td>\n",
       "      <td>15524700.0</td>\n",
       "      <td>8256190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>6279553</td>\n",
       "      <td>2193</td>\n",
       "      <td>2228</td>\n",
       "      <td>2666</td>\n",
       "      <td>2692</td>\n",
       "      <td>217</td>\n",
       "      <td>19</td>\n",
       "      <td>3246</td>\n",
       "      <td>14333</td>\n",
       "      <td>3169</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5840323</td>\n",
       "      <td>2248</td>\n",
       "      <td>2057</td>\n",
       "      <td>2100</td>\n",
       "      <td>2254</td>\n",
       "      <td>222</td>\n",
       "      <td>18</td>\n",
       "      <td>3353</td>\n",
       "      <td>11117</td>\n",
       "      <td>4135</td>\n",
       "      <td>...</td>\n",
       "      <td>4219870.0</td>\n",
       "      <td>7.16605</td>\n",
       "      <td>7225530.0</td>\n",
       "      <td>4172340.0</td>\n",
       "      <td>7.32276</td>\n",
       "      <td>8515520.0</td>\n",
       "      <td>4170950.0</td>\n",
       "      <td>7.23482</td>\n",
       "      <td>8056600.0</td>\n",
       "      <td>4783130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6345977</td>\n",
       "      <td>2597</td>\n",
       "      <td>2552</td>\n",
       "      <td>2502</td>\n",
       "      <td>2076</td>\n",
       "      <td>196</td>\n",
       "      <td>26</td>\n",
       "      <td>4288</td>\n",
       "      <td>13166</td>\n",
       "      <td>4648</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7132726</td>\n",
       "      <td>1984</td>\n",
       "      <td>2058</td>\n",
       "      <td>2567</td>\n",
       "      <td>1479</td>\n",
       "      <td>187</td>\n",
       "      <td>6</td>\n",
       "      <td>3093</td>\n",
       "      <td>11416</td>\n",
       "      <td>2914</td>\n",
       "      <td>...</td>\n",
       "      <td>2967320.0</td>\n",
       "      <td>7.18370</td>\n",
       "      <td>7300780.0</td>\n",
       "      <td>3713600.0</td>\n",
       "      <td>7.23577</td>\n",
       "      <td>9900240.0</td>\n",
       "      <td>3497420.0</td>\n",
       "      <td>7.23599</td>\n",
       "      <td>5744920.0</td>\n",
       "      <td>3075420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6300324</td>\n",
       "      <td>2079</td>\n",
       "      <td>2096</td>\n",
       "      <td>2211</td>\n",
       "      <td>2329</td>\n",
       "      <td>217</td>\n",
       "      <td>22</td>\n",
       "      <td>2529</td>\n",
       "      <td>14655</td>\n",
       "      <td>2198</td>\n",
       "      <td>...</td>\n",
       "      <td>3318770.0</td>\n",
       "      <td>7.24271</td>\n",
       "      <td>8032880.0</td>\n",
       "      <td>5110710.0</td>\n",
       "      <td>7.24266</td>\n",
       "      <td>5918480.0</td>\n",
       "      <td>8678260.0</td>\n",
       "      <td>7.24003</td>\n",
       "      <td>3556370.0</td>\n",
       "      <td>3544560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>6317414</td>\n",
       "      <td>2377</td>\n",
       "      <td>2230</td>\n",
       "      <td>2642</td>\n",
       "      <td>2869</td>\n",
       "      <td>233</td>\n",
       "      <td>24</td>\n",
       "      <td>2938</td>\n",
       "      <td>12312</td>\n",
       "      <td>3165</td>\n",
       "      <td>...</td>\n",
       "      <td>3488680.0</td>\n",
       "      <td>7.15247</td>\n",
       "      <td>4836200.0</td>\n",
       "      <td>2995810.0</td>\n",
       "      <td>7.15518</td>\n",
       "      <td>5731290.0</td>\n",
       "      <td>3189580.0</td>\n",
       "      <td>7.16605</td>\n",
       "      <td>4384660.0</td>\n",
       "      <td>3341830.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5783011</td>\n",
       "      <td>1891</td>\n",
       "      <td>1918</td>\n",
       "      <td>2038</td>\n",
       "      <td>1845</td>\n",
       "      <td>287</td>\n",
       "      <td>31</td>\n",
       "      <td>3238</td>\n",
       "      <td>12171</td>\n",
       "      <td>2645</td>\n",
       "      <td>...</td>\n",
       "      <td>4576130.0</td>\n",
       "      <td>7.16644</td>\n",
       "      <td>15837700.0</td>\n",
       "      <td>4574200.0</td>\n",
       "      <td>7.14947</td>\n",
       "      <td>12317800.0</td>\n",
       "      <td>4811700.0</td>\n",
       "      <td>7.13478</td>\n",
       "      <td>17156400.0</td>\n",
       "      <td>4703430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>5813624</td>\n",
       "      <td>2432</td>\n",
       "      <td>2097</td>\n",
       "      <td>2632</td>\n",
       "      <td>2361</td>\n",
       "      <td>273</td>\n",
       "      <td>34</td>\n",
       "      <td>3001</td>\n",
       "      <td>12293</td>\n",
       "      <td>2863</td>\n",
       "      <td>...</td>\n",
       "      <td>5093020.0</td>\n",
       "      <td>7.30527</td>\n",
       "      <td>7087840.0</td>\n",
       "      <td>5091070.0</td>\n",
       "      <td>7.27818</td>\n",
       "      <td>5160080.0</td>\n",
       "      <td>5092370.0</td>\n",
       "      <td>7.30372</td>\n",
       "      <td>11967900.0</td>\n",
       "      <td>4269350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5877985</td>\n",
       "      <td>2297</td>\n",
       "      <td>2263</td>\n",
       "      <td>2459</td>\n",
       "      <td>2072</td>\n",
       "      <td>248</td>\n",
       "      <td>18</td>\n",
       "      <td>2422</td>\n",
       "      <td>12079</td>\n",
       "      <td>2692</td>\n",
       "      <td>...</td>\n",
       "      <td>4311700.0</td>\n",
       "      <td>7.23210</td>\n",
       "      <td>5873980.0</td>\n",
       "      <td>4279970.0</td>\n",
       "      <td>7.23703</td>\n",
       "      <td>6863870.0</td>\n",
       "      <td>4359720.0</td>\n",
       "      <td>7.23604</td>\n",
       "      <td>9509390.0</td>\n",
       "      <td>5981970.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>7073802</td>\n",
       "      <td>2797</td>\n",
       "      <td>2550</td>\n",
       "      <td>2525</td>\n",
       "      <td>3661</td>\n",
       "      <td>272</td>\n",
       "      <td>29</td>\n",
       "      <td>3135</td>\n",
       "      <td>18782</td>\n",
       "      <td>3547</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>5701761</td>\n",
       "      <td>2344</td>\n",
       "      <td>2166</td>\n",
       "      <td>1996</td>\n",
       "      <td>2538</td>\n",
       "      <td>273</td>\n",
       "      <td>20</td>\n",
       "      <td>3189</td>\n",
       "      <td>11190</td>\n",
       "      <td>2704</td>\n",
       "      <td>...</td>\n",
       "      <td>4947720.0</td>\n",
       "      <td>7.38346</td>\n",
       "      <td>14797200.0</td>\n",
       "      <td>5708510.0</td>\n",
       "      <td>7.38758</td>\n",
       "      <td>13278200.0</td>\n",
       "      <td>4281760.0</td>\n",
       "      <td>7.38298</td>\n",
       "      <td>10141200.0</td>\n",
       "      <td>5332180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>5615278</td>\n",
       "      <td>2398</td>\n",
       "      <td>2153</td>\n",
       "      <td>2062</td>\n",
       "      <td>2119</td>\n",
       "      <td>149</td>\n",
       "      <td>21</td>\n",
       "      <td>3515</td>\n",
       "      <td>9931</td>\n",
       "      <td>2715</td>\n",
       "      <td>...</td>\n",
       "      <td>2745060.0</td>\n",
       "      <td>7.24964</td>\n",
       "      <td>4451050.0</td>\n",
       "      <td>2097980.0</td>\n",
       "      <td>7.20895</td>\n",
       "      <td>7767310.0</td>\n",
       "      <td>2914480.0</td>\n",
       "      <td>7.23388</td>\n",
       "      <td>4157560.0</td>\n",
       "      <td>2966380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5916360</td>\n",
       "      <td>2200</td>\n",
       "      <td>2029</td>\n",
       "      <td>1853</td>\n",
       "      <td>2265</td>\n",
       "      <td>176</td>\n",
       "      <td>10</td>\n",
       "      <td>3049</td>\n",
       "      <td>11987</td>\n",
       "      <td>3304</td>\n",
       "      <td>...</td>\n",
       "      <td>12894500.0</td>\n",
       "      <td>7.16301</td>\n",
       "      <td>23993600.0</td>\n",
       "      <td>12755000.0</td>\n",
       "      <td>7.16586</td>\n",
       "      <td>28904900.0</td>\n",
       "      <td>9822850.0</td>\n",
       "      <td>7.15195</td>\n",
       "      <td>45370800.0</td>\n",
       "      <td>11265400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5814463</td>\n",
       "      <td>2441</td>\n",
       "      <td>2100</td>\n",
       "      <td>2668</td>\n",
       "      <td>2336</td>\n",
       "      <td>276</td>\n",
       "      <td>36</td>\n",
       "      <td>3010</td>\n",
       "      <td>12617</td>\n",
       "      <td>2855</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>6172580</td>\n",
       "      <td>2782</td>\n",
       "      <td>2708</td>\n",
       "      <td>3073</td>\n",
       "      <td>3315</td>\n",
       "      <td>212</td>\n",
       "      <td>26</td>\n",
       "      <td>3985</td>\n",
       "      <td>14253</td>\n",
       "      <td>4127</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6774342</td>\n",
       "      <td>2480</td>\n",
       "      <td>2363</td>\n",
       "      <td>2065</td>\n",
       "      <td>2890</td>\n",
       "      <td>282</td>\n",
       "      <td>20</td>\n",
       "      <td>2841</td>\n",
       "      <td>16469</td>\n",
       "      <td>2845</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5865161</td>\n",
       "      <td>2054</td>\n",
       "      <td>2063</td>\n",
       "      <td>1929</td>\n",
       "      <td>1980</td>\n",
       "      <td>180</td>\n",
       "      <td>28</td>\n",
       "      <td>2505</td>\n",
       "      <td>11660</td>\n",
       "      <td>2648</td>\n",
       "      <td>...</td>\n",
       "      <td>6741250.0</td>\n",
       "      <td>7.16610</td>\n",
       "      <td>18337700.0</td>\n",
       "      <td>7255980.0</td>\n",
       "      <td>7.16712</td>\n",
       "      <td>17752700.0</td>\n",
       "      <td>7467770.0</td>\n",
       "      <td>7.16778</td>\n",
       "      <td>10680900.0</td>\n",
       "      <td>9164790.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6219262</td>\n",
       "      <td>2527</td>\n",
       "      <td>2301</td>\n",
       "      <td>2922</td>\n",
       "      <td>2807</td>\n",
       "      <td>246</td>\n",
       "      <td>17</td>\n",
       "      <td>2955</td>\n",
       "      <td>13294</td>\n",
       "      <td>3238</td>\n",
       "      <td>...</td>\n",
       "      <td>2835030.0</td>\n",
       "      <td>7.16535</td>\n",
       "      <td>8229570.0</td>\n",
       "      <td>2739530.0</td>\n",
       "      <td>7.16537</td>\n",
       "      <td>8242230.0</td>\n",
       "      <td>3362510.0</td>\n",
       "      <td>7.16535</td>\n",
       "      <td>6115790.0</td>\n",
       "      <td>4545140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6151157</td>\n",
       "      <td>2473</td>\n",
       "      <td>2300</td>\n",
       "      <td>2242</td>\n",
       "      <td>2156</td>\n",
       "      <td>245</td>\n",
       "      <td>35</td>\n",
       "      <td>3153</td>\n",
       "      <td>13936</td>\n",
       "      <td>3385</td>\n",
       "      <td>...</td>\n",
       "      <td>414169.0</td>\n",
       "      <td>7.17096</td>\n",
       "      <td>672485.0</td>\n",
       "      <td>317153.0</td>\n",
       "      <td>7.13043</td>\n",
       "      <td>519456.0</td>\n",
       "      <td>470314.0</td>\n",
       "      <td>7.16536</td>\n",
       "      <td>531852.0</td>\n",
       "      <td>404226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>5765673</td>\n",
       "      <td>2059</td>\n",
       "      <td>2131</td>\n",
       "      <td>2205</td>\n",
       "      <td>2053</td>\n",
       "      <td>214</td>\n",
       "      <td>20</td>\n",
       "      <td>3077</td>\n",
       "      <td>15997</td>\n",
       "      <td>3532</td>\n",
       "      <td>...</td>\n",
       "      <td>11126800.0</td>\n",
       "      <td>7.16359</td>\n",
       "      <td>29332200.0</td>\n",
       "      <td>11767500.0</td>\n",
       "      <td>7.15584</td>\n",
       "      <td>18228100.0</td>\n",
       "      <td>9979020.0</td>\n",
       "      <td>7.15757</td>\n",
       "      <td>31155800.0</td>\n",
       "      <td>16931400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6452080</td>\n",
       "      <td>2268</td>\n",
       "      <td>2505</td>\n",
       "      <td>1952</td>\n",
       "      <td>2379</td>\n",
       "      <td>211</td>\n",
       "      <td>27</td>\n",
       "      <td>4638</td>\n",
       "      <td>14504</td>\n",
       "      <td>3975</td>\n",
       "      <td>...</td>\n",
       "      <td>4550500.0</td>\n",
       "      <td>7.16324</td>\n",
       "      <td>3950570.0</td>\n",
       "      <td>6089740.0</td>\n",
       "      <td>7.09062</td>\n",
       "      <td>3564150.0</td>\n",
       "      <td>4259950.0</td>\n",
       "      <td>7.09540</td>\n",
       "      <td>3748660.0</td>\n",
       "      <td>3571750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6191830</td>\n",
       "      <td>2619</td>\n",
       "      <td>2447</td>\n",
       "      <td>2197</td>\n",
       "      <td>3207</td>\n",
       "      <td>317</td>\n",
       "      <td>24</td>\n",
       "      <td>4377</td>\n",
       "      <td>12868</td>\n",
       "      <td>3169</td>\n",
       "      <td>...</td>\n",
       "      <td>6420720.0</td>\n",
       "      <td>7.08810</td>\n",
       "      <td>17232300.0</td>\n",
       "      <td>7437530.0</td>\n",
       "      <td>7.16660</td>\n",
       "      <td>24824800.0</td>\n",
       "      <td>7771480.0</td>\n",
       "      <td>7.09903</td>\n",
       "      <td>20568600.0</td>\n",
       "      <td>11024000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6281946</td>\n",
       "      <td>1708</td>\n",
       "      <td>1893</td>\n",
       "      <td>1895</td>\n",
       "      <td>2076</td>\n",
       "      <td>183</td>\n",
       "      <td>28</td>\n",
       "      <td>2282</td>\n",
       "      <td>11770</td>\n",
       "      <td>2775</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>6184901</td>\n",
       "      <td>2375</td>\n",
       "      <td>2314</td>\n",
       "      <td>2456</td>\n",
       "      <td>2537</td>\n",
       "      <td>238</td>\n",
       "      <td>18</td>\n",
       "      <td>2590</td>\n",
       "      <td>11963</td>\n",
       "      <td>2881</td>\n",
       "      <td>...</td>\n",
       "      <td>10077100.0</td>\n",
       "      <td>7.07568</td>\n",
       "      <td>32348300.0</td>\n",
       "      <td>7823790.0</td>\n",
       "      <td>7.08579</td>\n",
       "      <td>24078800.0</td>\n",
       "      <td>8451840.0</td>\n",
       "      <td>7.06532</td>\n",
       "      <td>20758000.0</td>\n",
       "      <td>8603840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>5822814</td>\n",
       "      <td>1841</td>\n",
       "      <td>1645</td>\n",
       "      <td>2055</td>\n",
       "      <td>2070</td>\n",
       "      <td>185</td>\n",
       "      <td>23</td>\n",
       "      <td>3289</td>\n",
       "      <td>11807</td>\n",
       "      <td>3037</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5412720</td>\n",
       "      <td>1746</td>\n",
       "      <td>1651</td>\n",
       "      <td>1656</td>\n",
       "      <td>2089</td>\n",
       "      <td>204</td>\n",
       "      <td>13</td>\n",
       "      <td>2200</td>\n",
       "      <td>10998</td>\n",
       "      <td>2217</td>\n",
       "      <td>...</td>\n",
       "      <td>5022980.0</td>\n",
       "      <td>7.08891</td>\n",
       "      <td>12804100.0</td>\n",
       "      <td>5553580.0</td>\n",
       "      <td>7.09749</td>\n",
       "      <td>10573100.0</td>\n",
       "      <td>6594220.0</td>\n",
       "      <td>7.09587</td>\n",
       "      <td>7831260.0</td>\n",
       "      <td>5644400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6478225</td>\n",
       "      <td>2604</td>\n",
       "      <td>2267</td>\n",
       "      <td>2706</td>\n",
       "      <td>2721</td>\n",
       "      <td>275</td>\n",
       "      <td>9</td>\n",
       "      <td>2905</td>\n",
       "      <td>12203</td>\n",
       "      <td>3159</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>5905974</td>\n",
       "      <td>1931</td>\n",
       "      <td>1898</td>\n",
       "      <td>2346</td>\n",
       "      <td>2363</td>\n",
       "      <td>180</td>\n",
       "      <td>24</td>\n",
       "      <td>3133</td>\n",
       "      <td>12563</td>\n",
       "      <td>3048</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>6595517</td>\n",
       "      <td>2732</td>\n",
       "      <td>2216</td>\n",
       "      <td>2809</td>\n",
       "      <td>2535</td>\n",
       "      <td>232</td>\n",
       "      <td>28</td>\n",
       "      <td>3760</td>\n",
       "      <td>14321</td>\n",
       "      <td>4101</td>\n",
       "      <td>...</td>\n",
       "      <td>4605720.0</td>\n",
       "      <td>7.07550</td>\n",
       "      <td>10908100.0</td>\n",
       "      <td>5376510.0</td>\n",
       "      <td>7.10400</td>\n",
       "      <td>11702600.0</td>\n",
       "      <td>6254670.0</td>\n",
       "      <td>7.09608</td>\n",
       "      <td>11407400.0</td>\n",
       "      <td>7939670.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>7104555</td>\n",
       "      <td>1986</td>\n",
       "      <td>1978</td>\n",
       "      <td>1415</td>\n",
       "      <td>2611</td>\n",
       "      <td>235</td>\n",
       "      <td>31</td>\n",
       "      <td>2564</td>\n",
       "      <td>12076</td>\n",
       "      <td>2583</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>6153593</td>\n",
       "      <td>1679</td>\n",
       "      <td>1899</td>\n",
       "      <td>1968</td>\n",
       "      <td>1995</td>\n",
       "      <td>239</td>\n",
       "      <td>14</td>\n",
       "      <td>3126</td>\n",
       "      <td>12904</td>\n",
       "      <td>2444</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>6497474</td>\n",
       "      <td>2844</td>\n",
       "      <td>2643</td>\n",
       "      <td>2610</td>\n",
       "      <td>2159</td>\n",
       "      <td>241</td>\n",
       "      <td>30</td>\n",
       "      <td>4149</td>\n",
       "      <td>12562</td>\n",
       "      <td>3922</td>\n",
       "      <td>...</td>\n",
       "      <td>5166810.0</td>\n",
       "      <td>7.24250</td>\n",
       "      <td>16333100.0</td>\n",
       "      <td>5488730.0</td>\n",
       "      <td>7.21844</td>\n",
       "      <td>13230900.0</td>\n",
       "      <td>6035990.0</td>\n",
       "      <td>7.23694</td>\n",
       "      <td>12490900.0</td>\n",
       "      <td>8797310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>6190825</td>\n",
       "      <td>2819</td>\n",
       "      <td>3007</td>\n",
       "      <td>2720</td>\n",
       "      <td>3733</td>\n",
       "      <td>219</td>\n",
       "      <td>22</td>\n",
       "      <td>4260</td>\n",
       "      <td>14188</td>\n",
       "      <td>4814</td>\n",
       "      <td>...</td>\n",
       "      <td>5390730.0</td>\n",
       "      <td>7.16050</td>\n",
       "      <td>10740900.0</td>\n",
       "      <td>4346480.0</td>\n",
       "      <td>7.21978</td>\n",
       "      <td>18394100.0</td>\n",
       "      <td>6139840.0</td>\n",
       "      <td>7.10606</td>\n",
       "      <td>22174000.0</td>\n",
       "      <td>7327000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6500098</td>\n",
       "      <td>2816</td>\n",
       "      <td>2523</td>\n",
       "      <td>3709</td>\n",
       "      <td>3680</td>\n",
       "      <td>287</td>\n",
       "      <td>41</td>\n",
       "      <td>3485</td>\n",
       "      <td>15355</td>\n",
       "      <td>3939</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6616436</td>\n",
       "      <td>2448</td>\n",
       "      <td>2687</td>\n",
       "      <td>2904</td>\n",
       "      <td>2665</td>\n",
       "      <td>231</td>\n",
       "      <td>24</td>\n",
       "      <td>2754</td>\n",
       "      <td>14444</td>\n",
       "      <td>2785</td>\n",
       "      <td>...</td>\n",
       "      <td>6519020.0</td>\n",
       "      <td>7.18951</td>\n",
       "      <td>31108100.0</td>\n",
       "      <td>5751750.0</td>\n",
       "      <td>7.16696</td>\n",
       "      <td>26534300.0</td>\n",
       "      <td>5369030.0</td>\n",
       "      <td>7.17709</td>\n",
       "      <td>19705200.0</td>\n",
       "      <td>13128900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5791334</td>\n",
       "      <td>1968</td>\n",
       "      <td>2085</td>\n",
       "      <td>2236</td>\n",
       "      <td>1876</td>\n",
       "      <td>196</td>\n",
       "      <td>28</td>\n",
       "      <td>2706</td>\n",
       "      <td>12071</td>\n",
       "      <td>2659</td>\n",
       "      <td>...</td>\n",
       "      <td>4899180.0</td>\n",
       "      <td>7.29131</td>\n",
       "      <td>9351010.0</td>\n",
       "      <td>4259930.0</td>\n",
       "      <td>7.26006</td>\n",
       "      <td>9073540.0</td>\n",
       "      <td>5571050.0</td>\n",
       "      <td>7.27293</td>\n",
       "      <td>7662500.0</td>\n",
       "      <td>5961710.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>6008394</td>\n",
       "      <td>2714</td>\n",
       "      <td>2656</td>\n",
       "      <td>2187</td>\n",
       "      <td>2374</td>\n",
       "      <td>240</td>\n",
       "      <td>30</td>\n",
       "      <td>3123</td>\n",
       "      <td>13085</td>\n",
       "      <td>3022</td>\n",
       "      <td>...</td>\n",
       "      <td>5914810.0</td>\n",
       "      <td>7.17807</td>\n",
       "      <td>37955300.0</td>\n",
       "      <td>6290960.0</td>\n",
       "      <td>7.12576</td>\n",
       "      <td>49785000.0</td>\n",
       "      <td>6582480.0</td>\n",
       "      <td>7.16139</td>\n",
       "      <td>20535900.0</td>\n",
       "      <td>11972000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>6386455</td>\n",
       "      <td>2066</td>\n",
       "      <td>1971</td>\n",
       "      <td>1339</td>\n",
       "      <td>2336</td>\n",
       "      <td>195</td>\n",
       "      <td>22</td>\n",
       "      <td>3145</td>\n",
       "      <td>14046</td>\n",
       "      <td>2849</td>\n",
       "      <td>...</td>\n",
       "      <td>3697850.0</td>\n",
       "      <td>7.18599</td>\n",
       "      <td>7512530.0</td>\n",
       "      <td>3592270.0</td>\n",
       "      <td>7.13018</td>\n",
       "      <td>8232850.0</td>\n",
       "      <td>4170410.0</td>\n",
       "      <td>7.13461</td>\n",
       "      <td>6294010.0</td>\n",
       "      <td>3597260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6003911</td>\n",
       "      <td>2469</td>\n",
       "      <td>2238</td>\n",
       "      <td>2957</td>\n",
       "      <td>2905</td>\n",
       "      <td>203</td>\n",
       "      <td>18</td>\n",
       "      <td>3989</td>\n",
       "      <td>12678</td>\n",
       "      <td>4272</td>\n",
       "      <td>...</td>\n",
       "      <td>5714180.0</td>\n",
       "      <td>7.21084</td>\n",
       "      <td>9375400.0</td>\n",
       "      <td>5578490.0</td>\n",
       "      <td>7.19742</td>\n",
       "      <td>9407080.0</td>\n",
       "      <td>4957180.0</td>\n",
       "      <td>7.14830</td>\n",
       "      <td>13119700.0</td>\n",
       "      <td>5515800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5575197</td>\n",
       "      <td>2118</td>\n",
       "      <td>2135</td>\n",
       "      <td>2095</td>\n",
       "      <td>2278</td>\n",
       "      <td>212</td>\n",
       "      <td>21</td>\n",
       "      <td>2911</td>\n",
       "      <td>11098</td>\n",
       "      <td>2889</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5735873</td>\n",
       "      <td>2475</td>\n",
       "      <td>2316</td>\n",
       "      <td>3011</td>\n",
       "      <td>2928</td>\n",
       "      <td>248</td>\n",
       "      <td>27</td>\n",
       "      <td>2995</td>\n",
       "      <td>12881</td>\n",
       "      <td>3269</td>\n",
       "      <td>...</td>\n",
       "      <td>5939480.0</td>\n",
       "      <td>7.30916</td>\n",
       "      <td>21116300.0</td>\n",
       "      <td>7130210.0</td>\n",
       "      <td>7.29825</td>\n",
       "      <td>28021900.0</td>\n",
       "      <td>6892660.0</td>\n",
       "      <td>7.31148</td>\n",
       "      <td>18897400.0</td>\n",
       "      <td>8166430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>6664760</td>\n",
       "      <td>2999</td>\n",
       "      <td>2907</td>\n",
       "      <td>2328</td>\n",
       "      <td>2862</td>\n",
       "      <td>198</td>\n",
       "      <td>23</td>\n",
       "      <td>3364</td>\n",
       "      <td>15310</td>\n",
       "      <td>3130</td>\n",
       "      <td>...</td>\n",
       "      <td>3721330.0</td>\n",
       "      <td>7.30932</td>\n",
       "      <td>7291980.0</td>\n",
       "      <td>3867050.0</td>\n",
       "      <td>7.30966</td>\n",
       "      <td>12213200.0</td>\n",
       "      <td>3806780.0</td>\n",
       "      <td>7.30933</td>\n",
       "      <td>8804540.0</td>\n",
       "      <td>3673750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>12280771</td>\n",
       "      <td>1706</td>\n",
       "      <td>1301</td>\n",
       "      <td>460</td>\n",
       "      <td>1517</td>\n",
       "      <td>58</td>\n",
       "      <td>89</td>\n",
       "      <td>897</td>\n",
       "      <td>484</td>\n",
       "      <td>233</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>6061795</td>\n",
       "      <td>1804</td>\n",
       "      <td>1734</td>\n",
       "      <td>2116</td>\n",
       "      <td>1868</td>\n",
       "      <td>231</td>\n",
       "      <td>25</td>\n",
       "      <td>3017</td>\n",
       "      <td>11621</td>\n",
       "      <td>2430</td>\n",
       "      <td>...</td>\n",
       "      <td>3404910.0</td>\n",
       "      <td>7.30889</td>\n",
       "      <td>5325750.0</td>\n",
       "      <td>4056660.0</td>\n",
       "      <td>7.31046</td>\n",
       "      <td>4809680.0</td>\n",
       "      <td>3372650.0</td>\n",
       "      <td>7.30199</td>\n",
       "      <td>6261400.0</td>\n",
       "      <td>3420730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>5906664</td>\n",
       "      <td>2313</td>\n",
       "      <td>2296</td>\n",
       "      <td>2630</td>\n",
       "      <td>2108</td>\n",
       "      <td>216</td>\n",
       "      <td>25</td>\n",
       "      <td>3326</td>\n",
       "      <td>11519</td>\n",
       "      <td>3311</td>\n",
       "      <td>...</td>\n",
       "      <td>16281700.0</td>\n",
       "      <td>7.18506</td>\n",
       "      <td>139893000.0</td>\n",
       "      <td>77030300.0</td>\n",
       "      <td>7.16457</td>\n",
       "      <td>86780500.0</td>\n",
       "      <td>24879300.0</td>\n",
       "      <td>7.19108</td>\n",
       "      <td>73154500.0</td>\n",
       "      <td>22788100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>6039066</td>\n",
       "      <td>2597</td>\n",
       "      <td>2356</td>\n",
       "      <td>3000</td>\n",
       "      <td>3223</td>\n",
       "      <td>209</td>\n",
       "      <td>19</td>\n",
       "      <td>3678</td>\n",
       "      <td>14109</td>\n",
       "      <td>3439</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6159812</td>\n",
       "      <td>2333</td>\n",
       "      <td>2362</td>\n",
       "      <td>2985</td>\n",
       "      <td>3543</td>\n",
       "      <td>170</td>\n",
       "      <td>18</td>\n",
       "      <td>4375</td>\n",
       "      <td>12062</td>\n",
       "      <td>4843</td>\n",
       "      <td>...</td>\n",
       "      <td>3624550.0</td>\n",
       "      <td>7.24637</td>\n",
       "      <td>7889820.0</td>\n",
       "      <td>3774180.0</td>\n",
       "      <td>7.23639</td>\n",
       "      <td>12819700.0</td>\n",
       "      <td>5100150.0</td>\n",
       "      <td>7.23767</td>\n",
       "      <td>13779100.0</td>\n",
       "      <td>3584500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>6525153</td>\n",
       "      <td>2875</td>\n",
       "      <td>2765</td>\n",
       "      <td>1963</td>\n",
       "      <td>2734</td>\n",
       "      <td>238</td>\n",
       "      <td>14</td>\n",
       "      <td>3613</td>\n",
       "      <td>13711</td>\n",
       "      <td>3539</td>\n",
       "      <td>...</td>\n",
       "      <td>6625790.0</td>\n",
       "      <td>7.22924</td>\n",
       "      <td>17259000.0</td>\n",
       "      <td>6024800.0</td>\n",
       "      <td>7.23700</td>\n",
       "      <td>23971300.0</td>\n",
       "      <td>5709190.0</td>\n",
       "      <td>7.23638</td>\n",
       "      <td>24023700.0</td>\n",
       "      <td>5509570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6039467</td>\n",
       "      <td>2611</td>\n",
       "      <td>2163</td>\n",
       "      <td>2405</td>\n",
       "      <td>3158</td>\n",
       "      <td>302</td>\n",
       "      <td>29</td>\n",
       "      <td>3750</td>\n",
       "      <td>14848</td>\n",
       "      <td>3871</td>\n",
       "      <td>...</td>\n",
       "      <td>4377390.0</td>\n",
       "      <td>7.17020</td>\n",
       "      <td>14032600.0</td>\n",
       "      <td>4030560.0</td>\n",
       "      <td>7.24815</td>\n",
       "      <td>14226700.0</td>\n",
       "      <td>4892320.0</td>\n",
       "      <td>7.16697</td>\n",
       "      <td>8431120.0</td>\n",
       "      <td>4251400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6373582</td>\n",
       "      <td>2460</td>\n",
       "      <td>2156</td>\n",
       "      <td>2249</td>\n",
       "      <td>2598</td>\n",
       "      <td>254</td>\n",
       "      <td>34</td>\n",
       "      <td>3797</td>\n",
       "      <td>13410</td>\n",
       "      <td>3635</td>\n",
       "      <td>...</td>\n",
       "      <td>3158030.0</td>\n",
       "      <td>7.30698</td>\n",
       "      <td>9788700.0</td>\n",
       "      <td>3480750.0</td>\n",
       "      <td>7.30212</td>\n",
       "      <td>21470200.0</td>\n",
       "      <td>3561200.0</td>\n",
       "      <td>7.24143</td>\n",
       "      <td>11508900.0</td>\n",
       "      <td>4689150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6540480</td>\n",
       "      <td>1927</td>\n",
       "      <td>1695</td>\n",
       "      <td>2693</td>\n",
       "      <td>2064</td>\n",
       "      <td>150</td>\n",
       "      <td>20</td>\n",
       "      <td>3528</td>\n",
       "      <td>11961</td>\n",
       "      <td>3197</td>\n",
       "      <td>...</td>\n",
       "      <td>7909290.0</td>\n",
       "      <td>7.16070</td>\n",
       "      <td>8639400.0</td>\n",
       "      <td>7348310.0</td>\n",
       "      <td>7.13381</td>\n",
       "      <td>9441140.0</td>\n",
       "      <td>9105980.0</td>\n",
       "      <td>7.16359</td>\n",
       "      <td>12188300.0</td>\n",
       "      <td>13876400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>8613438</td>\n",
       "      <td>2434</td>\n",
       "      <td>2260</td>\n",
       "      <td>2881</td>\n",
       "      <td>2950</td>\n",
       "      <td>231</td>\n",
       "      <td>23</td>\n",
       "      <td>3435</td>\n",
       "      <td>15226</td>\n",
       "      <td>3553</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6114820</td>\n",
       "      <td>2635</td>\n",
       "      <td>2158</td>\n",
       "      <td>2431</td>\n",
       "      <td>3119</td>\n",
       "      <td>301</td>\n",
       "      <td>29</td>\n",
       "      <td>3764</td>\n",
       "      <td>13113</td>\n",
       "      <td>3816</td>\n",
       "      <td>...</td>\n",
       "      <td>6439070.0</td>\n",
       "      <td>7.20349</td>\n",
       "      <td>10663000.0</td>\n",
       "      <td>7148630.0</td>\n",
       "      <td>7.20098</td>\n",
       "      <td>10286300.0</td>\n",
       "      <td>6726600.0</td>\n",
       "      <td>7.17927</td>\n",
       "      <td>11914600.0</td>\n",
       "      <td>7953000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>5785924</td>\n",
       "      <td>2692</td>\n",
       "      <td>2092</td>\n",
       "      <td>1890</td>\n",
       "      <td>2438</td>\n",
       "      <td>172</td>\n",
       "      <td>32</td>\n",
       "      <td>2980</td>\n",
       "      <td>13100</td>\n",
       "      <td>3527</td>\n",
       "      <td>...</td>\n",
       "      <td>6800430.0</td>\n",
       "      <td>7.16224</td>\n",
       "      <td>11829300.0</td>\n",
       "      <td>6417680.0</td>\n",
       "      <td>7.15213</td>\n",
       "      <td>13580000.0</td>\n",
       "      <td>8086990.0</td>\n",
       "      <td>7.16131</td>\n",
       "      <td>15778400.0</td>\n",
       "      <td>8926450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>6164394</td>\n",
       "      <td>1896</td>\n",
       "      <td>1972</td>\n",
       "      <td>2270</td>\n",
       "      <td>1890</td>\n",
       "      <td>242</td>\n",
       "      <td>19</td>\n",
       "      <td>3114</td>\n",
       "      <td>12613</td>\n",
       "      <td>3310</td>\n",
       "      <td>...</td>\n",
       "      <td>7436190.0</td>\n",
       "      <td>7.31537</td>\n",
       "      <td>9560450.0</td>\n",
       "      <td>6951020.0</td>\n",
       "      <td>7.30938</td>\n",
       "      <td>16958100.0</td>\n",
       "      <td>6263750.0</td>\n",
       "      <td>7.31838</td>\n",
       "      <td>16281500.0</td>\n",
       "      <td>8325060.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6704208</td>\n",
       "      <td>2480</td>\n",
       "      <td>2514</td>\n",
       "      <td>1770</td>\n",
       "      <td>2354</td>\n",
       "      <td>137</td>\n",
       "      <td>20</td>\n",
       "      <td>3839</td>\n",
       "      <td>12513</td>\n",
       "      <td>3202</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>6364286</td>\n",
       "      <td>2038</td>\n",
       "      <td>1603</td>\n",
       "      <td>2539</td>\n",
       "      <td>2127</td>\n",
       "      <td>271</td>\n",
       "      <td>23</td>\n",
       "      <td>2513</td>\n",
       "      <td>12274</td>\n",
       "      <td>2427</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7345869</td>\n",
       "      <td>2282</td>\n",
       "      <td>2353</td>\n",
       "      <td>2380</td>\n",
       "      <td>2631</td>\n",
       "      <td>195</td>\n",
       "      <td>13</td>\n",
       "      <td>3984</td>\n",
       "      <td>14899</td>\n",
       "      <td>4284</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6093748</td>\n",
       "      <td>2140</td>\n",
       "      <td>2092</td>\n",
       "      <td>2592</td>\n",
       "      <td>2660</td>\n",
       "      <td>231</td>\n",
       "      <td>25</td>\n",
       "      <td>3446</td>\n",
       "      <td>12140</td>\n",
       "      <td>2931</td>\n",
       "      <td>...</td>\n",
       "      <td>4408730.0</td>\n",
       "      <td>7.09561</td>\n",
       "      <td>12000400.0</td>\n",
       "      <td>4525870.0</td>\n",
       "      <td>7.13089</td>\n",
       "      <td>10239200.0</td>\n",
       "      <td>4609460.0</td>\n",
       "      <td>7.10369</td>\n",
       "      <td>6642650.0</td>\n",
       "      <td>5297480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>6713812</td>\n",
       "      <td>2648</td>\n",
       "      <td>2580</td>\n",
       "      <td>3657</td>\n",
       "      <td>3502</td>\n",
       "      <td>217</td>\n",
       "      <td>29</td>\n",
       "      <td>4004</td>\n",
       "      <td>17221</td>\n",
       "      <td>4392</td>\n",
       "      <td>...</td>\n",
       "      <td>4598670.0</td>\n",
       "      <td>7.23706</td>\n",
       "      <td>11707800.0</td>\n",
       "      <td>4996590.0</td>\n",
       "      <td>7.23963</td>\n",
       "      <td>9370480.0</td>\n",
       "      <td>4657880.0</td>\n",
       "      <td>7.20636</td>\n",
       "      <td>16949200.0</td>\n",
       "      <td>5592830.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>5746176</td>\n",
       "      <td>2145</td>\n",
       "      <td>2229</td>\n",
       "      <td>2477</td>\n",
       "      <td>2752</td>\n",
       "      <td>223</td>\n",
       "      <td>26</td>\n",
       "      <td>3165</td>\n",
       "      <td>13103</td>\n",
       "      <td>3511</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6280478</td>\n",
       "      <td>2632</td>\n",
       "      <td>2421</td>\n",
       "      <td>2597</td>\n",
       "      <td>2935</td>\n",
       "      <td>217</td>\n",
       "      <td>35</td>\n",
       "      <td>3081</td>\n",
       "      <td>16285</td>\n",
       "      <td>3207</td>\n",
       "      <td>...</td>\n",
       "      <td>4685160.0</td>\n",
       "      <td>7.23799</td>\n",
       "      <td>23517500.0</td>\n",
       "      <td>5222900.0</td>\n",
       "      <td>7.24393</td>\n",
       "      <td>23141100.0</td>\n",
       "      <td>8485940.0</td>\n",
       "      <td>7.23676</td>\n",
       "      <td>11800600.0</td>\n",
       "      <td>5861150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5572301</td>\n",
       "      <td>2192</td>\n",
       "      <td>1973</td>\n",
       "      <td>1786</td>\n",
       "      <td>2602</td>\n",
       "      <td>100</td>\n",
       "      <td>23</td>\n",
       "      <td>2902</td>\n",
       "      <td>11724</td>\n",
       "      <td>2264</td>\n",
       "      <td>...</td>\n",
       "      <td>2952040.0</td>\n",
       "      <td>7.38737</td>\n",
       "      <td>3896040.0</td>\n",
       "      <td>3308080.0</td>\n",
       "      <td>7.35127</td>\n",
       "      <td>3803210.0</td>\n",
       "      <td>3274490.0</td>\n",
       "      <td>7.34936</td>\n",
       "      <td>6164930.0</td>\n",
       "      <td>3256990.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>6149448</td>\n",
       "      <td>1968</td>\n",
       "      <td>2052</td>\n",
       "      <td>2005</td>\n",
       "      <td>1937</td>\n",
       "      <td>199</td>\n",
       "      <td>31</td>\n",
       "      <td>3644</td>\n",
       "      <td>13285</td>\n",
       "      <td>3314</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6350829</td>\n",
       "      <td>2161</td>\n",
       "      <td>1746</td>\n",
       "      <td>1731</td>\n",
       "      <td>2567</td>\n",
       "      <td>207</td>\n",
       "      <td>23</td>\n",
       "      <td>2668</td>\n",
       "      <td>12260</td>\n",
       "      <td>2751</td>\n",
       "      <td>...</td>\n",
       "      <td>6534840.0</td>\n",
       "      <td>7.02620</td>\n",
       "      <td>9714510.0</td>\n",
       "      <td>4492480.0</td>\n",
       "      <td>7.03039</td>\n",
       "      <td>7472740.0</td>\n",
       "      <td>6758980.0</td>\n",
       "      <td>7.03386</td>\n",
       "      <td>15873600.0</td>\n",
       "      <td>6700750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>6537963</td>\n",
       "      <td>2884</td>\n",
       "      <td>2878</td>\n",
       "      <td>1967</td>\n",
       "      <td>2838</td>\n",
       "      <td>256</td>\n",
       "      <td>28</td>\n",
       "      <td>3088</td>\n",
       "      <td>14824</td>\n",
       "      <td>3218</td>\n",
       "      <td>...</td>\n",
       "      <td>3165440.0</td>\n",
       "      <td>7.15097</td>\n",
       "      <td>3923690.0</td>\n",
       "      <td>3363320.0</td>\n",
       "      <td>7.16447</td>\n",
       "      <td>3221150.0</td>\n",
       "      <td>3655820.0</td>\n",
       "      <td>7.15968</td>\n",
       "      <td>4232500.0</td>\n",
       "      <td>3170740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6067945</td>\n",
       "      <td>2275</td>\n",
       "      <td>2363</td>\n",
       "      <td>2486</td>\n",
       "      <td>2348</td>\n",
       "      <td>267</td>\n",
       "      <td>20</td>\n",
       "      <td>3934</td>\n",
       "      <td>14308</td>\n",
       "      <td>3850</td>\n",
       "      <td>...</td>\n",
       "      <td>4157920.0</td>\n",
       "      <td>7.10053</td>\n",
       "      <td>11185400.0</td>\n",
       "      <td>4262490.0</td>\n",
       "      <td>7.10751</td>\n",
       "      <td>12168900.0</td>\n",
       "      <td>4473290.0</td>\n",
       "      <td>7.09959</td>\n",
       "      <td>13768100.0</td>\n",
       "      <td>4667660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6285368</td>\n",
       "      <td>2563</td>\n",
       "      <td>2487</td>\n",
       "      <td>2110</td>\n",
       "      <td>2322</td>\n",
       "      <td>245</td>\n",
       "      <td>25</td>\n",
       "      <td>2775</td>\n",
       "      <td>13583</td>\n",
       "      <td>3849</td>\n",
       "      <td>...</td>\n",
       "      <td>3449140.0</td>\n",
       "      <td>7.09802</td>\n",
       "      <td>9479110.0</td>\n",
       "      <td>5330700.0</td>\n",
       "      <td>7.07677</td>\n",
       "      <td>7273380.0</td>\n",
       "      <td>4380770.0</td>\n",
       "      <td>7.09542</td>\n",
       "      <td>5945320.0</td>\n",
       "      <td>4033600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6026680</td>\n",
       "      <td>2274</td>\n",
       "      <td>1994</td>\n",
       "      <td>2520</td>\n",
       "      <td>2332</td>\n",
       "      <td>266</td>\n",
       "      <td>33</td>\n",
       "      <td>3009</td>\n",
       "      <td>14443</td>\n",
       "      <td>3427</td>\n",
       "      <td>...</td>\n",
       "      <td>3784810.0</td>\n",
       "      <td>7.00368</td>\n",
       "      <td>7966720.0</td>\n",
       "      <td>4045010.0</td>\n",
       "      <td>7.02016</td>\n",
       "      <td>12148800.0</td>\n",
       "      <td>4825690.0</td>\n",
       "      <td>7.00466</td>\n",
       "      <td>9127580.0</td>\n",
       "      <td>7253280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>6102147</td>\n",
       "      <td>2128</td>\n",
       "      <td>2070</td>\n",
       "      <td>2358</td>\n",
       "      <td>2925</td>\n",
       "      <td>172</td>\n",
       "      <td>31</td>\n",
       "      <td>4243</td>\n",
       "      <td>9938</td>\n",
       "      <td>4895</td>\n",
       "      <td>...</td>\n",
       "      <td>4105180.0</td>\n",
       "      <td>7.14724</td>\n",
       "      <td>19345700.0</td>\n",
       "      <td>3924500.0</td>\n",
       "      <td>7.17344</td>\n",
       "      <td>16881500.0</td>\n",
       "      <td>4414750.0</td>\n",
       "      <td>7.09850</td>\n",
       "      <td>14488100.0</td>\n",
       "      <td>4687230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5894582</td>\n",
       "      <td>2689</td>\n",
       "      <td>2593</td>\n",
       "      <td>2229</td>\n",
       "      <td>2028</td>\n",
       "      <td>211</td>\n",
       "      <td>51</td>\n",
       "      <td>3441</td>\n",
       "      <td>10132</td>\n",
       "      <td>2833</td>\n",
       "      <td>...</td>\n",
       "      <td>1952570.0</td>\n",
       "      <td>7.16399</td>\n",
       "      <td>9853070.0</td>\n",
       "      <td>2727410.0</td>\n",
       "      <td>7.20734</td>\n",
       "      <td>8994040.0</td>\n",
       "      <td>2798600.0</td>\n",
       "      <td>7.16715</td>\n",
       "      <td>8209940.0</td>\n",
       "      <td>2380010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5864365</td>\n",
       "      <td>2004</td>\n",
       "      <td>2145</td>\n",
       "      <td>1637</td>\n",
       "      <td>2564</td>\n",
       "      <td>231</td>\n",
       "      <td>22</td>\n",
       "      <td>2946</td>\n",
       "      <td>14536</td>\n",
       "      <td>2708</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6054574</td>\n",
       "      <td>1953</td>\n",
       "      <td>1776</td>\n",
       "      <td>1935</td>\n",
       "      <td>1989</td>\n",
       "      <td>173</td>\n",
       "      <td>22</td>\n",
       "      <td>2772</td>\n",
       "      <td>10825</td>\n",
       "      <td>2779</td>\n",
       "      <td>...</td>\n",
       "      <td>4644190.0</td>\n",
       "      <td>7.31287</td>\n",
       "      <td>16120700.0</td>\n",
       "      <td>5263040.0</td>\n",
       "      <td>7.30877</td>\n",
       "      <td>13869000.0</td>\n",
       "      <td>6048170.0</td>\n",
       "      <td>7.30881</td>\n",
       "      <td>11416500.0</td>\n",
       "      <td>3904680.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>6340437</td>\n",
       "      <td>2304</td>\n",
       "      <td>2130</td>\n",
       "      <td>2071</td>\n",
       "      <td>2378</td>\n",
       "      <td>293</td>\n",
       "      <td>29</td>\n",
       "      <td>3910</td>\n",
       "      <td>15962</td>\n",
       "      <td>3747</td>\n",
       "      <td>...</td>\n",
       "      <td>8633670.0</td>\n",
       "      <td>7.27280</td>\n",
       "      <td>14729700.0</td>\n",
       "      <td>7208380.0</td>\n",
       "      <td>7.28291</td>\n",
       "      <td>11988800.0</td>\n",
       "      <td>8406620.0</td>\n",
       "      <td>7.28261</td>\n",
       "      <td>17215000.0</td>\n",
       "      <td>7985350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>5713787</td>\n",
       "      <td>2601</td>\n",
       "      <td>2511</td>\n",
       "      <td>2278</td>\n",
       "      <td>2762</td>\n",
       "      <td>191</td>\n",
       "      <td>14</td>\n",
       "      <td>3127</td>\n",
       "      <td>12484</td>\n",
       "      <td>3880</td>\n",
       "      <td>...</td>\n",
       "      <td>5804890.0</td>\n",
       "      <td>7.16574</td>\n",
       "      <td>16551100.0</td>\n",
       "      <td>6303830.0</td>\n",
       "      <td>7.16693</td>\n",
       "      <td>15778700.0</td>\n",
       "      <td>8052560.0</td>\n",
       "      <td>7.16649</td>\n",
       "      <td>11506500.0</td>\n",
       "      <td>6732150.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 1770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    allvol_unknown  allvol_ctx_rh_posterior_insula  \\\n",
       "74         6059622                            2528   \n",
       "6          6333243                            2154   \n",
       "39         6271620                            2338   \n",
       "84         6279553                            2193   \n",
       "11         5840323                            2248   \n",
       "24         6345977                            2597   \n",
       "3          7132726                            1984   \n",
       "1          6300324                            2079   \n",
       "61         6317414                            2377   \n",
       "50         5783011                            1891   \n",
       "63         5813624                            2432   \n",
       "60         5877985                            2297   \n",
       "52         7073802                            2797   \n",
       "72         5701761                            2344   \n",
       "51         5615278                            2398   \n",
       "80         5916360                            2200   \n",
       "64         5814463                            2441   \n",
       "70         6172580                            2782   \n",
       "31         6774342                            2480   \n",
       "16         5865161                            2054   \n",
       "2          6219262                            2527   \n",
       "10         6151157                            2473   \n",
       "81         5765673                            2059   \n",
       "34         6452080                            2268   \n",
       "20         6191830                            2619   \n",
       "0          6281946                            1708   \n",
       "36         6184901                            2375   \n",
       "62         5822814                            1841   \n",
       "46         5412720                            1746   \n",
       "21         6478225                            2604   \n",
       "69         5905974                            1931   \n",
       "44         6595517                            2732   \n",
       "32         7104555                            1986   \n",
       "79         6153593                            1679   \n",
       "53         6497474                            2844   \n",
       "37         6190825                            2819   \n",
       "19         6500098                            2816   \n",
       "22         6616436                            2448   \n",
       "13         5791334                            1968   \n",
       "73         6008394                            2714   \n",
       "66         6386455                            2066   \n",
       "54         6003911                            2469   \n",
       "49         5575197                            2118   \n",
       "35         5735873                            2475   \n",
       "55         6664760                            2999   \n",
       "38        12280771                            1706   \n",
       "67         6061795                            1804   \n",
       "75         5906664                            2313   \n",
       "77         6039066                            2597   \n",
       "7          6159812                            2333   \n",
       "86         6525153                            2875   \n",
       "18         6039467                            2611   \n",
       "5          6373582                            2460   \n",
       "29         6540480                            1927   \n",
       "40         8613438                            2434   \n",
       "17         6114820                            2635   \n",
       "57         5785924                            2692   \n",
       "78         6164394                            1896   \n",
       "26         6704208                            2480   \n",
       "83         6364286                            2038   \n",
       "15         7345869                            2282   \n",
       "12         6093748                            2140   \n",
       "48         6713812                            2648   \n",
       "71         5746176                            2145   \n",
       "27         6280478                            2632   \n",
       "25         5572301                            2192   \n",
       "43         6149448                            1968   \n",
       "8          6350829                            2161   \n",
       "68         6537963                            2884   \n",
       "28         6067945                            2275   \n",
       "65         6285368                            2563   \n",
       "23         6026680                            2274   \n",
       "45         6102147                            2128   \n",
       "14         5894582                            2689   \n",
       "42         5864365                            2004   \n",
       "4          6054574                            1953   \n",
       "82         6340437                            2304   \n",
       "87         5713787                            2601   \n",
       "\n",
       "    allvol_ctx_lh_posterior_insula  allvol_ctx_rh_parietal_operculum  \\\n",
       "74                            2588                              2837   \n",
       "6                             2312                              2588   \n",
       "39                            2243                              2670   \n",
       "84                            2228                              2666   \n",
       "11                            2057                              2100   \n",
       "24                            2552                              2502   \n",
       "3                             2058                              2567   \n",
       "1                             2096                              2211   \n",
       "61                            2230                              2642   \n",
       "50                            1918                              2038   \n",
       "63                            2097                              2632   \n",
       "60                            2263                              2459   \n",
       "52                            2550                              2525   \n",
       "72                            2166                              1996   \n",
       "51                            2153                              2062   \n",
       "80                            2029                              1853   \n",
       "64                            2100                              2668   \n",
       "70                            2708                              3073   \n",
       "31                            2363                              2065   \n",
       "16                            2063                              1929   \n",
       "2                             2301                              2922   \n",
       "10                            2300                              2242   \n",
       "81                            2131                              2205   \n",
       "34                            2505                              1952   \n",
       "20                            2447                              2197   \n",
       "0                             1893                              1895   \n",
       "36                            2314                              2456   \n",
       "62                            1645                              2055   \n",
       "46                            1651                              1656   \n",
       "21                            2267                              2706   \n",
       "69                            1898                              2346   \n",
       "44                            2216                              2809   \n",
       "32                            1978                              1415   \n",
       "79                            1899                              1968   \n",
       "53                            2643                              2610   \n",
       "37                            3007                              2720   \n",
       "19                            2523                              3709   \n",
       "22                            2687                              2904   \n",
       "13                            2085                              2236   \n",
       "73                            2656                              2187   \n",
       "66                            1971                              1339   \n",
       "54                            2238                              2957   \n",
       "49                            2135                              2095   \n",
       "35                            2316                              3011   \n",
       "55                            2907                              2328   \n",
       "38                            1301                               460   \n",
       "67                            1734                              2116   \n",
       "75                            2296                              2630   \n",
       "77                            2356                              3000   \n",
       "7                             2362                              2985   \n",
       "86                            2765                              1963   \n",
       "18                            2163                              2405   \n",
       "5                             2156                              2249   \n",
       "29                            1695                              2693   \n",
       "40                            2260                              2881   \n",
       "17                            2158                              2431   \n",
       "57                            2092                              1890   \n",
       "78                            1972                              2270   \n",
       "26                            2514                              1770   \n",
       "83                            1603                              2539   \n",
       "15                            2353                              2380   \n",
       "12                            2092                              2592   \n",
       "48                            2580                              3657   \n",
       "71                            2229                              2477   \n",
       "27                            2421                              2597   \n",
       "25                            1973                              1786   \n",
       "43                            2052                              2005   \n",
       "8                             1746                              1731   \n",
       "68                            2878                              1967   \n",
       "28                            2363                              2486   \n",
       "65                            2487                              2110   \n",
       "23                            1994                              2520   \n",
       "45                            2070                              2358   \n",
       "14                            2593                              2229   \n",
       "42                            2145                              1637   \n",
       "4                             1776                              1935   \n",
       "82                            2130                              2071   \n",
       "87                            2511                              2278   \n",
       "\n",
       "    allvol_ctx_lh_parietal_operculum  allvol_left_lateral_ventricle  \\\n",
       "74                              3282                            288   \n",
       "6                               2536                            203   \n",
       "39                              1728                            199   \n",
       "84                              2692                            217   \n",
       "11                              2254                            222   \n",
       "24                              2076                            196   \n",
       "3                               1479                            187   \n",
       "1                               2329                            217   \n",
       "61                              2869                            233   \n",
       "50                              1845                            287   \n",
       "63                              2361                            273   \n",
       "60                              2072                            248   \n",
       "52                              3661                            272   \n",
       "72                              2538                            273   \n",
       "51                              2119                            149   \n",
       "80                              2265                            176   \n",
       "64                              2336                            276   \n",
       "70                              3315                            212   \n",
       "31                              2890                            282   \n",
       "16                              1980                            180   \n",
       "2                               2807                            246   \n",
       "10                              2156                            245   \n",
       "81                              2053                            214   \n",
       "34                              2379                            211   \n",
       "20                              3207                            317   \n",
       "0                               2076                            183   \n",
       "36                              2537                            238   \n",
       "62                              2070                            185   \n",
       "46                              2089                            204   \n",
       "21                              2721                            275   \n",
       "69                              2363                            180   \n",
       "44                              2535                            232   \n",
       "32                              2611                            235   \n",
       "79                              1995                            239   \n",
       "53                              2159                            241   \n",
       "37                              3733                            219   \n",
       "19                              3680                            287   \n",
       "22                              2665                            231   \n",
       "13                              1876                            196   \n",
       "73                              2374                            240   \n",
       "66                              2336                            195   \n",
       "54                              2905                            203   \n",
       "49                              2278                            212   \n",
       "35                              2928                            248   \n",
       "55                              2862                            198   \n",
       "38                              1517                             58   \n",
       "67                              1868                            231   \n",
       "75                              2108                            216   \n",
       "77                              3223                            209   \n",
       "7                               3543                            170   \n",
       "86                              2734                            238   \n",
       "18                              3158                            302   \n",
       "5                               2598                            254   \n",
       "29                              2064                            150   \n",
       "40                              2950                            231   \n",
       "17                              3119                            301   \n",
       "57                              2438                            172   \n",
       "78                              1890                            242   \n",
       "26                              2354                            137   \n",
       "83                              2127                            271   \n",
       "15                              2631                            195   \n",
       "12                              2660                            231   \n",
       "48                              3502                            217   \n",
       "71                              2752                            223   \n",
       "27                              2935                            217   \n",
       "25                              2602                            100   \n",
       "43                              1937                            199   \n",
       "8                               2567                            207   \n",
       "68                              2838                            256   \n",
       "28                              2348                            267   \n",
       "65                              2322                            245   \n",
       "23                              2332                            266   \n",
       "45                              2925                            172   \n",
       "14                              2028                            211   \n",
       "42                              2564                            231   \n",
       "4                               1989                            173   \n",
       "82                              2378                            293   \n",
       "87                              2762                            191   \n",
       "\n",
       "    allvol_left_inf_lat_vent  allvol_ctx_rh_post_orbital_gyrus  \\\n",
       "74                        25                              3783   \n",
       "6                         27                              3150   \n",
       "39                        11                              2714   \n",
       "84                        19                              3246   \n",
       "11                        18                              3353   \n",
       "24                        26                              4288   \n",
       "3                          6                              3093   \n",
       "1                         22                              2529   \n",
       "61                        24                              2938   \n",
       "50                        31                              3238   \n",
       "63                        34                              3001   \n",
       "60                        18                              2422   \n",
       "52                        29                              3135   \n",
       "72                        20                              3189   \n",
       "51                        21                              3515   \n",
       "80                        10                              3049   \n",
       "64                        36                              3010   \n",
       "70                        26                              3985   \n",
       "31                        20                              2841   \n",
       "16                        28                              2505   \n",
       "2                         17                              2955   \n",
       "10                        35                              3153   \n",
       "81                        20                              3077   \n",
       "34                        27                              4638   \n",
       "20                        24                              4377   \n",
       "0                         28                              2282   \n",
       "36                        18                              2590   \n",
       "62                        23                              3289   \n",
       "46                        13                              2200   \n",
       "21                         9                              2905   \n",
       "69                        24                              3133   \n",
       "44                        28                              3760   \n",
       "32                        31                              2564   \n",
       "79                        14                              3126   \n",
       "53                        30                              4149   \n",
       "37                        22                              4260   \n",
       "19                        41                              3485   \n",
       "22                        24                              2754   \n",
       "13                        28                              2706   \n",
       "73                        30                              3123   \n",
       "66                        22                              3145   \n",
       "54                        18                              3989   \n",
       "49                        21                              2911   \n",
       "35                        27                              2995   \n",
       "55                        23                              3364   \n",
       "38                        89                               897   \n",
       "67                        25                              3017   \n",
       "75                        25                              3326   \n",
       "77                        19                              3678   \n",
       "7                         18                              4375   \n",
       "86                        14                              3613   \n",
       "18                        29                              3750   \n",
       "5                         34                              3797   \n",
       "29                        20                              3528   \n",
       "40                        23                              3435   \n",
       "17                        29                              3764   \n",
       "57                        32                              2980   \n",
       "78                        19                              3114   \n",
       "26                        20                              3839   \n",
       "83                        23                              2513   \n",
       "15                        13                              3984   \n",
       "12                        25                              3446   \n",
       "48                        29                              4004   \n",
       "71                        26                              3165   \n",
       "27                        35                              3081   \n",
       "25                        23                              2902   \n",
       "43                        31                              3644   \n",
       "8                         23                              2668   \n",
       "68                        28                              3088   \n",
       "28                        20                              3934   \n",
       "65                        25                              2775   \n",
       "23                        33                              3009   \n",
       "45                        31                              4243   \n",
       "14                        51                              3441   \n",
       "42                        22                              2946   \n",
       "4                         22                              2772   \n",
       "82                        29                              3910   \n",
       "87                        14                              3127   \n",
       "\n",
       "    allvol_left_cerebellum_wm  allvol_ctx_lh_post_orbital_gyrus  ...  \\\n",
       "74                      15058                              3284  ...   \n",
       "6                       12130                              2822  ...   \n",
       "39                      11760                              3051  ...   \n",
       "84                      14333                              3169  ...   \n",
       "11                      11117                              4135  ...   \n",
       "24                      13166                              4648  ...   \n",
       "3                       11416                              2914  ...   \n",
       "1                       14655                              2198  ...   \n",
       "61                      12312                              3165  ...   \n",
       "50                      12171                              2645  ...   \n",
       "63                      12293                              2863  ...   \n",
       "60                      12079                              2692  ...   \n",
       "52                      18782                              3547  ...   \n",
       "72                      11190                              2704  ...   \n",
       "51                       9931                              2715  ...   \n",
       "80                      11987                              3304  ...   \n",
       "64                      12617                              2855  ...   \n",
       "70                      14253                              4127  ...   \n",
       "31                      16469                              2845  ...   \n",
       "16                      11660                              2648  ...   \n",
       "2                       13294                              3238  ...   \n",
       "10                      13936                              3385  ...   \n",
       "81                      15997                              3532  ...   \n",
       "34                      14504                              3975  ...   \n",
       "20                      12868                              3169  ...   \n",
       "0                       11770                              2775  ...   \n",
       "36                      11963                              2881  ...   \n",
       "62                      11807                              3037  ...   \n",
       "46                      10998                              2217  ...   \n",
       "21                      12203                              3159  ...   \n",
       "69                      12563                              3048  ...   \n",
       "44                      14321                              4101  ...   \n",
       "32                      12076                              2583  ...   \n",
       "79                      12904                              2444  ...   \n",
       "53                      12562                              3922  ...   \n",
       "37                      14188                              4814  ...   \n",
       "19                      15355                              3939  ...   \n",
       "22                      14444                              2785  ...   \n",
       "13                      12071                              2659  ...   \n",
       "73                      13085                              3022  ...   \n",
       "66                      14046                              2849  ...   \n",
       "54                      12678                              4272  ...   \n",
       "49                      11098                              2889  ...   \n",
       "35                      12881                              3269  ...   \n",
       "55                      15310                              3130  ...   \n",
       "38                        484                               233  ...   \n",
       "67                      11621                              2430  ...   \n",
       "75                      11519                              3311  ...   \n",
       "77                      14109                              3439  ...   \n",
       "7                       12062                              4843  ...   \n",
       "86                      13711                              3539  ...   \n",
       "18                      14848                              3871  ...   \n",
       "5                       13410                              3635  ...   \n",
       "29                      11961                              3197  ...   \n",
       "40                      15226                              3553  ...   \n",
       "17                      13113                              3816  ...   \n",
       "57                      13100                              3527  ...   \n",
       "78                      12613                              3310  ...   \n",
       "26                      12513                              3202  ...   \n",
       "83                      12274                              2427  ...   \n",
       "15                      14899                              4284  ...   \n",
       "12                      12140                              2931  ...   \n",
       "48                      17221                              4392  ...   \n",
       "71                      13103                              3511  ...   \n",
       "27                      16285                              3207  ...   \n",
       "25                      11724                              2264  ...   \n",
       "43                      13285                              3314  ...   \n",
       "8                       12260                              2751  ...   \n",
       "68                      14824                              3218  ...   \n",
       "28                      14308                              3850  ...   \n",
       "65                      13583                              3849  ...   \n",
       "23                      14443                              3427  ...   \n",
       "45                       9938                              4895  ...   \n",
       "14                      10132                              2833  ...   \n",
       "42                      14536                              2708  ...   \n",
       "4                       10825                              2779  ...   \n",
       "82                      15962                              3747  ...   \n",
       "87                      12484                              3880  ...   \n",
       "\n",
       "    31p_r_paroperc_aatp  31p_l_wm_parcing_ph  31p_l_wm_parcing_gatp  \\\n",
       "74                  NaN                  NaN                    NaN   \n",
       "6             2669620.0              7.16438              6611740.0   \n",
       "39            6376530.0              7.23973             11951100.0   \n",
       "84                  NaN                  NaN                    NaN   \n",
       "11            4219870.0              7.16605              7225530.0   \n",
       "24                  NaN                  NaN                    NaN   \n",
       "3             2967320.0              7.18370              7300780.0   \n",
       "1             3318770.0              7.24271              8032880.0   \n",
       "61            3488680.0              7.15247              4836200.0   \n",
       "50            4576130.0              7.16644             15837700.0   \n",
       "63            5093020.0              7.30527              7087840.0   \n",
       "60            4311700.0              7.23210              5873980.0   \n",
       "52                  NaN                  NaN                    NaN   \n",
       "72            4947720.0              7.38346             14797200.0   \n",
       "51            2745060.0              7.24964              4451050.0   \n",
       "80           12894500.0              7.16301             23993600.0   \n",
       "64                  NaN                  NaN                    NaN   \n",
       "70                  NaN                  NaN                    NaN   \n",
       "31                  NaN                  NaN                    NaN   \n",
       "16            6741250.0              7.16610             18337700.0   \n",
       "2             2835030.0              7.16535              8229570.0   \n",
       "10             414169.0              7.17096               672485.0   \n",
       "81           11126800.0              7.16359             29332200.0   \n",
       "34            4550500.0              7.16324              3950570.0   \n",
       "20            6420720.0              7.08810             17232300.0   \n",
       "0                   NaN                  NaN                    NaN   \n",
       "36           10077100.0              7.07568             32348300.0   \n",
       "62                  NaN                  NaN                    NaN   \n",
       "46            5022980.0              7.08891             12804100.0   \n",
       "21                  NaN                  NaN                    NaN   \n",
       "69                  NaN                  NaN                    NaN   \n",
       "44            4605720.0              7.07550             10908100.0   \n",
       "32                  NaN                  NaN                    NaN   \n",
       "79                  NaN                  NaN                    NaN   \n",
       "53            5166810.0              7.24250             16333100.0   \n",
       "37            5390730.0              7.16050             10740900.0   \n",
       "19                  NaN                  NaN                    NaN   \n",
       "22            6519020.0              7.18951             31108100.0   \n",
       "13            4899180.0              7.29131              9351010.0   \n",
       "73            5914810.0              7.17807             37955300.0   \n",
       "66            3697850.0              7.18599              7512530.0   \n",
       "54            5714180.0              7.21084              9375400.0   \n",
       "49                  NaN                  NaN                    NaN   \n",
       "35            5939480.0              7.30916             21116300.0   \n",
       "55            3721330.0              7.30932              7291980.0   \n",
       "38                  NaN                  NaN                    NaN   \n",
       "67            3404910.0              7.30889              5325750.0   \n",
       "75           16281700.0              7.18506            139893000.0   \n",
       "77                  NaN                  NaN                    NaN   \n",
       "7             3624550.0              7.24637              7889820.0   \n",
       "86            6625790.0              7.22924             17259000.0   \n",
       "18            4377390.0              7.17020             14032600.0   \n",
       "5             3158030.0              7.30698              9788700.0   \n",
       "29            7909290.0              7.16070              8639400.0   \n",
       "40                  NaN                  NaN                    NaN   \n",
       "17            6439070.0              7.20349             10663000.0   \n",
       "57            6800430.0              7.16224             11829300.0   \n",
       "78            7436190.0              7.31537              9560450.0   \n",
       "26                  NaN                  NaN                    NaN   \n",
       "83                  NaN                  NaN                    NaN   \n",
       "15                  NaN                  NaN                    NaN   \n",
       "12            4408730.0              7.09561             12000400.0   \n",
       "48            4598670.0              7.23706             11707800.0   \n",
       "71                  NaN                  NaN                    NaN   \n",
       "27            4685160.0              7.23799             23517500.0   \n",
       "25            2952040.0              7.38737              3896040.0   \n",
       "43                  NaN                  NaN                    NaN   \n",
       "8             6534840.0              7.02620              9714510.0   \n",
       "68            3165440.0              7.15097              3923690.0   \n",
       "28            4157920.0              7.10053             11185400.0   \n",
       "65            3449140.0              7.09802              9479110.0   \n",
       "23            3784810.0              7.00368              7966720.0   \n",
       "45            4105180.0              7.14724             19345700.0   \n",
       "14            1952570.0              7.16399              9853070.0   \n",
       "42                  NaN                  NaN                    NaN   \n",
       "4             4644190.0              7.31287             16120700.0   \n",
       "82            8633670.0              7.27280             14729700.0   \n",
       "87            5804890.0              7.16574             16551100.0   \n",
       "\n",
       "    31p_l_wm_parcing_aatp  31p_cc_ant_ph  31p_cc_ant_gatp  31p_cc_ant_aatp  \\\n",
       "74                    NaN            NaN              NaN              NaN   \n",
       "6               3234290.0        7.13503        7858490.0        3510950.0   \n",
       "39              5826170.0        7.30665       29879000.0        8074850.0   \n",
       "84                    NaN            NaN              NaN              NaN   \n",
       "11              4172340.0        7.32276        8515520.0        4170950.0   \n",
       "24                    NaN            NaN              NaN              NaN   \n",
       "3               3713600.0        7.23577        9900240.0        3497420.0   \n",
       "1               5110710.0        7.24266        5918480.0        8678260.0   \n",
       "61              2995810.0        7.15518        5731290.0        3189580.0   \n",
       "50              4574200.0        7.14947       12317800.0        4811700.0   \n",
       "63              5091070.0        7.27818        5160080.0        5092370.0   \n",
       "60              4279970.0        7.23703        6863870.0        4359720.0   \n",
       "52                    NaN            NaN              NaN              NaN   \n",
       "72              5708510.0        7.38758       13278200.0        4281760.0   \n",
       "51              2097980.0        7.20895        7767310.0        2914480.0   \n",
       "80             12755000.0        7.16586       28904900.0        9822850.0   \n",
       "64                    NaN            NaN              NaN              NaN   \n",
       "70                    NaN            NaN              NaN              NaN   \n",
       "31                    NaN            NaN              NaN              NaN   \n",
       "16              7255980.0        7.16712       17752700.0        7467770.0   \n",
       "2               2739530.0        7.16537        8242230.0        3362510.0   \n",
       "10               317153.0        7.13043         519456.0         470314.0   \n",
       "81             11767500.0        7.15584       18228100.0        9979020.0   \n",
       "34              6089740.0        7.09062        3564150.0        4259950.0   \n",
       "20              7437530.0        7.16660       24824800.0        7771480.0   \n",
       "0                     NaN            NaN              NaN              NaN   \n",
       "36              7823790.0        7.08579       24078800.0        8451840.0   \n",
       "62                    NaN            NaN              NaN              NaN   \n",
       "46              5553580.0        7.09749       10573100.0        6594220.0   \n",
       "21                    NaN            NaN              NaN              NaN   \n",
       "69                    NaN            NaN              NaN              NaN   \n",
       "44              5376510.0        7.10400       11702600.0        6254670.0   \n",
       "32                    NaN            NaN              NaN              NaN   \n",
       "79                    NaN            NaN              NaN              NaN   \n",
       "53              5488730.0        7.21844       13230900.0        6035990.0   \n",
       "37              4346480.0        7.21978       18394100.0        6139840.0   \n",
       "19                    NaN            NaN              NaN              NaN   \n",
       "22              5751750.0        7.16696       26534300.0        5369030.0   \n",
       "13              4259930.0        7.26006        9073540.0        5571050.0   \n",
       "73              6290960.0        7.12576       49785000.0        6582480.0   \n",
       "66              3592270.0        7.13018        8232850.0        4170410.0   \n",
       "54              5578490.0        7.19742        9407080.0        4957180.0   \n",
       "49                    NaN            NaN              NaN              NaN   \n",
       "35              7130210.0        7.29825       28021900.0        6892660.0   \n",
       "55              3867050.0        7.30966       12213200.0        3806780.0   \n",
       "38                    NaN            NaN              NaN              NaN   \n",
       "67              4056660.0        7.31046        4809680.0        3372650.0   \n",
       "75             77030300.0        7.16457       86780500.0       24879300.0   \n",
       "77                    NaN            NaN              NaN              NaN   \n",
       "7               3774180.0        7.23639       12819700.0        5100150.0   \n",
       "86              6024800.0        7.23700       23971300.0        5709190.0   \n",
       "18              4030560.0        7.24815       14226700.0        4892320.0   \n",
       "5               3480750.0        7.30212       21470200.0        3561200.0   \n",
       "29              7348310.0        7.13381        9441140.0        9105980.0   \n",
       "40                    NaN            NaN              NaN              NaN   \n",
       "17              7148630.0        7.20098       10286300.0        6726600.0   \n",
       "57              6417680.0        7.15213       13580000.0        8086990.0   \n",
       "78              6951020.0        7.30938       16958100.0        6263750.0   \n",
       "26                    NaN            NaN              NaN              NaN   \n",
       "83                    NaN            NaN              NaN              NaN   \n",
       "15                    NaN            NaN              NaN              NaN   \n",
       "12              4525870.0        7.13089       10239200.0        4609460.0   \n",
       "48              4996590.0        7.23963        9370480.0        4657880.0   \n",
       "71                    NaN            NaN              NaN              NaN   \n",
       "27              5222900.0        7.24393       23141100.0        8485940.0   \n",
       "25              3308080.0        7.35127        3803210.0        3274490.0   \n",
       "43                    NaN            NaN              NaN              NaN   \n",
       "8               4492480.0        7.03039        7472740.0        6758980.0   \n",
       "68              3363320.0        7.16447        3221150.0        3655820.0   \n",
       "28              4262490.0        7.10751       12168900.0        4473290.0   \n",
       "65              5330700.0        7.07677        7273380.0        4380770.0   \n",
       "23              4045010.0        7.02016       12148800.0        4825690.0   \n",
       "45              3924500.0        7.17344       16881500.0        4414750.0   \n",
       "14              2727410.0        7.20734        8994040.0        2798600.0   \n",
       "42                    NaN            NaN              NaN              NaN   \n",
       "4               5263040.0        7.30877       13869000.0        6048170.0   \n",
       "82              7208380.0        7.28291       11988800.0        8406620.0   \n",
       "87              6303830.0        7.16693       15778700.0        8052560.0   \n",
       "\n",
       "    31p_l_pat_ph  31p_l_pat_gatp  31p_l_pat_aatp  \n",
       "74           NaN             NaN             NaN  \n",
       "6        7.16700      11857700.0       4044550.0  \n",
       "39       7.31797      15524700.0       8256190.0  \n",
       "84           NaN             NaN             NaN  \n",
       "11       7.23482       8056600.0       4783130.0  \n",
       "24           NaN             NaN             NaN  \n",
       "3        7.23599       5744920.0       3075420.0  \n",
       "1        7.24003       3556370.0       3544560.0  \n",
       "61       7.16605       4384660.0       3341830.0  \n",
       "50       7.13478      17156400.0       4703430.0  \n",
       "63       7.30372      11967900.0       4269350.0  \n",
       "60       7.23604       9509390.0       5981970.0  \n",
       "52           NaN             NaN             NaN  \n",
       "72       7.38298      10141200.0       5332180.0  \n",
       "51       7.23388       4157560.0       2966380.0  \n",
       "80       7.15195      45370800.0      11265400.0  \n",
       "64           NaN             NaN             NaN  \n",
       "70           NaN             NaN             NaN  \n",
       "31           NaN             NaN             NaN  \n",
       "16       7.16778      10680900.0       9164790.0  \n",
       "2        7.16535       6115790.0       4545140.0  \n",
       "10       7.16536        531852.0        404226.0  \n",
       "81       7.15757      31155800.0      16931400.0  \n",
       "34       7.09540       3748660.0       3571750.0  \n",
       "20       7.09903      20568600.0      11024000.0  \n",
       "0            NaN             NaN             NaN  \n",
       "36       7.06532      20758000.0       8603840.0  \n",
       "62           NaN             NaN             NaN  \n",
       "46       7.09587       7831260.0       5644400.0  \n",
       "21           NaN             NaN             NaN  \n",
       "69           NaN             NaN             NaN  \n",
       "44       7.09608      11407400.0       7939670.0  \n",
       "32           NaN             NaN             NaN  \n",
       "79           NaN             NaN             NaN  \n",
       "53       7.23694      12490900.0       8797310.0  \n",
       "37       7.10606      22174000.0       7327000.0  \n",
       "19           NaN             NaN             NaN  \n",
       "22       7.17709      19705200.0      13128900.0  \n",
       "13       7.27293       7662500.0       5961710.0  \n",
       "73       7.16139      20535900.0      11972000.0  \n",
       "66       7.13461       6294010.0       3597260.0  \n",
       "54       7.14830      13119700.0       5515800.0  \n",
       "49           NaN             NaN             NaN  \n",
       "35       7.31148      18897400.0       8166430.0  \n",
       "55       7.30933       8804540.0       3673750.0  \n",
       "38           NaN             NaN             NaN  \n",
       "67       7.30199       6261400.0       3420730.0  \n",
       "75       7.19108      73154500.0      22788100.0  \n",
       "77           NaN             NaN             NaN  \n",
       "7        7.23767      13779100.0       3584500.0  \n",
       "86       7.23638      24023700.0       5509570.0  \n",
       "18       7.16697       8431120.0       4251400.0  \n",
       "5        7.24143      11508900.0       4689150.0  \n",
       "29       7.16359      12188300.0      13876400.0  \n",
       "40           NaN             NaN             NaN  \n",
       "17       7.17927      11914600.0       7953000.0  \n",
       "57       7.16131      15778400.0       8926450.0  \n",
       "78       7.31838      16281500.0       8325060.0  \n",
       "26           NaN             NaN             NaN  \n",
       "83           NaN             NaN             NaN  \n",
       "15           NaN             NaN             NaN  \n",
       "12       7.10369       6642650.0       5297480.0  \n",
       "48       7.20636      16949200.0       5592830.0  \n",
       "71           NaN             NaN             NaN  \n",
       "27       7.23676      11800600.0       5861150.0  \n",
       "25       7.34936       6164930.0       3256990.0  \n",
       "43           NaN             NaN             NaN  \n",
       "8        7.03386      15873600.0       6700750.0  \n",
       "68       7.15968       4232500.0       3170740.0  \n",
       "28       7.09959      13768100.0       4667660.0  \n",
       "65       7.09542       5945320.0       4033600.0  \n",
       "23       7.00466       9127580.0       7253280.0  \n",
       "45       7.09850      14488100.0       4687230.0  \n",
       "14       7.16715       8209940.0       2380010.0  \n",
       "42           NaN             NaN             NaN  \n",
       "4        7.30881      11416500.0       3904680.0  \n",
       "82       7.28261      17215000.0       7985350.0  \n",
       "87       7.16649      11506500.0       6732150.0  \n",
       "\n",
       "[78 rows x 1770 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([41.72381091, 42.47403693, 44.12210155, 44.32364917, 43.0231483 ,\n",
       "        42.62242365, 42.57748961, 44.7612648 , 46.30422807, 42.95396423]),\n",
       " 'score_time': array([5.01433301, 8.09260035, 3.84794164, 7.51132321, 3.99689126,\n",
       "        3.70205593, 3.98510528, 7.98491096, 3.97489285, 0.42286468]),\n",
       " 'estimator': (Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                                   interaction_constraints=None, learning_rate=1,\n",
       "                                   max_delta_step=0, max_depth=5,\n",
       "                                   min_child_weight=1, missing=nan,\n",
       "                                   monotone_constraints=None, n_estimators=2000,\n",
       "                                   n_jobs=0, num_parallel_tree=2000,\n",
       "                                   objective='binary:logistic', random_state=0,\n",
       "                                   reg_alpha=0, reg_lambda=1, scale_pos_weight=2,\n",
       "                                   subsample=0.7, tree_method=None,\n",
       "                                   validate_parameters=False, verbosity=None))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                                   interaction_constraints=None, learning_rate=1,\n",
       "                                   max_delta_step=0, max_depth=5,\n",
       "                                   min_child_weight=1, missing=nan,\n",
       "                                   monotone_constraints=None, n_estimators=2000,\n",
       "                                   n_jobs=0, num_parallel_tree=2000,\n",
       "                                   objective='binary:logistic', random_state=0,\n",
       "                                   reg_alpha=0, reg_lambda=1, scale_pos_weight=2,\n",
       "                                   subsample=0.7, tree_method=None,\n",
       "                                   validate_parameters=False, verbosity=None))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                                   interaction_constraints=None, learning_rate=1,\n",
       "                                   max_delta_step=0, max_depth=5,\n",
       "                                   min_child_weight=1, missing=nan,\n",
       "                                   monotone_constraints=None, n_estimators=2000,\n",
       "                                   n_jobs=0, num_parallel_tree=2000,\n",
       "                                   objective='binary:logistic', random_state=0,\n",
       "                                   reg_alpha=0, reg_lambda=1, scale_pos_weight=2,\n",
       "                                   subsample=0.7, tree_method=None,\n",
       "                                   validate_parameters=False, verbosity=None))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                                   interaction_constraints=None, learning_rate=1,\n",
       "                                   max_delta_step=0, max_depth=5,\n",
       "                                   min_child_weight=1, missing=nan,\n",
       "                                   monotone_constraints=None, n_estimators=2000,\n",
       "                                   n_jobs=0, num_parallel_tree=2000,\n",
       "                                   objective='binary:logistic', random_state=0,\n",
       "                                   reg_alpha=0, reg_lambda=1, scale_pos_weight=2,\n",
       "                                   subsample=0.7, tree_method=None,\n",
       "                                   validate_parameters=False, verbosity=None))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                                   interaction_constraints=None, learning_rate=1,\n",
       "                                   max_delta_step=0, max_depth=5,\n",
       "                                   min_child_weight=1, missing=nan,\n",
       "                                   monotone_constraints=None, n_estimators=2000,\n",
       "                                   n_jobs=0, num_parallel_tree=2000,\n",
       "                                   objective='binary:logistic', random_state=0,\n",
       "                                   reg_alpha=0, reg_lambda=1, scale_pos_weight=2,\n",
       "                                   subsample=0.7, tree_method=None,\n",
       "                                   validate_parameters=False, verbosity=None))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                                   interaction_constraints=None, learning_rate=1,\n",
       "                                   max_delta_step=0, max_depth=5,\n",
       "                                   min_child_weight=1, missing=nan,\n",
       "                                   monotone_constraints=None, n_estimators=2000,\n",
       "                                   n_jobs=0, num_parallel_tree=2000,\n",
       "                                   objective='binary:logistic', random_state=0,\n",
       "                                   reg_alpha=0, reg_lambda=1, scale_pos_weight=2,\n",
       "                                   subsample=0.7, tree_method=None,\n",
       "                                   validate_parameters=False, verbosity=None))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                                   interaction_constraints=None, learning_rate=1,\n",
       "                                   max_delta_step=0, max_depth=5,\n",
       "                                   min_child_weight=1, missing=nan,\n",
       "                                   monotone_constraints=None, n_estimators=2000,\n",
       "                                   n_jobs=0, num_parallel_tree=2000,\n",
       "                                   objective='binary:logistic', random_state=0,\n",
       "                                   reg_alpha=0, reg_lambda=1, scale_pos_weight=2,\n",
       "                                   subsample=0.7, tree_method=None,\n",
       "                                   validate_parameters=False, verbosity=None))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                                   interaction_constraints=None, learning_rate=1,\n",
       "                                   max_delta_step=0, max_depth=5,\n",
       "                                   min_child_weight=1, missing=nan,\n",
       "                                   monotone_constraints=None, n_estimators=2000,\n",
       "                                   n_jobs=0, num_parallel_tree=2000,\n",
       "                                   objective='binary:logistic', random_state=0,\n",
       "                                   reg_alpha=0, reg_lambda=1, scale_pos_weight=2,\n",
       "                                   subsample=0.7, tree_method=None,\n",
       "                                   validate_parameters=False, verbosity=None))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                                   interaction_constraints=None, learning_rate=1,\n",
       "                                   max_delta_step=0, max_depth=5,\n",
       "                                   min_child_weight=1, missing=nan,\n",
       "                                   monotone_constraints=None, n_estimators=2000,\n",
       "                                   n_jobs=0, num_parallel_tree=2000,\n",
       "                                   objective='binary:logistic', random_state=0,\n",
       "                                   reg_alpha=0, reg_lambda=1, scale_pos_weight=2,\n",
       "                                   subsample=0.7, tree_method=None,\n",
       "                                   validate_parameters=False, verbosity=None))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                                   interaction_constraints=None, learning_rate=1,\n",
       "                                   max_delta_step=0, max_depth=5,\n",
       "                                   min_child_weight=1, missing=nan,\n",
       "                                   monotone_constraints=None, n_estimators=2000,\n",
       "                                   n_jobs=0, num_parallel_tree=2000,\n",
       "                                   objective='binary:logistic', random_state=0,\n",
       "                                   reg_alpha=0, reg_lambda=1, scale_pos_weight=2,\n",
       "                                   subsample=0.7, tree_method=None,\n",
       "                                   validate_parameters=False, verbosity=None))],\n",
       "           verbose=False)),\n",
       " 'test_score': array([0.6       , 0.73333333, 0.86666667, 0.73333333, 0.73333333,\n",
       "        0.93333333, 0.53333333, 0.91666667, 0.7       , 0.8       ]),\n",
       " 'train_score': array([0.97554348, 0.9682971 , 0.97101449, 0.96467391, 0.9673913 ,\n",
       "        0.92934783, 0.96467391, 0.96177778, 0.96608696, 0.95565217])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "select_features = ColumnTransformer([('best_features', 'passthrough', best_features_idx)])\n",
    "# clf = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "clf = xgboost.XGBRFClassifier(subsample=0.7,\n",
    "                              max_depth=5,\n",
    "                              reg_lambda=1,\n",
    "                              eval_metric='auc',\n",
    "                              scale_pos_weight=2,\n",
    "                              n_estimators=2000)\n",
    "\n",
    "pipelineM = Pipeline([(\"imp\", imputer),\n",
    "                      (\"scaler\", scaler),\n",
    "                      (\"features\", select_features),\n",
    "                      (\"clf\", clf)])\n",
    "\n",
    "cv_results = cross_validate(pipelineM, X_train, y_train, scoring='roc_auc', cv=10, return_train_score=True, return_estimator=True, n_jobs=NTHREADS)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-765180308f92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpipelineM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "pipelineM.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelineM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelineM.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([176.08964276, 175.07962036, 172.50754404, 171.25283504,\n",
       "        173.79708552, 183.37450099, 174.78414965, 172.04349756,\n",
       "        171.80838633, 170.57443428]),\n",
       " 'score_time': array([4.11216688, 3.78455019, 4.07930279, 8.57725739, 4.06918502,\n",
       "        8.08648276, 7.77613211, 3.99301076, 3.99458075, 4.01754832]),\n",
       " 'estimator': (Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=True, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=Tr...\n",
       "                                   interaction_constraints=None, learning_rate=1,\n",
       "                                   max_delta_step=0, max_depth=5,\n",
       "                                   min_child_weight=1, missing=nan,\n",
       "                                   monotone_constraints=None, n_estimators=2000,\n",
       "                                   n_jobs=0, num_parallel_tree=2000,\n",
       "                                   objective='binary:logistic', random_state=0,\n",
       "                                   reg_alpha=0, reg_lambda=3, scale_pos_weight=2,\n",
       "                                   subsample=0.7, tree_method=None,\n",
       "                                   validate_parameters=False, verbosity=None))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=True, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=Tr...\n",
       "                                   interaction_constraints=None, learning_rate=1,\n",
       "                                   max_delta_step=0, max_depth=5,\n",
       "                                   min_child_weight=1, missing=nan,\n",
       "                                   monotone_constraints=None, n_estimators=2000,\n",
       "                                   n_jobs=0, num_parallel_tree=2000,\n",
       "                                   objective='binary:logistic', random_state=0,\n",
       "                                   reg_alpha=0, reg_lambda=3, scale_pos_weight=2,\n",
       "                                   subsample=0.7, tree_method=None,\n",
       "                                   validate_parameters=False, verbosity=None))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=True, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=Tr...\n",
       "                                   interaction_constraints=None, learning_rate=1,\n",
       "                                   max_delta_step=0, max_depth=5,\n",
       "                                   min_child_weight=1, missing=nan,\n",
       "                                   monotone_constraints=None, n_estimators=2000,\n",
       "                                   n_jobs=0, num_parallel_tree=2000,\n",
       "                                   objective='binary:logistic', random_state=0,\n",
       "                                   reg_alpha=0, reg_lambda=3, scale_pos_weight=2,\n",
       "                                   subsample=0.7, tree_method=None,\n",
       "                                   validate_parameters=False, verbosity=None))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=True, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=Tr...\n",
       "                                   interaction_constraints=None, learning_rate=1,\n",
       "                                   max_delta_step=0, max_depth=5,\n",
       "                                   min_child_weight=1, missing=nan,\n",
       "                                   monotone_constraints=None, n_estimators=2000,\n",
       "                                   n_jobs=0, num_parallel_tree=2000,\n",
       "                                   objective='binary:logistic', random_state=0,\n",
       "                                   reg_alpha=0, reg_lambda=3, scale_pos_weight=2,\n",
       "                                   subsample=0.7, tree_method=None,\n",
       "                                   validate_parameters=False, verbosity=None))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=True, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=Tr...\n",
       "                                   interaction_constraints=None, learning_rate=1,\n",
       "                                   max_delta_step=0, max_depth=5,\n",
       "                                   min_child_weight=1, missing=nan,\n",
       "                                   monotone_constraints=None, n_estimators=2000,\n",
       "                                   n_jobs=0, num_parallel_tree=2000,\n",
       "                                   objective='binary:logistic', random_state=0,\n",
       "                                   reg_alpha=0, reg_lambda=3, scale_pos_weight=2,\n",
       "                                   subsample=0.7, tree_method=None,\n",
       "                                   validate_parameters=False, verbosity=None))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=True, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=Tr...\n",
       "                                   interaction_constraints=None, learning_rate=1,\n",
       "                                   max_delta_step=0, max_depth=5,\n",
       "                                   min_child_weight=1, missing=nan,\n",
       "                                   monotone_constraints=None, n_estimators=2000,\n",
       "                                   n_jobs=0, num_parallel_tree=2000,\n",
       "                                   objective='binary:logistic', random_state=0,\n",
       "                                   reg_alpha=0, reg_lambda=3, scale_pos_weight=2,\n",
       "                                   subsample=0.7, tree_method=None,\n",
       "                                   validate_parameters=False, verbosity=None))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=True, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=Tr...\n",
       "                                   interaction_constraints=None, learning_rate=1,\n",
       "                                   max_delta_step=0, max_depth=5,\n",
       "                                   min_child_weight=1, missing=nan,\n",
       "                                   monotone_constraints=None, n_estimators=2000,\n",
       "                                   n_jobs=0, num_parallel_tree=2000,\n",
       "                                   objective='binary:logistic', random_state=0,\n",
       "                                   reg_alpha=0, reg_lambda=3, scale_pos_weight=2,\n",
       "                                   subsample=0.7, tree_method=None,\n",
       "                                   validate_parameters=False, verbosity=None))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=True, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=Tr...\n",
       "                                   interaction_constraints=None, learning_rate=1,\n",
       "                                   max_delta_step=0, max_depth=5,\n",
       "                                   min_child_weight=1, missing=nan,\n",
       "                                   monotone_constraints=None, n_estimators=2000,\n",
       "                                   n_jobs=0, num_parallel_tree=2000,\n",
       "                                   objective='binary:logistic', random_state=0,\n",
       "                                   reg_alpha=0, reg_lambda=3, scale_pos_weight=2,\n",
       "                                   subsample=0.7, tree_method=None,\n",
       "                                   validate_parameters=False, verbosity=None))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=True, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=Tr...\n",
       "                                   interaction_constraints=None, learning_rate=1,\n",
       "                                   max_delta_step=0, max_depth=5,\n",
       "                                   min_child_weight=1, missing=nan,\n",
       "                                   monotone_constraints=None, n_estimators=2000,\n",
       "                                   n_jobs=0, num_parallel_tree=2000,\n",
       "                                   objective='binary:logistic', random_state=0,\n",
       "                                   reg_alpha=0, reg_lambda=3, scale_pos_weight=2,\n",
       "                                   subsample=0.7, tree_method=None,\n",
       "                                   validate_parameters=False, verbosity=None))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=True, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=Tr...\n",
       "                                   interaction_constraints=None, learning_rate=1,\n",
       "                                   max_delta_step=0, max_depth=5,\n",
       "                                   min_child_weight=1, missing=nan,\n",
       "                                   monotone_constraints=None, n_estimators=2000,\n",
       "                                   n_jobs=0, num_parallel_tree=2000,\n",
       "                                   objective='binary:logistic', random_state=0,\n",
       "                                   reg_alpha=0, reg_lambda=3, scale_pos_weight=2,\n",
       "                                   subsample=0.7, tree_method=None,\n",
       "                                   validate_parameters=False, verbosity=None))],\n",
       "           verbose=False)),\n",
       " 'test_score': array([0.26666667, 0.33333333, 0.26666667, 0.66666667, 0.73333333,\n",
       "        0.8       , 0.53333333, 0.66666667, 0.5       , 0.6       ]),\n",
       " 'train_score': array([0.99818841, 0.97826087, 0.98369565, 0.99547101, 0.96557971,\n",
       "        1.        , 0.98731884, 0.99022222, 0.99130435, 0.99130435])}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "kbest = SelectKBest(score_func=mutual_info_classif, k=500)\n",
    "selector = RandomForestClassifier(\n",
    "    n_estimators=200, max_depth=5,\n",
    "    class_weight=\"balanced_subsample\",\n",
    "    max_samples=0.8)\n",
    "rfe = RFE(selector, n_features_to_select=10)\n",
    "\n",
    "clf = xgboost.XGBRFClassifier(subsample=0.7,\n",
    "                              max_depth=5,\n",
    "                              eval_metric='auc',\n",
    "                              reg_lambda=3,\n",
    "                              scale_pos_weight=2,\n",
    "                              n_estimators=2000)\n",
    "\n",
    "pipelineM = Pipeline([(\"imp\", imputer),\n",
    "                      (\"scaler\", scaler),\n",
    "                      (\"kbest\", kbest),\n",
    "                      (\"rfe\", rfe),\n",
    "                      (\"clf\", clf)])\n",
    "\n",
    "cv_results = cross_validate(pipelineM, X_train, y_train, scoring='roc_auc', cv=10, return_train_score=True, return_estimator=True, n_jobs=NTHREADS)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03108425,  0.03247435,  0.93070572,  1.43040242,  0.54341727,\n",
       "         0.8358848 ,  0.25429763, -1.29042286, -1.15797601, -0.93002884],\n",
       "       [-0.31251692,  0.12198789, -0.39753884,  1.26276808,  1.24565425,\n",
       "         0.34845742, -0.95094439,  0.06344111, -1.4893874 , -1.25686452],\n",
       "       [ 0.08363989, -0.22319224,  0.80136462,  1.09130647, -0.24945139,\n",
       "         0.95736156,  0.14372174, -0.42038489, -1.05492228, -0.844035  ],\n",
       "       [ 0.43024509,  1.04904381,  1.2730319 ,  0.43263365, -0.54036003,\n",
       "        -1.83936655, -1.4633628 ,  0.72080313, -0.10255366,  0.10071516],\n",
       "       [-0.57948103,  0.3028793 , -1.08631753,  0.01278235,  2.4371755 ,\n",
       "         1.15481692,  0.76724322, -1.00889838,  0.26691735, -0.13658054],\n",
       "       [-0.33389966, -2.32996757, -0.82618252, -0.92107105, -0.91429489,\n",
       "         1.94775317,  1.09238113,  2.09258657,  0.60857556,  0.3335782 ],\n",
       "       [ 1.1260163 ,  0.30887543, -1.51362963,  0.70271119, -0.68803261,\n",
       "        -1.99688587, -1.54309868,  0.18934904, -1.11347554, -0.77843145],\n",
       "       [ 0.17749346,  0.57711372,  0.50562782,  1.15968699,  0.37609726,\n",
       "        -0.83249252, -0.19802233, -2.25854641, -0.93752302, -0.76276934],\n",
       "       [-0.92365347,  0.04272822,  1.32585332, -0.48846219, -0.87436625,\n",
       "         0.77618468, -1.34501101, -0.77971764,  0.31053952,  0.40420544],\n",
       "       [-0.88357684,  0.46832693, -0.43096129, -0.90486895, -1.89856749,\n",
       "         0.18355902, -0.02220798, -0.74104929, -0.29460833, -0.14810549]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = IterativeImputer(add_indicator=True,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "kbest = SelectKBest(score_func=mutual_info_classif, k=500)\n",
    "selector = RandomForestClassifier(\n",
    "    n_estimators=200, max_depth=5,\n",
    "    class_weight=\"balanced_subsample\",\n",
    "    max_samples=0.8)\n",
    "rfe = RFE(selector, n_features_to_select=10)\n",
    "\n",
    "feat_sel = Pipeline([(\"imp\", imputer),\n",
    "                     (\"scaler\", scaler),\n",
    "                     (\"kbest\", kbest),\n",
    "                     (\"rfe\", rfe)])\n",
    "\n",
    "feat_sel.fit(X_train, y_train)\n",
    "feat_sel.transform(X_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_sel.transform(X_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idxs = [cv_results['estimator'][x].named_steps['kbest'].get_support() for x in range(10)]\n",
    "\n",
    "\n",
    "# X_test.iloc[:,ixds].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allvol_left_cerebellum_cortex</th>\n",
       "      <th>allvol_right_cerebellum_cortex</th>\n",
       "      <th>allvol_wm_rh_entorhinal</th>\n",
       "      <th>allvol_wm_lh_fusiform</th>\n",
       "      <th>t1r_l_inflatvent_m</th>\n",
       "      <th>t1r_brainstem_m</th>\n",
       "      <th>t1r_l_hippo_m</th>\n",
       "      <th>t1r_l_amyg_m</th>\n",
       "      <th>t1r_l_ventraldc_m</th>\n",
       "      <th>t1r_r_cbmctx_m</th>\n",
       "      <th>...</th>\n",
       "      <th>31p_r_precuneus_aatp</th>\n",
       "      <th>31p_l_parhippo_gatp</th>\n",
       "      <th>31p_l_parhippo_aatp</th>\n",
       "      <th>31p_l_wm_rosmfg_aatp</th>\n",
       "      <th>31p_r_wm_midtemp_gatp</th>\n",
       "      <th>31p_l_wm_latocc_aatp</th>\n",
       "      <th>31p_l_wm_entro_gatp</th>\n",
       "      <th>31p_l_wm_entro_aatp</th>\n",
       "      <th>31p_r_paroperc_aatp</th>\n",
       "      <th>31p_cc_ant_aatp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>45987</td>\n",
       "      <td>47576</td>\n",
       "      <td>307.0</td>\n",
       "      <td>5485</td>\n",
       "      <td>227.619</td>\n",
       "      <td>131.3920</td>\n",
       "      <td>108.774</td>\n",
       "      <td>117.7150</td>\n",
       "      <td>125.9070</td>\n",
       "      <td>108.4120</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>44075</td>\n",
       "      <td>44035</td>\n",
       "      <td>447.0</td>\n",
       "      <td>6305</td>\n",
       "      <td>173.970</td>\n",
       "      <td>103.8380</td>\n",
       "      <td>111.088</td>\n",
       "      <td>96.4308</td>\n",
       "      <td>101.5100</td>\n",
       "      <td>102.0350</td>\n",
       "      <td>...</td>\n",
       "      <td>5697690.0</td>\n",
       "      <td>8382610.0</td>\n",
       "      <td>7888190.0</td>\n",
       "      <td>5239490.0</td>\n",
       "      <td>9460270.0</td>\n",
       "      <td>6335430.0</td>\n",
       "      <td>8309390.0</td>\n",
       "      <td>8083070.0</td>\n",
       "      <td>5714180.0</td>\n",
       "      <td>4957180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>46124</td>\n",
       "      <td>46988</td>\n",
       "      <td>381.0</td>\n",
       "      <td>6292</td>\n",
       "      <td>148.259</td>\n",
       "      <td>92.5557</td>\n",
       "      <td>110.336</td>\n",
       "      <td>111.3230</td>\n",
       "      <td>113.6840</td>\n",
       "      <td>99.9443</td>\n",
       "      <td>...</td>\n",
       "      <td>4740850.0</td>\n",
       "      <td>8154720.0</td>\n",
       "      <td>4711940.0</td>\n",
       "      <td>4533980.0</td>\n",
       "      <td>8166090.0</td>\n",
       "      <td>4406450.0</td>\n",
       "      <td>8164540.0</td>\n",
       "      <td>4713360.0</td>\n",
       "      <td>4947720.0</td>\n",
       "      <td>4281760.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51754</td>\n",
       "      <td>52219</td>\n",
       "      <td>548.0</td>\n",
       "      <td>6542</td>\n",
       "      <td>335.357</td>\n",
       "      <td>91.9759</td>\n",
       "      <td>146.553</td>\n",
       "      <td>64.1329</td>\n",
       "      <td>96.8372</td>\n",
       "      <td>118.8050</td>\n",
       "      <td>...</td>\n",
       "      <td>3978610.0</td>\n",
       "      <td>3365090.0</td>\n",
       "      <td>3372790.0</td>\n",
       "      <td>3786600.0</td>\n",
       "      <td>3638940.0</td>\n",
       "      <td>3352330.0</td>\n",
       "      <td>3765280.0</td>\n",
       "      <td>3373470.0</td>\n",
       "      <td>3318770.0</td>\n",
       "      <td>8678260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>43468</td>\n",
       "      <td>42319</td>\n",
       "      <td>542.0</td>\n",
       "      <td>6563</td>\n",
       "      <td>307.893</td>\n",
       "      <td>102.9300</td>\n",
       "      <td>153.176</td>\n",
       "      <td>120.8070</td>\n",
       "      <td>126.0040</td>\n",
       "      <td>103.6270</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 189 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    allvol_left_cerebellum_cortex  allvol_right_cerebellum_cortex  \\\n",
       "62                          45987                           47576   \n",
       "54                          44075                           44035   \n",
       "72                          46124                           46988   \n",
       "1                           51754                           52219   \n",
       "32                          43468                           42319   \n",
       "\n",
       "    allvol_wm_rh_entorhinal  allvol_wm_lh_fusiform  t1r_l_inflatvent_m  \\\n",
       "62                    307.0                   5485             227.619   \n",
       "54                    447.0                   6305             173.970   \n",
       "72                    381.0                   6292             148.259   \n",
       "1                     548.0                   6542             335.357   \n",
       "32                    542.0                   6563             307.893   \n",
       "\n",
       "    t1r_brainstem_m  t1r_l_hippo_m  t1r_l_amyg_m  t1r_l_ventraldc_m  \\\n",
       "62         131.3920        108.774      117.7150           125.9070   \n",
       "54         103.8380        111.088       96.4308           101.5100   \n",
       "72          92.5557        110.336      111.3230           113.6840   \n",
       "1           91.9759        146.553       64.1329            96.8372   \n",
       "32         102.9300        153.176      120.8070           126.0040   \n",
       "\n",
       "    t1r_r_cbmctx_m  ...  31p_r_precuneus_aatp  31p_l_parhippo_gatp  \\\n",
       "62        108.4120  ...                   NaN                  NaN   \n",
       "54        102.0350  ...             5697690.0            8382610.0   \n",
       "72         99.9443  ...             4740850.0            8154720.0   \n",
       "1         118.8050  ...             3978610.0            3365090.0   \n",
       "32        103.6270  ...                   NaN                  NaN   \n",
       "\n",
       "    31p_l_parhippo_aatp  31p_l_wm_rosmfg_aatp  31p_r_wm_midtemp_gatp  \\\n",
       "62                  NaN                   NaN                    NaN   \n",
       "54            7888190.0             5239490.0              9460270.0   \n",
       "72            4711940.0             4533980.0              8166090.0   \n",
       "1             3372790.0             3786600.0              3638940.0   \n",
       "32                  NaN                   NaN                    NaN   \n",
       "\n",
       "    31p_l_wm_latocc_aatp  31p_l_wm_entro_gatp  31p_l_wm_entro_aatp  \\\n",
       "62                   NaN                  NaN                  NaN   \n",
       "54             6335430.0            8309390.0            8083070.0   \n",
       "72             4406450.0            8164540.0            4713360.0   \n",
       "1              3352330.0            3765280.0            3373470.0   \n",
       "32                   NaN                  NaN                  NaN   \n",
       "\n",
       "    31p_r_paroperc_aatp  31p_cc_ant_aatp  \n",
       "62                  NaN              NaN  \n",
       "54            5714180.0        4957180.0  \n",
       "72            4947720.0        4281760.0  \n",
       "1             3318770.0        8678260.0  \n",
       "32                  NaN              NaN  \n",
       "\n",
       "[5 rows x 189 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features = (idxs[0] * idxs[2] * idxs[4] * idxs[5] * idxs[8])\n",
    "tmp_X_train = X_train.iloc[:,best_features]\n",
    "tmp_X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([4.95868754, 5.12005615, 4.9623456 , 4.96746898, 4.94417143,\n",
       "        5.10147786, 5.18857265, 4.93725276, 4.94643855, 4.87636232]),\n",
       " 'score_time': array([1.09454441, 0.84499812, 1.00560832, 0.87827969, 0.74188852,\n",
       "        0.93452168, 0.89584589, 0.8460803 , 0.84884071, 0.73133397]),\n",
       " 'estimator': (Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                   PolynomialFeatures(degree=2, include_bias=True,\n",
       "                                      interaction_only=False, order='C')),\n",
       "                  ('clf',\n",
       "                   LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "                                      fit_intercept=True, intercept_scaling=1,\n",
       "                                      l1_ratio=None, max_iter=10000,\n",
       "                                      multi_class='auto', n_jobs=None,\n",
       "                                      penalty='l1', random_state=None,\n",
       "                                      solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                      warm_start=False))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                   PolynomialFeatures(degree=2, include_bias=True,\n",
       "                                      interaction_only=False, order='C')),\n",
       "                  ('clf',\n",
       "                   LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "                                      fit_intercept=True, intercept_scaling=1,\n",
       "                                      l1_ratio=None, max_iter=10000,\n",
       "                                      multi_class='auto', n_jobs=None,\n",
       "                                      penalty='l1', random_state=None,\n",
       "                                      solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                      warm_start=False))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                   PolynomialFeatures(degree=2, include_bias=True,\n",
       "                                      interaction_only=False, order='C')),\n",
       "                  ('clf',\n",
       "                   LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "                                      fit_intercept=True, intercept_scaling=1,\n",
       "                                      l1_ratio=None, max_iter=10000,\n",
       "                                      multi_class='auto', n_jobs=None,\n",
       "                                      penalty='l1', random_state=None,\n",
       "                                      solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                      warm_start=False))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                   PolynomialFeatures(degree=2, include_bias=True,\n",
       "                                      interaction_only=False, order='C')),\n",
       "                  ('clf',\n",
       "                   LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "                                      fit_intercept=True, intercept_scaling=1,\n",
       "                                      l1_ratio=None, max_iter=10000,\n",
       "                                      multi_class='auto', n_jobs=None,\n",
       "                                      penalty='l1', random_state=None,\n",
       "                                      solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                      warm_start=False))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                   PolynomialFeatures(degree=2, include_bias=True,\n",
       "                                      interaction_only=False, order='C')),\n",
       "                  ('clf',\n",
       "                   LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "                                      fit_intercept=True, intercept_scaling=1,\n",
       "                                      l1_ratio=None, max_iter=10000,\n",
       "                                      multi_class='auto', n_jobs=None,\n",
       "                                      penalty='l1', random_state=None,\n",
       "                                      solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                      warm_start=False))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                   PolynomialFeatures(degree=2, include_bias=True,\n",
       "                                      interaction_only=False, order='C')),\n",
       "                  ('clf',\n",
       "                   LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "                                      fit_intercept=True, intercept_scaling=1,\n",
       "                                      l1_ratio=None, max_iter=10000,\n",
       "                                      multi_class='auto', n_jobs=None,\n",
       "                                      penalty='l1', random_state=None,\n",
       "                                      solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                      warm_start=False))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                   PolynomialFeatures(degree=2, include_bias=True,\n",
       "                                      interaction_only=False, order='C')),\n",
       "                  ('clf',\n",
       "                   LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "                                      fit_intercept=True, intercept_scaling=1,\n",
       "                                      l1_ratio=None, max_iter=10000,\n",
       "                                      multi_class='auto', n_jobs=None,\n",
       "                                      penalty='l1', random_state=None,\n",
       "                                      solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                      warm_start=False))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                   PolynomialFeatures(degree=2, include_bias=True,\n",
       "                                      interaction_only=False, order='C')),\n",
       "                  ('clf',\n",
       "                   LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "                                      fit_intercept=True, intercept_scaling=1,\n",
       "                                      l1_ratio=None, max_iter=10000,\n",
       "                                      multi_class='auto', n_jobs=None,\n",
       "                                      penalty='l1', random_state=None,\n",
       "                                      solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                      warm_start=False))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                   PolynomialFeatures(degree=2, include_bias=True,\n",
       "                                      interaction_only=False, order='C')),\n",
       "                  ('clf',\n",
       "                   LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "                                      fit_intercept=True, intercept_scaling=1,\n",
       "                                      l1_ratio=None, max_iter=10000,\n",
       "                                      multi_class='auto', n_jobs=None,\n",
       "                                      penalty='l1', random_state=None,\n",
       "                                      solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                      warm_start=False))],\n",
       "           verbose=False),\n",
       "  Pipeline(memory=None,\n",
       "           steps=[('imp',\n",
       "                   IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                    imputation_order='random',\n",
       "                                    initial_strategy='median', max_iter=10,\n",
       "                                    max_value=None, min_value=None,\n",
       "                                    missing_values=nan, n_nearest_features=50,\n",
       "                                    random_state=None, sample_posterior=True,\n",
       "                                    skip_complete=False, tol=0.001, verbose=0)),\n",
       "                  ('scaler',\n",
       "                   StandardScaler(copy=True, with_mean=T...\n",
       "                   PolynomialFeatures(degree=2, include_bias=True,\n",
       "                                      interaction_only=False, order='C')),\n",
       "                  ('clf',\n",
       "                   LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "                                      fit_intercept=True, intercept_scaling=1,\n",
       "                                      l1_ratio=None, max_iter=10000,\n",
       "                                      multi_class='auto', n_jobs=None,\n",
       "                                      penalty='l1', random_state=None,\n",
       "                                      solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                      warm_start=False))],\n",
       "           verbose=False)),\n",
       " 'test_score': array([0.4       , 0.13333333, 0.2       , 0.66666667, 0.26666667,\n",
       "        0.26666667, 0.53333333, 0.58333333, 0.4       , 0.2       ]),\n",
       " 'train_score': array([0.89130435, 0.83514493, 0.79347826, 0.90036232, 0.83786232,\n",
       "        0.79257246, 0.87681159, 0.89777778, 0.93565217, 0.9       ])}"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=0.99, whiten=True)\n",
    "poly = PolynomialFeatures(interaction_only=False)\n",
    "clf = LogisticRegression(penalty='l1', solver='liblinear', C=0.1, max_iter=10000, class_weight='balanced')\n",
    "\n",
    "pipelineM = Pipeline([(\"imp\", imputer),\n",
    "                      (\"scaler\", scaler),\n",
    "                      (\"dimred\", pca),\n",
    "                      (\"poly\", poly),\n",
    "                      (\"clf\", clf)])\n",
    "\n",
    "cv_results = cross_validate(pipelineM, tmp_X_train, y_train, scoring='roc_auc', cv=10, return_train_score=True, return_estimator=True, n_jobs=NTHREADS)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 410)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['estimator'][7].named_steps['dimred'].components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the residual of all features, by fitting a model containing the feature names\n",
    "class ResidFeatures(BaseEstimator, TransformerMixin):\n",
    "    # Class Constructor \n",
    "    def __init__(self, feature_idxs):\n",
    "        self._feature_idxs = feature_idxs\n",
    "    \n",
    "    #Return self nothing else to do here    \n",
    "    def fit(self, X, y = None):\n",
    "        return self \n",
    "    \n",
    "    def _linr(self, X, y):\n",
    "        lm = LinearRegression().fit(X, y)\n",
    "        return np.atleast_2d(y - lm.predict(X)).T\n",
    "\n",
    "    # take the residual from variables of non-interest\n",
    "    def transform(self, X, y = None):\n",
    "        feature_X = np.hstack(\n",
    "            [label_binarize(X[:,f], np.unique(X[:,f]))\n",
    "             if type(X[0,f]) == str else np.atleast_2d(X[:,f]).T\n",
    "             for f in self._feature_idxs]\n",
    "        )\n",
    "        new_X = np.delete(X, self._feature_idxs, axis=1)\n",
    "        resid_X = np.hstack([self._linr(feature_X, new_X[:,c]) for c in range(new_X.shape[1])])\n",
    "            \n",
    "        return resid_X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resf = ResidFeatures(feature_idxs=[1856, 1855, 1854])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resf.transform(imputed_df.values).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df[\"gender\"] = bp_df[\"gender\"]\n",
    "imputed_df[\"group\"] = bp_df['group']\n",
    "imputed_df['age'] = bp_df['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/BipolarDerivedDataTraining.csv'\n",
    "NTHREADS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_df = pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bp_df.columns.get_loc('gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack([label_binarize(bp_df.values[:,f], np.unique(bp_df.values[:,f])) for f in [1, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = bp_df[\"allvol_unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y - lm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_df.columns[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bp_df[['group', 'madrs_score', 'ymrs_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LabelBinarizer()\n",
    "enc.fit(bp_df[['gender']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "enc.transform(bp_df[['gender']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# select the t1r columns\n",
    "p31_df = bp_df.filter(regex=(\"age$|gender|handedness|31p.*[^r]$|t1r.*_m|alff.*_m|vol|dti\"))\n",
    "display(p31_df.shape)\n",
    "p31_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(p31_df.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50)\n",
    "imputer.fit(p31_df)\n",
    "imputed_values = imputer.transform(p31_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imputed_df = pd.DataFrame(imputed_values, columns=p31_df.columns)\n",
    "imputed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imputed_df['31p_l_pat_aatp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import NullFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_male_female = bp_df.loc[bp_df[\"gender\"] != 'Transgender-does not identify as Male or Female',:]\n",
    "imputed_male_female = imputed_df.loc[bp_df[\"gender\"] != 'Transgender-does not identify as Male or Female',:]\n",
    "p31_male_female = p31_df.loc[bp_df[\"gender\"] != 'Transgender-does not identify as Male or Female',:]\n",
    "gender = bp_male_female[\"gender\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_male_female[\"gender\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = bp_male_female[\"gender\"]\n",
    "red = y == \"Male\"\n",
    "green = y == \"Female\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fig, subplots) = plt.subplots(1, 5, figsize=(15, 8))\n",
    "perplexities = [5, 30, 50, 100]\n",
    "ax = subplots[0]\n",
    "ax.scatter(imputed_male_female.values[red, 0], imputed_male_female.values[red, 1], c=\"r\")\n",
    "ax.scatter(imputed_male_female.values[green, 0], imputed_male_female.values[green, 1], c=\"g\")\n",
    "ax.xaxis.set_major_formatter(NullFormatter())\n",
    "ax.yaxis.set_major_formatter(NullFormatter())\n",
    "plt.axis('tight')\n",
    "\n",
    "for i, perplexity in enumerate(perplexities):\n",
    "    ax = subplots[i + 1]\n",
    "\n",
    "    tsne = TSNE(n_components=2, init='random',\n",
    "                random_state=0, perplexity=perplexity)\n",
    "    Y = tsne.fit_transform(imputed_male_female.values)\n",
    "    ax.set_title(\"Perplexity=%d\" % perplexity)\n",
    "    ax.scatter(Y[red, 0], Y[red, 1], c=\"r\")\n",
    "    ax.scatter(Y[green, 0], Y[green, 1], c=\"g\")\n",
    "    ax.xaxis.set_major_formatter(NullFormatter())\n",
    "    ax.yaxis.set_major_formatter(NullFormatter())\n",
    "    ax.axis('tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)\n",
    "Y = tsne.fit_transform(imputed_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pvalues = {}\n",
    "for col in imputed_df.columns:\n",
    "    kstat, pvalue = kstest_normal(imputed_df[col].dropna(), dist='norm', pvalmethod='table')\n",
    "    pvalues[col] = pvalue\n",
    "not_normal_columns = [col for col,val in pvalues.items() if val < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "not_normal_indices = [imputed_df.columns.get_loc(col) for col in not_normal_columns]\n",
    "# after imputation these columns are placed at the end of the matrix (passthrough)\n",
    "resid_feature_idxs = np.arange(len(p31_df.columns) - 3, len(p31_df.columns))\n",
    "resid_feature_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = bp_df['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(p31_df, group, test_size=10, stratify=group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup PCA\n",
    "\n",
    "placeholder = FunctionTransformer()\n",
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50)\n",
    "\n",
    "# resid = ResidFeatures(feature_idxs=resid_feature_idxs)\n",
    "\n",
    "lognorm = ColumnTransformer(\n",
    "    remainder='passthrough',\n",
    "    transformers=[('not_normal', PowerTransformer(standardize=False), not_normal_indices)])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "pca = PCA()\n",
    "# define the options I would like to vary within PCA\n",
    "n_components_opts = [32, 64, 80, 100]\n",
    "whiten_opts = [False, True]\n",
    "\n",
    "# define my classifier (Logistic regression)\n",
    "clf = LogisticRegression(max_iter=1000, penalty='l2', C=0.1, class_weight='balanced')\n",
    "\n",
    "\n",
    "# place the parameters I would like to vary using a list of dictionaries\n",
    "grid_params = [\n",
    "    {\n",
    "        'lognorm': (lognorm,),\n",
    "        'pca__n_components': n_components_opts,\n",
    "        'pca__whiten': whiten_opts,\n",
    "    },\n",
    "    {\n",
    "        'lognorm': (placeholder,),\n",
    "        'pca__n_components': n_components_opts,\n",
    "        'pca__whiten': whiten_opts,\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "pipeline = Pipeline([(\"imp\", imputer), (\"lognorm\", placeholder), (\"scaler\", scaler), (\"pca\", pca), (\"clf\", clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(pipeline, n_jobs=NTHREADS, param_grid=grid_params, cv=10, scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like lognorm does not help\n",
    "len(p31_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_columns = np.arange(len(p31_df.columns) - len(resid_feature_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_columns = np.arange(len(resid_feature_idxs), len(p31_df.columns))\n",
    "imputation_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "placeholder = FunctionTransformer()\n",
    "imputer = ColumnTransformer(\n",
    "    remainder='passthrough',\n",
    "    transformers=[('impute', IterativeImputer(initial_strategy='median',\n",
    "                                              imputation_order='random',\n",
    "                                              sample_posterior=True,\n",
    "                                              max_iter=10,\n",
    "                                              n_nearest_features=50),\n",
    "                    imputation_columns)])\n",
    "\n",
    "add_indicator_opts = [False, True]\n",
    "\n",
    "resid = ResidFeatures(feature_idxs=resid_feature_idxs)\n",
    "\n",
    "pcable = ColumnTransformer(\n",
    "    remainder='passthrough',\n",
    "    transformers=[('preproc', Pipeline([(\"scaler\", StandardScaler()),\n",
    "                                       (\"pca\", PCA())]), pca_columns)])\n",
    "# define the options I would like to vary within PCA\n",
    "n_components_opts = [32, 64, 80, 100]\n",
    "whiten_opts = [False, True]\n",
    "\n",
    "# define my classifier (Logistic regression)\n",
    "clf = LogisticRegression(max_iter=1000, penalty='l2', C=0.1, class_weight='balanced')\n",
    "\n",
    "\n",
    "# place the parameters I would like to vary using a list of dictionaries\n",
    "grid_paramsA = [\n",
    "    {\n",
    "        'pcable__preproc__pca__n_components': n_components_opts,\n",
    "        'pcable__preproc__pca__whiten': whiten_opts,\n",
    "        'imp__impute__add_indicator': add_indicator_opts,\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "pipelineA = Pipeline([(\"imp\", imputer), (\"resid\", resid), (\"pcable\", pcable), (\"clf\", clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchA = GridSearchCV(pipelineA, n_jobs=NTHREADS, param_grid=grid_paramsA, cv=10, scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchA.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchA.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchA.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchA.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchA.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchA_df = pd.DataFrame(searchA.cv_results_)\n",
    "searchA_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "searchA_df.groupby('param_imp__add_indicator')['mean_test_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchA_df.groupby('param_pcable__preproc__pca__n_components')['mean_test_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does not look like adding an indicator helps with the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate PCA\n",
    "pca_pipeline = Pipeline([(\"imp\", imputer), (\"scale\", scaler), (\"pca\", PCA(n_components=0.99))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_data = pca_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(pca_pipeline.get_params()['steps'][2][1].explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test different dimension reduction strategies (feature agglomation)\n",
    "placeholder = FunctionTransformer()\n",
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "ftagg = FeatureAgglomeration()\n",
    "n_clusters_opts = [5, 10, 20, 50, 100]\n",
    "\n",
    "# define my classifier (Logistic regression)\n",
    "clf = LogisticRegression(max_iter=1000, penalty='l2', C=0.1, class_weight='balanced')\n",
    "\n",
    "\n",
    "# place the parameters I would like to vary using a list of dictionaries\n",
    "grid_paramsB = [\n",
    "    {\n",
    "        'ftagg__n_clusters': n_clusters_opts,\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "pipelineB = Pipeline([(\"imp\", imputer), (\"scaler\", scaler), (\"ftagg\", ftagg), (\"clf\", clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchB = GridSearchCV(pipelineB, n_jobs=NTHREADS, param_grid=grid_paramsB, cv=10, scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchB.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchB.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchB_df = pd.DataFrame(searchB.cv_results_)\n",
    "searchB_df\n",
    "# use 100 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test different dimension reduction strategies (dictionary learning)\n",
    "placeholder = FunctionTransformer()\n",
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50)\n",
    "\n",
    "\n",
    "dict_learning = DictionaryLearning()\n",
    "n_components_opts = [5, 10, 20, 50]\n",
    "\n",
    "# define my classifier (Logistic regression)\n",
    "clf = LogisticRegression(max_iter=1000, penalty='l2', C=0.1, class_weight='balanced')\n",
    "\n",
    "\n",
    "# place the parameters I would like to vary using a list of dictionaries\n",
    "grid_paramsC = [\n",
    "    {\n",
    "        'dict_learning__n_components': n_components_opts,\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "pipelineC = Pipeline([(\"imp\", imputer), (\"scaler\", scaler), (\"dict_learning\", dict_learning), (\"clf\", clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchC = GridSearchCV(pipelineC, n_jobs=NTHREADS, param_grid=grid_paramsC, cv=10, scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "searchC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchC.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "searchC_df = pd.DataFrame(searchC.cv_results_)\n",
    "searchC_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test different dimension reduction strategies (factor analysis)\n",
    "placeholder = FunctionTransformer()\n",
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50)\n",
    "\n",
    "\n",
    "fa = FactorAnalysis()\n",
    "n_components_opts = [5, 10, 20, 50, 100]\n",
    "\n",
    "# define my classifier (Logistic regression)\n",
    "clf = LogisticRegression(max_iter=1000, penalty='l2', C=0.1, class_weight='balanced')\n",
    "\n",
    "\n",
    "# place the parameters I would like to vary using a list of dictionaries\n",
    "grid_paramsD = [\n",
    "    {\n",
    "        'fa__n_components': n_components_opts,\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "pipelineD = Pipeline([(\"imp\", imputer), (\"scaler\", scaler), (\"fa\", fa), (\"clf\", clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchD = GridSearchCV(pipelineD, n_jobs=NTHREADS, param_grid=grid_paramsD, cv=10, scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchD.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchD.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "searchD_df = pd.DataFrame(searchD.cv_results_)\n",
    "searchD_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test different dimension reduction strategies (kbest)\n",
    "placeholder = FunctionTransformer()\n",
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50)\n",
    "\n",
    "\n",
    "kbest = SelectKBest()\n",
    "k_opts = [5, 10, 20, 50, 100]\n",
    "\n",
    "# define my classifier (Logistic regression)\n",
    "clf = LogisticRegression(max_iter=1000, penalty='l2', C=0.1, class_weight='balanced')\n",
    "\n",
    "\n",
    "# place the parameters I would like to vary using a list of dictionaries\n",
    "grid_paramsE = [\n",
    "    {\n",
    "        'kbest__k': k_opts,\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "pipelineE = Pipeline([(\"imp\", imputer), (\"scaler\", scaler), (\"kbest\", kbest), (\"clf\", clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchE = GridSearchCV(pipelineE, n_jobs=NTHREADS, param_grid=grid_paramsE, cv=10, scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "searchE.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchE.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchE_df = pd.DataFrame(searchE.cv_results_)\n",
    "searchE_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare different dim reductions\n",
    "pca = PCA(n_components=64, whiten=True)\n",
    "fa = FactorAnalysis(n_components=20)\n",
    "ftagg = FeatureAgglomeration(n_clusters=100)\n",
    "d_learn = DictionaryLearning(n_components=5)\n",
    "kbest = SelectKBest(k=50)\n",
    "\n",
    "# define my classifier (Logistic regression)\n",
    "clf = LogisticRegression(max_iter=1000, penalty='l2', C=0.1, class_weight='balanced')\n",
    "\n",
    "\n",
    "# place the parameters I would like to vary using a list of dictionaries\n",
    "grid_paramsF = [\n",
    "    {\n",
    "        'dim_red': [pca, fa, ftagg, d_learn, kbest]\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "pipelineF = Pipeline([(\"imp\", imputer), (\"scaler\", scaler), (\"dim_red\", placeholder), (\"clf\", clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchF = GridSearchCV(pipelineF, n_jobs=NTHREADS, param_grid=grid_paramsF, cv=10, scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "searchF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchF.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "searchF_df = pd.DataFrame(searchF.cv_results_)\n",
    "searchF_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test adding interaction terms\n",
    "poly = PolynomialFeatures(degree=1)\n",
    "\n",
    "\n",
    "# place the parameters I would like to vary using a list of dictionaries\n",
    "grid_paramsG = [\n",
    "    {\n",
    "        'dim_red': [pca, d_learn],\n",
    "        'poly': [poly, placeholder],\n",
    "    },\n",
    "]\n",
    "\n",
    "pipelineG = Pipeline([(\"imp\", imputer), (\"scaler\", scaler), (\"dim_red\", placeholder), (\"poly\", placeholder), (\"clf\", clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchG = GridSearchCV(pipelineG, n_jobs=NTHREADS, param_grid=grid_paramsG, cv=10, scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchG.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overfitting the data?\n",
    "searchG.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchG.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "searchG_df = pd.DataFrame(searchG.cv_results_)\n",
    "searchG_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test adding interaction terms\n",
    "poly = PolynomialFeatures(degree=1)\n",
    "kbest = SelectKBest(k=50)\n",
    "\n",
    "# place the parameters I would like to vary using a list of dictionaries\n",
    "grid_paramsH = [\n",
    "    {\n",
    "        'poly': [poly, placeholder],\n",
    "    },\n",
    "]\n",
    "\n",
    "pipelineH = Pipeline([(\"imp\", imputer), (\"scaler\", scaler), (\"dim_red\", kbest), (\"poly\", placeholder), (\"clf\", clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchH = GridSearchCV(pipelineH, n_jobs=NTHREADS, param_grid=grid_paramsH, cv=10, scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "searchH.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe just the classifier needs to be changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchH.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchH.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "searchH_df = pd.DataFrame(searchH.cv_results_)\n",
    "searchH_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with adaboost classifier\n",
    "placeholder = FunctionTransformer()\n",
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50)\n",
    "pca = PCA(n_components=64, whiten=True)\n",
    "\n",
    "poly = PolynomialFeatures(degree=1)\n",
    "\n",
    "clf = AdaBoostClassifier()\n",
    "n_estimators_opts = [100, 1000, 2000]\n",
    "learning_rate_opts = [0.01, 0.1, 1.]\n",
    "base_estimator_opts = [None, LogisticRegression(class_weight=\"balanced\", max_iter=1000)]\n",
    "\n",
    "\n",
    "grid_paramsI = [\n",
    "    {\n",
    "        'clf__n_estimators': n_estimators_opts,\n",
    "        'clf__learning_rate': learning_rate_opts,\n",
    "        'clf__base_estimator': base_estimator_opts,\n",
    "    },\n",
    "]\n",
    "\n",
    "pipelineI = Pipeline([(\"imp\", imputer), (\"scaler\", scaler), (\"pca\", pca), (\"poly\", poly), (\"clf\", clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchI = GridSearchCV(pipelineI, n_jobs=NTHREADS, param_grid=grid_paramsI, cv=10, scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "searchI.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchI.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchI.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "searchI_df = pd.DataFrame(searchI.cv_results_)\n",
    "searchI_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boost\n",
    "# test with adaboost classifier\n",
    "placeholder = FunctionTransformer()\n",
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50)\n",
    "pca = PCA(n_components=64, whiten=True)\n",
    "\n",
    "poly = PolynomialFeatures(degree=1)\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "max_depth_opts = [3, 5, 15, 20]\n",
    "n_estimators_opts = [100, 1000, 2000]\n",
    "learning_rate_opts = [0.01, 0.1, 1.]\n",
    "\n",
    "\n",
    "grid_paramsJ = [\n",
    "    {\n",
    "        'clf__n_estimators': n_estimators_opts,\n",
    "        'clf__learning_rate': learning_rate_opts,\n",
    "        'clf__max_depth': max_depth_opts,\n",
    "    },\n",
    "]\n",
    "\n",
    "pipelineJ = Pipeline([(\"imp\", imputer), (\"scaler\", scaler), (\"pca\", pca), (\"poly\", poly), (\"clf\", clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchJ = GridSearchCV(pipelineJ, n_jobs=NTHREADS, param_grid=grid_paramsJ, cv=10, scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "searchJ.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchJ.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchJ.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchJ_df = pd.DataFrame(searchJ.cv_results_)\n",
    "searchJ_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boost\n",
    "# test pca and dict_learning with gradient boost\n",
    "placeholder = FunctionTransformer()\n",
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50)\n",
    "pca = PCA(whiten=True)\n",
    "n_components_opts = [5, 10, 20, 50, 100]\n",
    "\n",
    "d_learn = DictionaryLearning(n_components=5)\n",
    "alpha_opts = [0.01, 0.1, 1]\n",
    "\n",
    "poly = PolynomialFeatures(degree=1)\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=1000, max_depth=25, learning_rate=0.1)\n",
    "\n",
    "\n",
    "grid_paramsK = [\n",
    "    {\n",
    "        'dim_red': (pca,),\n",
    "        'dim_red__n_components': n_components_opts,\n",
    "        'poly': [placeholder, poly],\n",
    "    },\n",
    "    {\n",
    "        'dim_red': (d_learn,),\n",
    "        'dim_red__alpha': alpha_opts,\n",
    "        'poly': [placeholder, poly],\n",
    "    },\n",
    "]\n",
    "\n",
    "pipelineK = Pipeline([(\"imp\", imputer),\n",
    "                      (\"scaler\", scaler),\n",
    "                      (\"dim_red\", placeholder),\n",
    "                      (\"poly\", placeholder),\n",
    "                      (\"clf\", clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchK = GridSearchCV(pipelineK, n_jobs=NTHREADS, param_grid=grid_paramsK, cv=10, scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchK.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchK.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchK.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "searchK_df = pd.DataFrame(searchK.cv_results_)\n",
    "searchK_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boost\n",
    "# test pca and dict_learning with gradient boost\n",
    "placeholder = FunctionTransformer()\n",
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50)\n",
    "pca = PCA(whiten=True)\n",
    "n_components_opts = [2, 3, 5, 10]\n",
    "\n",
    "poly = PolynomialFeatures(degree=1)\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=1000, max_depth=25, learning_rate=0.1)\n",
    "\n",
    "\n",
    "grid_paramsL = [\n",
    "    {\n",
    "        'pca__n_components': n_components_opts,\n",
    "        'poly': [placeholder, poly],\n",
    "    },\n",
    "]\n",
    "\n",
    "pipelineL = Pipeline([(\"imp\", imputer),\n",
    "                      (\"scaler\", scaler),\n",
    "                      (\"pca\", pca),\n",
    "                      (\"poly\", placeholder),\n",
    "                      (\"clf\", clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchL = GridSearchCV(pipelineL, n_jobs=NTHREADS, param_grid=grid_paramsL, cv=10, scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchL.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchL.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchL.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "searchL_df = pd.DataFrame(searchL.cv_results_)\n",
    "searchL_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the best model?\n",
    "imputer = ColumnTransformer(\n",
    "    remainder='passthrough',\n",
    "    transformers=[('impute', IterativeImputer(add_indicator=False,\n",
    "                                              initial_strategy='median',\n",
    "                                              imputation_order='random',\n",
    "                                              sample_posterior=True,\n",
    "                                              max_iter=10,\n",
    "                                              n_nearest_features=50),\n",
    "                    imputation_columns)])\n",
    "resid = ResidFeatures(feature_idxs=resid_feature_idxs)\n",
    "pca = PCA(n_components=2, whiten=True)\n",
    "clf = GradientBoostingClassifier(n_estimators=1000, max_depth=25, learning_rate=0.1)\n",
    "pipelineM = Pipeline([(\"imp\", imputer),\n",
    "                      (\"resid\", resid),\n",
    "                      (\"scaler\", scaler),\n",
    "                      (\"pca\", pca),\n",
    "                      (\"clf\", clf)])\n",
    "pipelineM.fit(X_train, y_train)\n",
    "pipelineM.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineM.predict(X_test) == y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params2 = [\n",
    "    {\n",
    "        'clf__C': C_opts,\n",
    "    }\n",
    "]\n",
    "pipeline2 = Pipeline([(\"lognorm\", lognorm), (\"scaler\", scaler), (\"imp\", imputer),  (\"clf\", clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search2 = GridSearchCV(pipeline2, n_jobs=NTHREADS, param_grid=grid_params2, cv=10, scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup PCA\n",
    "\n",
    "imputer = IterativeImputer(sample_posterior=True, n_nearest_features=50, initial_strategy='median')\n",
    "# options I would like to vary for the imputation\n",
    "n_nearest_features_opts = [10, 50, 100]\n",
    "initial_strategy_opts = ['mean', 'median']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "kpca = KernelPCA(remove_zero_eig=True)\n",
    "# define the options I would like to vary within PCA\n",
    "n_components_opts = [2, 8, 16, 32, 64]\n",
    "kernel_opts = [\"linear\", \"poly\", \"rbf\", \"sigmoid\", \"cosine\"]\n",
    "\n",
    "# define my classifier (Logistic regression)\n",
    "clf = LogisticRegression(max_iter=1000, penalty='l2', class_weight='balanced')\n",
    "# define options I would like to vary with logistic regression\n",
    "# l1_ratio_opts = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "C_opts = [0.01, 0.1, 1.0]\n",
    "\n",
    "# place the parameters I would like to vary using a list of dictionaries\n",
    "grid_params3 = [\n",
    "    {\n",
    "#        'imp__n_nearest_features': n_nearest_features_opts,\n",
    "#        'imp__initial_strategy': initial_strategy_opts,\n",
    "        'kpca__n_components': n_components_opts,\n",
    "        'kpca__kernel': kernel_opts,\n",
    "#        'clf__l1_ratio': l1_ratio_opts,\n",
    "        'clf__C': C_opts,\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "pipeline3 = Pipeline([(\"lognorm\", lognorm), (\"scaler\", scaler), (\"imp\", imputer), (\"kpca\", kpca), (\"clf\", clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search3 = GridSearchCV(pipeline3, n_jobs=NTHREADS, param_grid=grid_params3, cv=10, scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search3.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search3_df = pd.DataFrame.from_records(search3.cv_results_['params'])\n",
    "search3_df['mean_test_score'] = search3.cv_results_['mean_test_score']\n",
    "search3_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search3_df.groupby('kpca__kernel')['mean_test_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search3_df.groupby('kpca__n_components')['mean_test_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup PCA\n",
    "\n",
    "imputer = IterativeImputer(sample_posterior=True)\n",
    "# options I would like to vary for the imputation\n",
    "n_nearest_features_opts = [10, 50, 100]\n",
    "initial_strategy_opts = ['mean', 'median']\n",
    "\n",
    "# define my classifier (Logistic regression)\n",
    "clf = RandomForestClassifier(max_features=\"sqrt\", class_weight=\"balanced_subsample\", n_estimators=2500)\n",
    "\n",
    "# place the parameters I would like to vary using a list of dictionaries\n",
    "grid_params4 = [\n",
    "    {\n",
    "        'imp__n_nearest_features': n_nearest_features_opts,\n",
    "        'imp__initial_strategy': initial_strategy_opts,\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "pipeline4 = Pipeline([(\"lognorm\", lognorm), (\"scaler\", scaler), (\"imp\", imputer), (\"clf\", clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search4 = GridSearchCV(pipeline4, n_jobs=NTHREADS, param_grid=grid_params4, cv=10, scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search4_df = pd.DataFrame.from_records(search4.cv_results_['params'])\n",
    "search4_df['mean_test_score'] = search4.cv_results_['mean_test_score']\n",
    "search4_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search4_df.groupby('imp__initial_strategy')['mean_test_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search4_df.groupby('imp__n_nearest_features')['mean_test_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search4.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search4.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = IterativeImputer(sample_posterior=True, n_nearest_features=50, initial_strategy='mean')\n",
    "\n",
    "kpca = KernelPCA(remove_zero_eig=True)\n",
    "# define the options I would like to vary within PCA\n",
    "n_components_opts = [32, 64, 80, 100]\n",
    "kernel_opts = [\"linear\", \"sigmoid\"]\n",
    "\n",
    "poly = PolynomialFeatures()\n",
    "degree_opts = [1, 2, 3]\n",
    "# define my classifier (Logistic regression)\n",
    "clf = LogisticRegression(max_iter=1000, penalty='l2', class_weight='balanced')\n",
    "# define options I would like to vary with logistic regression\n",
    "C_opts = [0.01, 0.1, 1.0]\n",
    "\n",
    "# place the parameters I would like to vary using a list of dictionaries\n",
    "grid_params5 = [\n",
    "    {\n",
    "        'kpca__n_components': n_components_opts,\n",
    "        'kpca__kernel': kernel_opts,\n",
    "        'poly__degree': degree_opts,\n",
    "        'clf__C': C_opts,\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "pipeline5 = Pipeline([(\"lognorm\", lognorm), (\"scaler\", scaler), (\"imp\", imputer), (\"kpca\", kpca), (\"poly\", poly), (\"clf\", clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search5 = GridSearchCV(pipeline5, n_jobs=NTHREADS, param_grid=grid_params5, cv=10, scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search5.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search5.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search5_df = pd.DataFrame.from_records(search5.cv_results_['params'])\n",
    "search5_df['mean_test_score'] = search5.cv_results_['mean_test_score']\n",
    "search5_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search5_df.groupby('kpca__kernel')['mean_test_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search5_df.groupby('clf__C')['mean_test_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search5_df.groupby('kpca__n_components')['mean_test_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search5_df.groupby('poly__degree')['mean_test_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(class_weight='balanced', probability=True)\n",
    "grid_params6 = [\n",
    "    {\n",
    "        'clf__kernel': kernel_opts,\n",
    "        'clf__C': C_opts,\n",
    "    }\n",
    "]\n",
    "pipeline6 = Pipeline([(\"lognorm\", lognorm), (\"scaler\", scaler), (\"imp\", imputer), (\"clf\", clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search6 = GridSearchCV(pipeline6, n_jobs=NTHREADS, param_grid=grid_params6, cv=10, scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search6.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search6.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search6.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search6.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'clf__C': 1.0, 'kpca__kernel': 'cosine', 'kpca__n_components': 8}\n",
    "\n",
    "kpca = KernelPCA()\n",
    "\n",
    "clf = AdaBoostClassifier()\n",
    "n_estimators_opts = [50, 1000, 2000]\n",
    "l1_ratio_opts = [0, 0.5, 1]\n",
    "\n",
    "grid_params7 = [\n",
    "    {   'kpca__kernel': kernel_opts,\n",
    "        'kpca__n_components': [2, 4, 8, 16, 32],\n",
    "        'clf__n_estimators': n_estimators_opts,\n",
    "        'clf__base_estimator': [LogisticRegression(max_iter=10000, solver='saga', penalty='elasticnet', class_weight='balanced')],\n",
    "        'clf__base_estimator__l1_ratio': l1_ratio_opts,\n",
    "        'clf__base_estimator__C': [0.01, 0.1, 1.0],\n",
    "    },\n",
    "    \n",
    "]\n",
    "\n",
    "pipeline7 = Pipeline([(\"lognorm\", lognorm), (\"scaler\", scaler), (\"imp\", imputer), (\"kpca\", kpca), (\"clf\", clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search7 = GridSearchCV(pipeline7, n_jobs=NTHREADS, param_grid=grid_params7, cv=10, scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search7.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search7.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search7.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_res = search7.cv_results_['rank_test_score'] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search7.cv_results_['std_test_score'][best_res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search7.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search7.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.values == search7.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca = KernelPCA(kernel='linear')\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=1000)\n",
    "\n",
    "grid_params8 = [\n",
    "    {   'kpca__n_components': [8, 16, 32, 48, 64, 80, 100],\n",
    "        'clf__base_estimator': [LogisticRegression(max_iter=10000, penalty='l2', C=0.1, class_weight='balanced')],\n",
    "    },\n",
    "    \n",
    "]\n",
    "\n",
    "pipeline8 = Pipeline([(\"lognorm\", lognorm), (\"scaler\", scaler), (\"imp\", imputer), (\"kpca\", kpca), (\"clf\", clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search8 = GridSearchCV(pipeline8, n_jobs=NTHREADS, param_grid=grid_params8, cv=10, scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search8.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search8.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search8.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search8.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search8.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = IterativeImputer(sample_posterior=True, n_nearest_features=50, initial_strategy='median')\n",
    "# options I would like to vary for the imputation\n",
    "n_nearest_features_opts = [10, 50, 100]\n",
    "initial_strategy_opts = ['mean', 'median']\n",
    "\n",
    "kbest = SelectKBest()\n",
    "k_opts = [5, 10, 20]\n",
    "\n",
    "poly = PolynomialFeatures()\n",
    "degree_opts = [1, 2, 3]\n",
    "# define my classifier (Logistic regression)\n",
    "clf = LogisticRegression(max_iter=1000, penalty='l2', class_weight='balanced')\n",
    "# define options I would like to vary with logistic regression\n",
    "# l1_ratio_opts = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "C_opts = [0.01, 0.1, 1.0]\n",
    "\n",
    "# place the parameters I would like to vary using a list of dictionaries\n",
    "grid_params9 = [\n",
    "    {\n",
    "        'kbest__k': k_opts,\n",
    "#        'kpca__n_components': n_components_opts,\n",
    "#        'kpca__kernel': kernel_opts,\n",
    "        'poly__degree': degree_opts,\n",
    "        'clf__C': C_opts,\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "pipeline9 = Pipeline([(\"lognorm\", lognorm),\n",
    "                      (\"scaler\", scaler),\n",
    "                      (\"imp\", imputer),\n",
    "                      (\"kbest\", kbest),\n",
    "                      (\"poly\", poly),\n",
    "                      (\"clf\", clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search9 = GridSearchCV(pipeline9, n_jobs=NTHREADS, param_grid=grid_params9, cv=10, scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search9.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search9.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search9.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search9.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search9.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search9.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search9.refit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search9.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search9.best_index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search9.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search9.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = IterativeImputer(sample_posterior=True, n_nearest_features=50, initial_strategy='mean')\n",
    "# options I would like to vary for the imputation\n",
    "\n",
    "kbest = SelectKBest()\n",
    "k_opts = [5, 10, 20]\n",
    "\n",
    "poly = PolynomialFeatures(degree=1)\n",
    "\n",
    "clf = GradientBoostingClassifier(max_features=\"sqrt\", n_estimators=2500)\n",
    "max_depth_opts = [3, 5, 10, 15]\n",
    "learning_rate_opts = [0.01, 0.1, 0.5]\n",
    "\n",
    "\n",
    "grid_params10 = [\n",
    "    {\n",
    "        'kbest__k': k_opts,\n",
    "        'clf__max_depth': max_depth_opts,\n",
    "        'clf__learning_rate': learning_rate_opts,\n",
    "    }\n",
    "]\n",
    "\n",
    "pipeline10 = Pipeline([(\"lognorm\", lognorm),\n",
    "                      (\"scaler\", scaler),\n",
    "                      (\"imp\", imputer),\n",
    "                      (\"kbest\", kbest),\n",
    "                      (\"poly\", poly),\n",
    "                      (\"clf\", clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search10 = GridSearchCV(pipeline10, n_jobs=NTHREADS, param_grid=grid_params10, cv=10, scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search10.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search10.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search10.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search10.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search10.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search10.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search10_df = pd.DataFrame.from_records(search10.cv_results_['params'])\n",
    "search10_df['mean_test_score'] = search10.cv_results_['mean_test_score']\n",
    "search10_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search10_df.groupby('clf__learning_rate')['mean_test_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search10_df.groupby('clf__max_depth')['mean_test_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search10_df.groupby('kbest__k')['mean_test_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the lognorm of non-normal data\n",
    "lognorm = ColumnTransformer(\n",
    "    transformers=[('not_normal', PowerTransformer(standardize=False), not_normal_columns)])\n",
    "# standardize variables\n",
    "scaler = StandardScaler()\n",
    "# impute existing variables\n",
    "imputer = IterativeImputer(n_nearest_features=50, sample_posterior=True, initial_strategy='median')\n",
    "\n",
    "# dimension reduction with selecting features\n",
    "kbest = SelectKBest()\n",
    "k_opts = [5, 10, 20, 50]\n",
    "\n",
    "pca = PCA()\n",
    "n_components_opts = [5, 10, 20, 50]\n",
    "whiten_opts = [False, True]\n",
    "\n",
    "kpca = KernelPCA(kernel=\"linear\")\n",
    "\n",
    "\n",
    "# feature multiplication\n",
    "poly = PolynomialFeatures()\n",
    "degree_opts = [1, 2, 3]\n",
    "\n",
    "# classifiers\n",
    "\n",
    "# boosting\n",
    "learning_rate_opts = [0.01, 0.1, 1.0]\n",
    "\n",
    "grad_boost = GradientBoostingClassifier(max_features=\"sqrt\", n_estimators=2500)\n",
    "max_depth_opts = [3, 5, 10, 15]\n",
    "\n",
    "\n",
    "ada_boost = AdaBoostClassifier(n_estimators=2500, base_estimator=LogisticRegression(max_iter=1000, class_weight=\"balanced\"))\n",
    "\n",
    "# logistic regression\n",
    "logr = LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
    "C_opts = [0.01, 0.1, 1.0]\n",
    "\n",
    "# random forest\n",
    "randf = RandomForestClassifier(max_features=\"sqrt\", class_weight=\"balanced_subsample\", n_estimators=2500)\n",
    "\n",
    "\n",
    "# placeholder\n",
    "placeholder = FunctionTransformer()\n",
    "grid_params11 = [\n",
    "    {\n",
    "        'dim_red': (kbest,),\n",
    "        'dim_red__k': k_opts,\n",
    "        'dim_enh': (poly,),\n",
    "        'dim_enh__degree': degree_opts,\n",
    "        'clf': (grad_boost,),\n",
    "        'clf__learning_rate': learning_rate_opts,\n",
    "        'clf__max_depth': max_depth_opts,\n",
    "    },\n",
    "        {\n",
    "        'dim_red': (pca,),\n",
    "        'dim_red__n_components': n_components_opts,\n",
    "        'dim_red__whiten': whiten_opts,\n",
    "        'dim_enh': (poly,),\n",
    "        'dim_enh__degree': degree_opts,\n",
    "        'clf': (grad_boost,),\n",
    "        'clf__learning_rate': learning_rate_opts,\n",
    "        'clf__max_depth': max_depth_opts,\n",
    "    },\n",
    "    {\n",
    "        'dim_red': (kpca,),\n",
    "        'dim_red__n_components': n_components_opts,\n",
    "        'dim_enh': (poly,),\n",
    "        'dim_enh__degree': degree_opts,\n",
    "        'clf': (grad_boost,),\n",
    "        'clf__learning_rate': learning_rate_opts,\n",
    "        'clf__max_depth': max_depth_opts,\n",
    "    },\n",
    "    {\n",
    "        'dim_red': (kbest,),\n",
    "        'dim_red__k': k_opts,\n",
    "        'dim_enh': (placeholder,),\n",
    "        'clf': (grad_boost,),\n",
    "        'clf__learning_rate': learning_rate_opts,\n",
    "        'clf__max_depth': max_depth_opts,\n",
    "    },\n",
    "    {\n",
    "        'dim_red': (pca,),\n",
    "        'dim_red__n_components': n_components_opts,\n",
    "        'dim_red__whiten': whiten_opts,\n",
    "        'dim_enh': (placeholder,),\n",
    "        'clf': (grad_boost,),\n",
    "        'clf__learning_rate': learning_rate_opts,\n",
    "        'clf__max_depth': max_depth_opts,\n",
    "    },\n",
    "    {\n",
    "        'dim_red': (kpca,),\n",
    "        'dim_red__n_components': n_components_opts,\n",
    "        'dim_enh': (placeholder,),\n",
    "        'clf': (grad_boost,),\n",
    "        'clf__learning_rate': learning_rate_opts,\n",
    "        'clf__max_depth': max_depth_opts,\n",
    "    },\n",
    "]\n",
    "\n",
    "pipeline11 = Pipeline([(\"lognorm\", lognorm),\n",
    "                       (\"scaler\", scaler),\n",
    "                       (\"imputer\", imputer),\n",
    "                       (\"dim_red\", placeholder),\n",
    "                       (\"dim_enh\", placeholder),\n",
    "                       (\"clf\", placeholder)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search11 = GridSearchCV(pipeline11, n_jobs=NTHREADS, param_grid=grid_params11, cv=10, scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search11.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "placeholder = FunctionTransformer()\n",
    "\n",
    "imputer = IterativeImputer(sample_posterior=True, n_nearest_features=50, initial_strategy='mean')\n",
    "# options I would like to vary for the imputation\n",
    "\n",
    "# reduction strategies\n",
    "kbest = SelectKBest()\n",
    "k_opts = [20, 50, 60, 80]\n",
    "\n",
    "pca = PCA()\n",
    "n_components_opts = [20, 50, 60, 80]\n",
    "whiten_opts = [False, True]\n",
    "\n",
    "kpca = KernelPCA(kernel=\"linear\")\n",
    "\n",
    "poly = PolynomialFeatures(degree=1)\n",
    "\n",
    "clf = GradientBoostingClassifier(max_features=\"sqrt\", n_estimators=2500, max_depth=10, learning_rate=0.5)\n",
    "\n",
    "\n",
    "grid_params12 = [\n",
    "    {\n",
    "        'dimred': (kbest,),\n",
    "        'dimred__k': k_opts,\n",
    "    },\n",
    "    {\n",
    "        'dimred': (pca,),\n",
    "        'dimred__n_components': n_components_opts,\n",
    "        'dimred__whiten': whiten_opts,\n",
    "    },\n",
    "    {\n",
    "        'dimred': (kpca,),\n",
    "        'dimred__n_components': n_components_opts,\n",
    "    },\n",
    "    \n",
    "]\n",
    "\n",
    "pipeline12 = Pipeline([(\"lognorm\", lognorm),\n",
    "                      (\"scaler\", scaler),\n",
    "                      (\"imp\", imputer),\n",
    "                      (\"dimred\", placeholder),\n",
    "                      (\"poly\", poly),\n",
    "                      (\"clf\", clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search12 = GridSearchCV(pipeline12, n_jobs=NTHREADS, param_grid=grid_params12, cv=10, scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search12.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search12.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search12.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search12.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search12_df = pd.DataFrame.from_records(search12.cv_results_['params'])\n",
    "search12_df['mean_test_score'] = search12.cv_results_['mean_test_score']\n",
    "search12_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search12_df['dimred'] = search12_df['dimred'].apply(lambda x: x.__str__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search12_df.groupby('dimred')['mean_test_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df = bp_df.filter(regex=(\"31p.*[^r]$|t1r.*_m|alff.*_m|vol|dti\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_df, group, test_size=10, stratify=group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boost Control cases for X_train/y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cases = (y_train == \"Case\").sum()\n",
    "n_controls = (y_train == \"Control\").sum()\n",
    "needed_controls = n_cases - n_controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_data = pd.DataFrame([np.random.permutation(X_train[y_train == \"Control\"][c]) for c in X_train.columns],\n",
    "                            index=X_train.columns).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_boost = pd.concat([X_train, control_data.iloc[0:needed_controls, :]])\n",
    "y_train_boost = pd.concat([y_train, y_train[y_train == \"Control\"].iloc[0:needed_controls]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try the best model?\n",
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "clf = MLPClassifier(solver='lbfgs')\n",
    "pipelineN = Pipeline([(\"imp\", imputer),\n",
    "                      (\"scaler\", scaler),\n",
    "                      (\"clf\", clf)])\n",
    "pipelineN.fit(X_train, y_train)\n",
    "pipelineN.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks promising, let's test different learning parameters\n",
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "clf = MLPClassifier(solver='lbfgs')\n",
    "alpha_opts = 10.0 ** -np.arange(1, 7)\n",
    "\n",
    "param_gridO = [\n",
    "    {\n",
    "        \"clf__alpha\": alpha_opts,\n",
    "    }\n",
    "]\n",
    "\n",
    "pipelineO = Pipeline([(\"imp\", imputer),\n",
    "                      (\"scaler\", scaler),\n",
    "                      (\"clf\", clf)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchO = GridSearchCV(pipelineO, n_jobs=NTHREADS, param_grid=param_gridO, cv=10, scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=32)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done  28 out of  60 | elapsed:  1.0min remaining:  1.2min\n",
      "[Parallel(n_jobs=32)]: Done  60 out of  60 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('imp',\n",
       "                                        IterativeImputer(add_indicator=False,\n",
       "                                                         estimator=None,\n",
       "                                                         imputation_order='random',\n",
       "                                                         initial_strategy='median',\n",
       "                                                         max_iter=10,\n",
       "                                                         max_value=None,\n",
       "                                                         min_value=None,\n",
       "                                                         missing_values=nan,\n",
       "                                                         n_nearest_features=50,\n",
       "                                                         random_state=None,\n",
       "                                                         sample_posterior=True,\n",
       "                                                         skip_complete=False,\n",
       "                                                         tol=0.001,\n",
       "                                                         verbose=0)),\n",
       "                                       (...\n",
       "                                                      nesterovs_momentum=True,\n",
       "                                                      power_t=0.5,\n",
       "                                                      random_state=None,\n",
       "                                                      shuffle=True,\n",
       "                                                      solver='lbfgs',\n",
       "                                                      tol=0.0001,\n",
       "                                                      validation_fraction=0.1,\n",
       "                                                      verbose=False,\n",
       "                                                      warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=32,\n",
       "             param_grid=[{'clf__alpha': array([1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06])}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchO.fit(X_train_boost, y_train_boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333333"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchO.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Control', 'Case', 'Control', 'Control', 'Control', 'Case', 'Case',\n",
       "       'Case', 'Case', 'Case'], dtype='<U7')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchO.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.001}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchO.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9546666666666667"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchO.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54.433084</td>\n",
       "      <td>1.567079</td>\n",
       "      <td>4.969285</td>\n",
       "      <td>1.291613</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'clf__alpha': 0.1}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.900667</td>\n",
       "      <td>0.082970</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.355649</td>\n",
       "      <td>1.561148</td>\n",
       "      <td>4.971033</td>\n",
       "      <td>1.298188</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'clf__alpha': 0.01}</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.899333</td>\n",
       "      <td>0.117093</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.019608</td>\n",
       "      <td>1.679950</td>\n",
       "      <td>4.946061</td>\n",
       "      <td>1.231938</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'clf__alpha': 0.001}</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.954667</td>\n",
       "      <td>0.082667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.530026</td>\n",
       "      <td>1.099783</td>\n",
       "      <td>4.647366</td>\n",
       "      <td>1.364514</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'clf__alpha': 0.0001}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.920667</td>\n",
       "      <td>0.130451</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.662105</td>\n",
       "      <td>1.426727</td>\n",
       "      <td>4.540552</td>\n",
       "      <td>1.235639</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>{'clf__alpha': 1e-05}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.106207</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>52.021164</td>\n",
       "      <td>1.583680</td>\n",
       "      <td>4.524173</td>\n",
       "      <td>1.279840</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>{'clf__alpha': 1e-06}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.123935</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      54.433084      1.567079         4.969285        1.291613   \n",
       "1      54.355649      1.561148         4.971033        1.298188   \n",
       "2      54.019608      1.679950         4.946061        1.231938   \n",
       "3      52.530026      1.099783         4.647366        1.364514   \n",
       "4      51.662105      1.426727         4.540552        1.235639   \n",
       "5      52.021164      1.583680         4.524173        1.279840   \n",
       "\n",
       "  param_clf__alpha                  params  split0_test_score  \\\n",
       "0              0.1     {'clf__alpha': 0.1}           0.966667   \n",
       "1             0.01    {'clf__alpha': 0.01}           0.933333   \n",
       "2            0.001   {'clf__alpha': 0.001}           0.933333   \n",
       "3           0.0001  {'clf__alpha': 0.0001}           1.000000   \n",
       "4            1e-05   {'clf__alpha': 1e-05}           1.000000   \n",
       "5            1e-06   {'clf__alpha': 1e-06}           1.000000   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.800000               0.92               1.00               0.92   \n",
       "1           0.700000               1.00               1.00               1.00   \n",
       "2           0.933333               1.00               1.00               1.00   \n",
       "3           0.966667               1.00               1.00               0.92   \n",
       "4           0.800000               1.00               0.96               0.92   \n",
       "5           0.800000               1.00               0.96               1.00   \n",
       "\n",
       "   split5_test_score  split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0               0.72               0.88               0.92               1.00   \n",
       "1               0.68               0.88               1.00               0.96   \n",
       "2               0.72               0.96               1.00               1.00   \n",
       "3               0.56               0.92               1.00               1.00   \n",
       "4               0.64               0.92               0.96               0.96   \n",
       "5               0.60               0.96               1.00               1.00   \n",
       "\n",
       "   split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0               0.88         0.900667        0.082970                4  \n",
       "1               0.84         0.899333        0.117093                6  \n",
       "2               1.00         0.954667        0.082667                1  \n",
       "3               0.84         0.920667        0.130451                2  \n",
       "4               0.84         0.900000        0.106207                5  \n",
       "5               0.88         0.920000        0.123935                3  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(searchO.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       78\n",
       "unique       2\n",
       "top       Case\n",
       "freq        51\n",
       "Name: group, dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add additional control cases to training\n",
    "searchO.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try the best model?\n",
    "imputer = IterativeImputer(add_indicator=False,\n",
    "                           initial_strategy='median',\n",
    "                           imputation_order='random',\n",
    "                           sample_posterior=True,\n",
    "                           max_iter=10,\n",
    "                           n_nearest_features=50)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=0.001)\n",
    "pipelineP = Pipeline([(\"imp\", imputer),\n",
    "                      (\"scaler\", scaler),\n",
    "                      (\"clf\", clf)])\n",
    "pipelineP.fit(X_train_boost, y_train_boost)\n",
    "pipelineP.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Case', 'Case', 'Control', 'Case', 'Control', 'Case', 'Control',\n",
       "       'Case', 'Case', 'Control'], dtype='<U7')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelineP.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comfy_pants",
   "language": "python",
   "name": "comfy_pants"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
